{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c033961d-e588-4913-930c-a467f746985b",
   "metadata": {},
   "source": [
    "# Explain what does PyTorch 2.0 do to your code\n",
    "\n",
    "PyTorch 2.0 looks like magic to many researchers, as they dynamically translate the bytecode for you. Many people don't know Python bytecode, so they don't know how do the translated code look like. Fortunately, with `depyf`, we can clearly illustrate it for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66dc808-699f-4db6-be39-103a504103b4",
   "metadata": {},
   "source": [
    "# Run some code with `torch.compile`, and use `eager` backend\n",
    "\n",
    "Note that we use `eager` backend so that the compiled subgraph runs in eager mode, and then we can easily get its code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60a95337-ef1a-40be-9d8b-2ba1a5e7cf48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T14:46:03.393155Z",
     "start_time": "2023-12-02T14:46:03.215745Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "@torch.compile(backend=\"eager\")\n",
    "def toy_example(a, b):\n",
    "    x = a / (torch.abs(a) + 1)\n",
    "    if b.sum() < 0:\n",
    "        b = b * -1\n",
    "    return x * b\n",
    "\n",
    "for _ in range(100):\n",
    "    toy_example(torch.randn(10), torch.randn(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85aedd01-78ba-4393-8b26-79a9ba210796",
   "metadata": {},
   "source": [
    "# Interactively explore everything you are curious about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfd1080f-6852-43d4-972a-0aa26fb0e1d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T14:59:19.459421Z",
     "start_time": "2023-12-02T14:59:19.453177Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "# transformed source code:"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.JSON object>",
      "application/json": {
       "name": "toy_example",
       "source_code": "toy_example",
       "compiled_code_entries": [
        {
         "guard": [
          "___guarded_code.valid",
          "___check_global_state()",
          "hasattr(L['a'], '_dynamo_dynamic_indices') == False",
          "hasattr(L['b'], '_dynamo_dynamic_indices') == False",
          "utils_device.CURRENT_DEVICE == None",
          "(___skip_backend_check() or ___current_backend() == ___lookup_backend(5862548880))",
          "___compile_config_hash() == 'f026a689da89e70080ed880f2c694b3f'",
          "not ___needs_nopython()",
          "___check_tensors(L['a'], L['b'], tensor_check_names=tensor_check_names)"
         ],
         "compiled_code": "compiled_code_6",
         "compiled_subgraph": "__compiled_fn_0",
         "referenced_global_functions": {
          "__resume_at_30_1": {
           "name": "__resume_at_30_1",
           "source_code": "__resume_at_30_1",
           "compiled_code_entries": [
            {
             "guard": [
              "___guarded_code.valid",
              "___check_global_state()",
              "hasattr(L['b'], '_dynamo_dynamic_indices') == False",
              "hasattr(L['x'], '_dynamo_dynamic_indices') == False",
              "utils_device.CURRENT_DEVICE == None",
              "(___skip_backend_check() or ___current_backend() == ___lookup_backend(5862548880))",
              "___compile_config_hash() == 'f026a689da89e70080ed880f2c694b3f'",
              "___check_tensors(L['b'], L['x'], tensor_check_names=tensor_check_names)"
             ],
             "compiled_code": "compiled_code_7",
             "compiled_subgraph": "__compiled_fn_3",
             "referenced_global_functions": {}
            }
           ]
          },
          "__resume_at_38_2": {
           "name": "__resume_at_38_2",
           "source_code": "__resume_at_38_2",
           "compiled_code_entries": [
            {
             "guard": [
              "___guarded_code.valid",
              "___check_global_state()",
              "hasattr(L['b'], '_dynamo_dynamic_indices') == False",
              "hasattr(L['x'], '_dynamo_dynamic_indices') == False",
              "utils_device.CURRENT_DEVICE == None",
              "(___skip_backend_check() or ___current_backend() == ___lookup_backend(5862548880))",
              "___compile_config_hash() == 'f026a689da89e70080ed880f2c694b3f'",
              "___check_tensors(L['b'], L['x'], tensor_check_names=tensor_check_names)"
             ],
             "compiled_code": "compiled_code_8",
             "compiled_subgraph": "__compiled_fn_4",
             "referenced_global_functions": {}
            }
           ]
          }
         }
        }
       ]
      }
     },
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "# source code of referenced function:"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "<details>\n  <summary>compiled_code_6</summary>\n\n  ```python\n  def compiled_code_6(a, b):\n      __temp_1689 = __compiled_fn_0(a, b)\n      x = __temp_1689[0]\n      if __temp_1689[1]:\n          return __resume_at_30_1(b, x)\n      return __resume_at_38_2(b, x)\n\n  ```\n</details>\n<details>\n  <summary>toy_example</summary>\n\n  ```python\n  def toy_example(a, b):\n      x = a / (torch.abs(a) + 1)\n      if b.sum() < 0:\n          b = b * -1\n      return x * b\n\n  ```\n</details>\n<details>\n  <summary>__resume_at_38_2</summary>\n\n  ```python\n  def __resume_at_38_2(b, x):\n      return x * b\n\n  ```\n</details>\n<details>\n  <summary>__compiled_fn_4</summary>\n\n  ```python\n  def __compiled_fn_4(self, L_x_, L_b_):\n      l_x_ = L_x_\n      l_b_ = L_b_\n      mul = l_x_ * l_b_\n      l_x_ = None\n      l_b_ = None\n      return mul,\n\n  ```\n</details>\n<details>\n  <summary>compiled_code_7</summary>\n\n  ```python\n  def compiled_code_7(b, x):\n      return __compiled_fn_3(b, x)[0]\n\n  ```\n</details>\n<details>\n  <summary>__compiled_fn_3</summary>\n\n  ```python\n  def __compiled_fn_3(self, L_b_, L_x_):\n      l_b_ = L_b_\n      l_x_ = L_x_\n      b = l_b_ * -1\n      l_b_ = None\n      mul_1 = l_x_ * b\n      l_x_ = None\n      b = None\n      return mul_1,\n\n  ```\n</details>\n<details>\n  <summary>__resume_at_30_1</summary>\n\n  ```python\n  def __resume_at_30_1(b, x):\n      b = b * -1\n      return x * b\n\n  ```\n</details>\n<details>\n  <summary>__compiled_fn_0</summary>\n\n  ```python\n  def __compiled_fn_0(self, L_a_, L_b_):\n      l_a_ = L_a_\n      l_b_ = L_b_\n      abs_1 = torch.abs(l_a_)\n      add = abs_1 + 1\n      abs_1 = None\n      x = l_a_ / add\n      l_a_ = None\n      add = None\n      sum_1 = l_b_.sum()\n      l_b_ = None\n      lt = sum_1 < 0\n      sum_1 = None\n      return x, lt\n\n  ```\n</details>\n<details>\n  <summary>compiled_code_8</summary>\n\n  ```python\n  def compiled_code_8(b, x):\n      return __compiled_fn_4(x, b)[0]\n\n  ```\n</details>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from depyf.explain import interactive_explain\n",
    "interactive_explain(toy_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e38342e-b772-4675-84cd-0846fe1dd948",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T15:00:50.402790Z",
     "start_time": "2023-12-02T15:00:00.350241Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/unicorn/miniconda3/envs/pt2/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/unicorn/miniconda3/envs/pt2/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Swin_T_Weights.IMAGENET1K_V1`. You can also use `weights=Swin_T_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "model = torchvision.models.swin_t(pretrained=True)\n",
    "model_compile = torch.compile(model, backend='eager')\n",
    "for _ in range(100):\n",
    "    model_compile(torch.randn(1,3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "# transformed source code:"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.JSON object>",
      "application/json": {
       "name": "forward",
       "source_code": "forward",
       "compiled_code_entries": [
        {
         "guard": [
          "___guarded_code.valid",
          "___check_global_state()",
          "hasattr(L['x'], '_dynamo_dynamic_indices') == False",
          "___check_obj_id(L['self'], 6400846016)",
          "L['self'].training == True",
          "utils_device.CURRENT_DEVICE == None",
          "(___skip_backend_check() or ___current_backend() == ___lookup_backend(6426673792))",
          "___compile_config_hash() == 'f026a689da89e70080ed880f2c694b3f'",
          "___check_type_id(G['shifted_window_attention'].__defaults__[0], 4311392808)",
          "G['shifted_window_attention'].__defaults__[0] == 0.0",
          "___check_type_id(G['shifted_window_attention'].__defaults__[1], 4311392808)",
          "G['shifted_window_attention'].__defaults__[1] == 0.0",
          "___check_obj_id(G['shifted_window_attention'].__defaults__[2], 4311465712)",
          "___check_obj_id(G['shifted_window_attention'].__defaults__[3], 4311465712)",
          "___check_obj_id(G['shifted_window_attention'].__defaults__[4], 4311465712)",
          "___check_obj_id(G['shifted_window_attention'].__defaults__[5], 4311463024)",
          "___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 4311422584)",
          "set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()",
          "___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 4311422584)",
          "set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()",
          "___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 4311422584)",
          "set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()",
          "___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 4311422584)",
          "set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()",
          "___check_obj_id(G['__import_torchvision_dot_ops_dot_stochastic_depth'].stochastic_depth.__defaults__[0], 4311463024)",
          "___check_tensors(L['x'], tensor_check_names=tensor_check_names)"
         ],
         "compiled_code": "compiled_code_9",
         "compiled_subgraph": "__compiled_fn_7",
         "referenced_global_functions": {}
        },
        {
         "guard": [
          "___guarded_code.valid",
          "___check_global_state()",
          "hasattr(L['x'], '_dynamo_dynamic_indices') == False",
          "___check_obj_id(L['self'], 5862548064)",
          "L['self'].training == True",
          "utils_device.CURRENT_DEVICE == None",
          "(___skip_backend_check() or ___current_backend() == ___lookup_backend(6319837808))",
          "___compile_config_hash() == 'f026a689da89e70080ed880f2c694b3f'",
          "___check_type_id(G['shifted_window_attention'].__defaults__[0], 4311392808)",
          "G['shifted_window_attention'].__defaults__[0] == 0.0",
          "___check_type_id(G['shifted_window_attention'].__defaults__[1], 4311392808)",
          "G['shifted_window_attention'].__defaults__[1] == 0.0",
          "___check_obj_id(G['shifted_window_attention'].__defaults__[2], 4311465712)",
          "___check_obj_id(G['shifted_window_attention'].__defaults__[3], 4311465712)",
          "___check_obj_id(G['shifted_window_attention'].__defaults__[4], 4311465712)",
          "___check_obj_id(G['shifted_window_attention'].__defaults__[5], 4311463024)",
          "___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 4311422584)",
          "set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()",
          "___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 4311422584)",
          "set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()",
          "___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 4311422584)",
          "set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()",
          "___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 4311422584)",
          "set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()",
          "___check_obj_id(G['__import_torchvision_dot_ops_dot_stochastic_depth'].stochastic_depth.__defaults__[0], 4311463024)",
          "___check_tensors(L['x'], tensor_check_names=tensor_check_names)"
         ],
         "compiled_code": "compiled_code_10",
         "compiled_subgraph": "__compiled_fn_6",
         "referenced_global_functions": {}
        }
       ]
      }
     },
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "# source code of referenced function:"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "<details>\n  <summary>__compiled_fn_6</summary>\n\n  ```python\n  def __compiled_fn_6(self, L_x_):\n      l_x_ = L_x_\n      l__self___features_0_0 = self.L__self___features_0_0(l_x_)\n      l_x_ = None\n      __temp_2498 = []\n      __temp_2498.extend((0, 2, 3, 1))\n      permute = torch.permute(l__self___features_0_0, __temp_2498)\n      l__self___features_0_0 = None\n      l__self___features_0_2 = self.L__self___features_0_2(permute)\n      permute = None\n      getattr_getattr_l__self___features___1_____0___norm1 = (self.\n          getattr_getattr_L__self___features___1_____0___norm1(\n          l__self___features_0_2))\n      (\n          getattr_getattr_l__self___features___1_____0___attn_relative_position_bias_table\n          ) = (self.\n          getattr_getattr_L__self___features___1_____0___attn_relative_position_bias_table\n          )\n      (getattr_getattr_l__self___features___1_____0___attn_relative_position_index\n          ) = (self.\n          getattr_getattr_L__self___features___1_____0___attn_relative_position_index\n          )\n      relative_position_bias = (\n          getattr_getattr_l__self___features___1_____0___attn_relative_position_bias_table\n          [\n          getattr_getattr_l__self___features___1_____0___attn_relative_position_index\n          ])\n      (\n          getattr_getattr_l__self___features___1_____0___attn_relative_position_bias_table\n          ) = None\n      (getattr_getattr_l__self___features___1_____0___attn_relative_position_index\n          ) = None\n      relative_position_bias_1 = relative_position_bias.view(49, 49, -1)\n      relative_position_bias = None\n      permute_1 = relative_position_bias_1.permute(2, 0, 1)\n      relative_position_bias_1 = None\n      contiguous = permute_1.contiguous()\n      permute_1 = None\n      relative_position_bias_3 = contiguous.unsqueeze(0)\n      contiguous = None\n      getattr_getattr_l__self___features___1_____0___attn_qkv_weight = (self.\n          getattr_getattr_L__self___features___1_____0___attn_qkv_weight)\n      getattr_getattr_l__self___features___1_____0___attn_proj_weight = (self.\n          getattr_getattr_L__self___features___1_____0___attn_proj_weight)\n      getattr_getattr_l__self___features___1_____0___attn_qkv_bias = (self.\n          getattr_getattr_L__self___features___1_____0___attn_qkv_bias)\n      getattr_getattr_l__self___features___1_____0___attn_proj_bias = (self.\n          getattr_getattr_L__self___features___1_____0___attn_proj_bias)\n      x = torch.nn.functional.pad(\n          getattr_getattr_l__self___features___1_____0___norm1, (0, 0, 0, 0, 0, 0))\n      getattr_getattr_l__self___features___1_____0___norm1 = None\n      x_1 = x.view(1, 8, 7, 8, 7, 96)\n      x = None\n      permute_2 = x_1.permute(0, 1, 3, 2, 4, 5)\n      x_1 = None\n      x_2 = permute_2.reshape(64, 49, 96)\n      permute_2 = None\n      qkv = torch._C._nn.linear(x_2,\n          getattr_getattr_l__self___features___1_____0___attn_qkv_weight,\n          getattr_getattr_l__self___features___1_____0___attn_qkv_bias)\n      x_2 = None\n      getattr_getattr_l__self___features___1_____0___attn_qkv_weight = None\n      getattr_getattr_l__self___features___1_____0___attn_qkv_bias = None\n      reshape_1 = qkv.reshape(64, 49, 3, 3, 32)\n      qkv = None\n      qkv_1 = reshape_1.permute(2, 0, 3, 1, 4)\n      reshape_1 = None\n      q = qkv_1[0]\n      k = qkv_1[1]\n      v = qkv_1[2]\n      qkv_1 = None\n      q_1 = q * 0.1767766952966369\n      q = None\n      transpose = k.transpose(-2, -1)\n      k = None\n      attn = q_1.matmul(transpose)\n      q_1 = None\n      transpose = None\n      attn_1 = attn + relative_position_bias_3\n      attn = None\n      relative_position_bias_3 = None\n      attn_2 = torch.nn.functional.softmax(attn_1, dim=-1)\n      attn_1 = None\n      attn_3 = torch.nn.functional.dropout(attn_2, p=0.0, training=True)\n      attn_2 = None\n      matmul_1 = attn_3.matmul(v)\n      attn_3 = None\n      v = None\n      transpose_1 = matmul_1.transpose(1, 2)\n      matmul_1 = None\n      x_3 = transpose_1.reshape(64, 49, 96)\n      transpose_1 = None\n      x_4 = torch._C._nn.linear(x_3,\n          getattr_getattr_l__self___features___1_____0___attn_proj_weight,\n          getattr_getattr_l__self___features___1_____0___attn_proj_bias)\n      x_3 = None\n      getattr_getattr_l__self___features___1_____0___attn_proj_weight = None\n      getattr_getattr_l__self___features___1_____0___attn_proj_bias = None\n      x_5 = torch.nn.functional.dropout(x_4, p=0.0, training=True)\n      x_4 = None\n      x_6 = x_5.view(1, 8, 8, 7, 7, 96)\n      x_5 = None\n      permute_4 = x_6.permute(0, 1, 3, 2, 4, 5)\n      x_6 = None\n      x_7 = permute_4.reshape(1, 56, 56, 96)\n      permute_4 = None\n      getitem_4 = x_7[slice(None, None, None), slice(None, 56, None), slice(None,\n          56, None), slice(None, None, None)]\n      x_7 = None\n      x_8 = getitem_4.contiguous()\n      getitem_4 = None\n      _log_api_usage_once = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      x_9 = l__self___features_0_2 + x_8\n      l__self___features_0_2 = None\n      x_8 = None\n      getattr_getattr_l__self___features___1_____0___norm2 = (self.\n          getattr_getattr_L__self___features___1_____0___norm2(x_9))\n      getattr_getattr_l__self___features___1_____0___mlp_0 = (self.\n          getattr_getattr_L__self___features___1_____0___mlp_0(\n          getattr_getattr_l__self___features___1_____0___norm2))\n      getattr_getattr_l__self___features___1_____0___norm2 = None\n      getattr_getattr_l__self___features___1_____0___mlp_1 = (self.\n          getattr_getattr_L__self___features___1_____0___mlp_1(\n          getattr_getattr_l__self___features___1_____0___mlp_0))\n      getattr_getattr_l__self___features___1_____0___mlp_0 = None\n      getattr_getattr_l__self___features___1_____0___mlp_2 = (self.\n          getattr_getattr_L__self___features___1_____0___mlp_2(\n          getattr_getattr_l__self___features___1_____0___mlp_1))\n      getattr_getattr_l__self___features___1_____0___mlp_1 = None\n      getattr_getattr_l__self___features___1_____0___mlp_3 = (self.\n          getattr_getattr_L__self___features___1_____0___mlp_3(\n          getattr_getattr_l__self___features___1_____0___mlp_2))\n      getattr_getattr_l__self___features___1_____0___mlp_2 = None\n      getattr_getattr_l__self___features___1_____0___mlp_4 = (self.\n          getattr_getattr_L__self___features___1_____0___mlp_4(\n          getattr_getattr_l__self___features___1_____0___mlp_3))\n      getattr_getattr_l__self___features___1_____0___mlp_3 = None\n      _log_api_usage_once_1 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      x_10 = x_9 + getattr_getattr_l__self___features___1_____0___mlp_4\n      x_9 = None\n      getattr_getattr_l__self___features___1_____0___mlp_4 = None\n      getattr_getattr_l__self___features___1_____1___norm1 = (self.\n          getattr_getattr_L__self___features___1_____1___norm1(x_10))\n      (\n          getattr_getattr_l__self___features___1_____1___attn_relative_position_bias_table\n          ) = (self.\n          getattr_getattr_L__self___features___1_____1___attn_relative_position_bias_table\n          )\n      (getattr_getattr_l__self___features___1_____1___attn_relative_position_index\n          ) = (self.\n          getattr_getattr_L__self___features___1_____1___attn_relative_position_index\n          )\n      relative_position_bias_4 = (\n          getattr_getattr_l__self___features___1_____1___attn_relative_position_bias_table\n          [\n          getattr_getattr_l__self___features___1_____1___attn_relative_position_index\n          ])\n      (\n          getattr_getattr_l__self___features___1_____1___attn_relative_position_bias_table\n          ) = None\n      (getattr_getattr_l__self___features___1_____1___attn_relative_position_index\n          ) = None\n      relative_position_bias_5 = relative_position_bias_4.view(49, 49, -1)\n      relative_position_bias_4 = None\n      permute_5 = relative_position_bias_5.permute(2, 0, 1)\n      relative_position_bias_5 = None\n      contiguous_2 = permute_5.contiguous()\n      permute_5 = None\n      relative_position_bias_7 = contiguous_2.unsqueeze(0)\n      contiguous_2 = None\n      getattr_getattr_l__self___features___1_____1___attn_qkv_weight = (self.\n          getattr_getattr_L__self___features___1_____1___attn_qkv_weight)\n      getattr_getattr_l__self___features___1_____1___attn_proj_weight = (self.\n          getattr_getattr_L__self___features___1_____1___attn_proj_weight)\n      getattr_getattr_l__self___features___1_____1___attn_qkv_bias = (self.\n          getattr_getattr_L__self___features___1_____1___attn_qkv_bias)\n      getattr_getattr_l__self___features___1_____1___attn_proj_bias = (self.\n          getattr_getattr_L__self___features___1_____1___attn_proj_bias)\n      x_11 = torch.nn.functional.pad(\n          getattr_getattr_l__self___features___1_____1___norm1, (0, 0, 0, 0, 0, 0))\n      getattr_getattr_l__self___features___1_____1___norm1 = None\n      x_12 = torch.roll(x_11, shifts=(-3, -3), dims=(1, 2))\n      x_11 = None\n      x_13 = x_12.view(1, 8, 7, 8, 7, 96)\n      x_12 = None\n      permute_6 = x_13.permute(0, 1, 3, 2, 4, 5)\n      x_13 = None\n      x_14 = permute_6.reshape(64, 49, 96)\n      permute_6 = None\n      qkv_2 = torch._C._nn.linear(x_14,\n          getattr_getattr_l__self___features___1_____1___attn_qkv_weight,\n          getattr_getattr_l__self___features___1_____1___attn_qkv_bias)\n      getattr_getattr_l__self___features___1_____1___attn_qkv_weight = None\n      getattr_getattr_l__self___features___1_____1___attn_qkv_bias = None\n      reshape_5 = qkv_2.reshape(64, 49, 3, 3, 32)\n      qkv_2 = None\n      qkv_3 = reshape_5.permute(2, 0, 3, 1, 4)\n      reshape_5 = None\n      q_2 = qkv_3[0]\n      k_1 = qkv_3[1]\n      v_1 = qkv_3[2]\n      qkv_3 = None\n      q_3 = q_2 * 0.1767766952966369\n      q_2 = None\n      transpose_2 = k_1.transpose(-2, -1)\n      k_1 = None\n      attn_4 = q_3.matmul(transpose_2)\n      q_3 = None\n      transpose_2 = None\n      attn_5 = attn_4 + relative_position_bias_7\n      attn_4 = None\n      relative_position_bias_7 = None\n      attn_mask = x_14.new_zeros((56, 56))\n      x_14 = None\n      attn_mask[slice(0, -7, None), slice(0, -7, None)] = 0\n      setitem = attn_mask\n      attn_mask[slice(0, -7, None), slice(-7, -3, None)] = 1\n      setitem_1 = attn_mask\n      attn_mask[slice(0, -7, None), slice(-3, None, None)] = 2\n      setitem_2 = attn_mask\n      attn_mask[slice(-7, -3, None), slice(0, -7, None)] = 3\n      setitem_3 = attn_mask\n      attn_mask[slice(-7, -3, None), slice(-7, -3, None)] = 4\n      setitem_4 = attn_mask\n      attn_mask[slice(-7, -3, None), slice(-3, None, None)] = 5\n      setitem_5 = attn_mask\n      attn_mask[slice(-3, None, None), slice(0, -7, None)] = 6\n      setitem_6 = attn_mask\n      attn_mask[slice(-3, None, None), slice(-7, -3, None)] = 7\n      setitem_7 = attn_mask\n      attn_mask[slice(-3, None, None), slice(-3, None, None)] = 8\n      setitem_8 = attn_mask\n      attn_mask_1 = attn_mask.view(8, 7, 8, 7)\n      attn_mask = None\n      permute_8 = attn_mask_1.permute(0, 2, 1, 3)\n      attn_mask_1 = None\n      attn_mask_2 = permute_8.reshape(64, 49)\n      permute_8 = None\n      unsqueeze_2 = attn_mask_2.unsqueeze(1)\n      unsqueeze_3 = attn_mask_2.unsqueeze(2)\n      attn_mask_2 = None\n      attn_mask_3 = unsqueeze_2 - unsqueeze_3\n      unsqueeze_2 = None\n      unsqueeze_3 = None\n      ne = attn_mask_3 != 0\n      masked_fill = attn_mask_3.masked_fill(ne, -100.0)\n      ne = None\n      eq = attn_mask_3 == 0\n      attn_mask_3 = None\n      attn_mask_4 = masked_fill.masked_fill(eq, 0.0)\n      masked_fill = None\n      eq = None\n      attn_6 = attn_5.view(1, 64, 3, 49, 49)\n      attn_5 = None\n      unsqueeze_4 = attn_mask_4.unsqueeze(1)\n      attn_mask_4 = None\n      unsqueeze_5 = unsqueeze_4.unsqueeze(0)\n      unsqueeze_4 = None\n      attn_7 = attn_6 + unsqueeze_5\n      attn_6 = None\n      unsqueeze_5 = None\n      attn_8 = attn_7.view(-1, 3, 49, 49)\n      attn_7 = None\n      attn_9 = torch.nn.functional.softmax(attn_8, dim=-1)\n      attn_8 = None\n      attn_10 = torch.nn.functional.dropout(attn_9, p=0.0, training=True)\n      attn_9 = None\n      matmul_3 = attn_10.matmul(v_1)\n      attn_10 = None\n      v_1 = None\n      transpose_3 = matmul_3.transpose(1, 2)\n      matmul_3 = None\n      x_15 = transpose_3.reshape(64, 49, 96)\n      transpose_3 = None\n      x_16 = torch._C._nn.linear(x_15,\n          getattr_getattr_l__self___features___1_____1___attn_proj_weight,\n          getattr_getattr_l__self___features___1_____1___attn_proj_bias)\n      x_15 = None\n      getattr_getattr_l__self___features___1_____1___attn_proj_weight = None\n      getattr_getattr_l__self___features___1_____1___attn_proj_bias = None\n      x_17 = torch.nn.functional.dropout(x_16, p=0.0, training=True)\n      x_16 = None\n      x_18 = x_17.view(1, 8, 8, 7, 7, 96)\n      x_17 = None\n      permute_9 = x_18.permute(0, 1, 3, 2, 4, 5)\n      x_18 = None\n      x_19 = permute_9.reshape(1, 56, 56, 96)\n      permute_9 = None\n      x_20 = torch.roll(x_19, shifts=(3, 3), dims=(1, 2))\n      x_19 = None\n      getitem_9 = x_20[slice(None, None, None), slice(None, 56, None), slice(None,\n          56, None), slice(None, None, None)]\n      x_20 = None\n      x_21 = getitem_9.contiguous()\n      getitem_9 = None\n      _log_api_usage_once_2 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      __temp_2601 = []\n      __temp_2601.extend((1, 1, 1, 1))\n      noise = torch.empty(__temp_2601, dtype=torch.float32, device=device(type='cpu')\n          )\n      noise_1 = noise.bernoulli_(0.9818181818181818)\n      noise = None\n      div_ = noise_1.div_(0.9818181818181818)\n      mul_2 = x_21 * noise_1\n      x_21 = None\n      noise_1 = None\n      x_22 = x_10 + mul_2\n      x_10 = None\n      mul_2 = None\n      getattr_getattr_l__self___features___1_____1___norm2 = (self.\n          getattr_getattr_L__self___features___1_____1___norm2(x_22))\n      getattr_getattr_l__self___features___1_____1___mlp_0 = (self.\n          getattr_getattr_L__self___features___1_____1___mlp_0(\n          getattr_getattr_l__self___features___1_____1___norm2))\n      getattr_getattr_l__self___features___1_____1___norm2 = None\n      getattr_getattr_l__self___features___1_____1___mlp_1 = (self.\n          getattr_getattr_L__self___features___1_____1___mlp_1(\n          getattr_getattr_l__self___features___1_____1___mlp_0))\n      getattr_getattr_l__self___features___1_____1___mlp_0 = None\n      getattr_getattr_l__self___features___1_____1___mlp_2 = (self.\n          getattr_getattr_L__self___features___1_____1___mlp_2(\n          getattr_getattr_l__self___features___1_____1___mlp_1))\n      getattr_getattr_l__self___features___1_____1___mlp_1 = None\n      getattr_getattr_l__self___features___1_____1___mlp_3 = (self.\n          getattr_getattr_L__self___features___1_____1___mlp_3(\n          getattr_getattr_l__self___features___1_____1___mlp_2))\n      getattr_getattr_l__self___features___1_____1___mlp_2 = None\n      getattr_getattr_l__self___features___1_____1___mlp_4 = (self.\n          getattr_getattr_L__self___features___1_____1___mlp_4(\n          getattr_getattr_l__self___features___1_____1___mlp_3))\n      getattr_getattr_l__self___features___1_____1___mlp_3 = None\n      _log_api_usage_once_3 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      __temp_2614 = []\n      __temp_2614.extend((1, 1, 1, 1))\n      noise_2 = torch.empty(__temp_2614, dtype=torch.float32, device=device(type=\n          'cpu'))\n      noise_3 = noise_2.bernoulli_(0.9818181818181818)\n      noise_2 = None\n      div__1 = noise_3.div_(0.9818181818181818)\n      mul_3 = getattr_getattr_l__self___features___1_____1___mlp_4 * noise_3\n      getattr_getattr_l__self___features___1_____1___mlp_4 = None\n      noise_3 = None\n      x_23 = x_22 + mul_3\n      x_22 = None\n      mul_3 = None\n      x_24 = torch.nn.functional.pad(x_23, (0, 0, 0, 0, 0, 0))\n      x_23 = None\n      x0 = x_24[Ellipsis, slice(0, None, 2), slice(0, None, 2), slice(None, None,\n          None)]\n      x1 = x_24[Ellipsis, slice(1, None, 2), slice(0, None, 2), slice(None, None,\n          None)]\n      x2 = x_24[Ellipsis, slice(0, None, 2), slice(1, None, 2), slice(None, None,\n          None)]\n      x3 = x_24[Ellipsis, slice(1, None, 2), slice(1, None, 2), slice(None, None,\n          None)]\n      x_24 = None\n      x_26 = torch.cat([x0, x1, x2, x3], -1)\n      x0 = None\n      x1 = None\n      x2 = None\n      x3 = None\n      x_27 = self.getattr_L__self___features___2___norm(x_26)\n      x_26 = None\n      x_28 = self.getattr_L__self___features___2___reduction(x_27)\n      x_27 = None\n      getattr_getattr_l__self___features___3_____0___norm1 = (self.\n          getattr_getattr_L__self___features___3_____0___norm1(x_28))\n      (\n          getattr_getattr_l__self___features___3_____0___attn_relative_position_bias_table\n          ) = (self.\n          getattr_getattr_L__self___features___3_____0___attn_relative_position_bias_table\n          )\n      (getattr_getattr_l__self___features___3_____0___attn_relative_position_index\n          ) = (self.\n          getattr_getattr_L__self___features___3_____0___attn_relative_position_index\n          )\n      relative_position_bias_8 = (\n          getattr_getattr_l__self___features___3_____0___attn_relative_position_bias_table\n          [\n          getattr_getattr_l__self___features___3_____0___attn_relative_position_index\n          ])\n      (\n          getattr_getattr_l__self___features___3_____0___attn_relative_position_bias_table\n          ) = None\n      (getattr_getattr_l__self___features___3_____0___attn_relative_position_index\n          ) = None\n      relative_position_bias_9 = relative_position_bias_8.view(49, 49, -1)\n      relative_position_bias_8 = None\n      permute_10 = relative_position_bias_9.permute(2, 0, 1)\n      relative_position_bias_9 = None\n      contiguous_4 = permute_10.contiguous()\n      permute_10 = None\n      relative_position_bias_11 = contiguous_4.unsqueeze(0)\n      contiguous_4 = None\n      getattr_getattr_l__self___features___3_____0___attn_qkv_weight = (self.\n          getattr_getattr_L__self___features___3_____0___attn_qkv_weight)\n      getattr_getattr_l__self___features___3_____0___attn_proj_weight = (self.\n          getattr_getattr_L__self___features___3_____0___attn_proj_weight)\n      getattr_getattr_l__self___features___3_____0___attn_qkv_bias = (self.\n          getattr_getattr_L__self___features___3_____0___attn_qkv_bias)\n      getattr_getattr_l__self___features___3_____0___attn_proj_bias = (self.\n          getattr_getattr_L__self___features___3_____0___attn_proj_bias)\n      x_29 = torch.nn.functional.pad(\n          getattr_getattr_l__self___features___3_____0___norm1, (0, 0, 0, 0, 0, 0))\n      getattr_getattr_l__self___features___3_____0___norm1 = None\n      x_30 = x_29.view(1, 4, 7, 4, 7, 192)\n      x_29 = None\n      permute_11 = x_30.permute(0, 1, 3, 2, 4, 5)\n      x_30 = None\n      x_31 = permute_11.reshape(16, 49, 192)\n      permute_11 = None\n      qkv_4 = torch._C._nn.linear(x_31,\n          getattr_getattr_l__self___features___3_____0___attn_qkv_weight,\n          getattr_getattr_l__self___features___3_____0___attn_qkv_bias)\n      x_31 = None\n      getattr_getattr_l__self___features___3_____0___attn_qkv_weight = None\n      getattr_getattr_l__self___features___3_____0___attn_qkv_bias = None\n      reshape_10 = qkv_4.reshape(16, 49, 3, 6, 32)\n      qkv_4 = None\n      qkv_5 = reshape_10.permute(2, 0, 3, 1, 4)\n      reshape_10 = None\n      q_4 = qkv_5[0]\n      k_2 = qkv_5[1]\n      v_2 = qkv_5[2]\n      qkv_5 = None\n      q_5 = q_4 * 0.1767766952966369\n      q_4 = None\n      transpose_4 = k_2.transpose(-2, -1)\n      k_2 = None\n      attn_11 = q_5.matmul(transpose_4)\n      q_5 = None\n      transpose_4 = None\n      attn_12 = attn_11 + relative_position_bias_11\n      attn_11 = None\n      relative_position_bias_11 = None\n      attn_13 = torch.nn.functional.softmax(attn_12, dim=-1)\n      attn_12 = None\n      attn_14 = torch.nn.functional.dropout(attn_13, p=0.0, training=True)\n      attn_13 = None\n      matmul_5 = attn_14.matmul(v_2)\n      attn_14 = None\n      v_2 = None\n      transpose_5 = matmul_5.transpose(1, 2)\n      matmul_5 = None\n      x_32 = transpose_5.reshape(16, 49, 192)\n      transpose_5 = None\n      x_33 = torch._C._nn.linear(x_32,\n          getattr_getattr_l__self___features___3_____0___attn_proj_weight,\n          getattr_getattr_l__self___features___3_____0___attn_proj_bias)\n      x_32 = None\n      getattr_getattr_l__self___features___3_____0___attn_proj_weight = None\n      getattr_getattr_l__self___features___3_____0___attn_proj_bias = None\n      x_34 = torch.nn.functional.dropout(x_33, p=0.0, training=True)\n      x_33 = None\n      x_35 = x_34.view(1, 4, 4, 7, 7, 192)\n      x_34 = None\n      permute_13 = x_35.permute(0, 1, 3, 2, 4, 5)\n      x_35 = None\n      x_36 = permute_13.reshape(1, 28, 28, 192)\n      permute_13 = None\n      getitem_18 = x_36[slice(None, None, None), slice(None, 28, None), slice(\n          None, 28, None), slice(None, None, None)]\n      x_36 = None\n      x_37 = getitem_18.contiguous()\n      getitem_18 = None\n      _log_api_usage_once_4 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      __temp_2667 = []\n      __temp_2667.extend((1, 1, 1, 1))\n      noise_4 = torch.empty(__temp_2667, dtype=torch.float32, device=device(type=\n          'cpu'))\n      noise_5 = noise_4.bernoulli_(0.9636363636363636)\n      noise_4 = None\n      div__2 = noise_5.div_(0.9636363636363636)\n      mul_5 = x_37 * noise_5\n      x_37 = None\n      noise_5 = None\n      x_38 = x_28 + mul_5\n      x_28 = None\n      mul_5 = None\n      getattr_getattr_l__self___features___3_____0___norm2 = (self.\n          getattr_getattr_L__self___features___3_____0___norm2(x_38))\n      getattr_getattr_l__self___features___3_____0___mlp_0 = (self.\n          getattr_getattr_L__self___features___3_____0___mlp_0(\n          getattr_getattr_l__self___features___3_____0___norm2))\n      getattr_getattr_l__self___features___3_____0___norm2 = None\n      getattr_getattr_l__self___features___3_____0___mlp_1 = (self.\n          getattr_getattr_L__self___features___3_____0___mlp_1(\n          getattr_getattr_l__self___features___3_____0___mlp_0))\n      getattr_getattr_l__self___features___3_____0___mlp_0 = None\n      getattr_getattr_l__self___features___3_____0___mlp_2 = (self.\n          getattr_getattr_L__self___features___3_____0___mlp_2(\n          getattr_getattr_l__self___features___3_____0___mlp_1))\n      getattr_getattr_l__self___features___3_____0___mlp_1 = None\n      getattr_getattr_l__self___features___3_____0___mlp_3 = (self.\n          getattr_getattr_L__self___features___3_____0___mlp_3(\n          getattr_getattr_l__self___features___3_____0___mlp_2))\n      getattr_getattr_l__self___features___3_____0___mlp_2 = None\n      getattr_getattr_l__self___features___3_____0___mlp_4 = (self.\n          getattr_getattr_L__self___features___3_____0___mlp_4(\n          getattr_getattr_l__self___features___3_____0___mlp_3))\n      getattr_getattr_l__self___features___3_____0___mlp_3 = None\n      _log_api_usage_once_5 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      __temp_2680 = []\n      __temp_2680.extend((1, 1, 1, 1))\n      noise_6 = torch.empty(__temp_2680, dtype=torch.float32, device=device(type=\n          'cpu'))\n      noise_7 = noise_6.bernoulli_(0.9636363636363636)\n      noise_6 = None\n      div__3 = noise_7.div_(0.9636363636363636)\n      mul_6 = getattr_getattr_l__self___features___3_____0___mlp_4 * noise_7\n      getattr_getattr_l__self___features___3_____0___mlp_4 = None\n      noise_7 = None\n      x_39 = x_38 + mul_6\n      x_38 = None\n      mul_6 = None\n      getattr_getattr_l__self___features___3_____1___norm1 = (self.\n          getattr_getattr_L__self___features___3_____1___norm1(x_39))\n      (\n          getattr_getattr_l__self___features___3_____1___attn_relative_position_bias_table\n          ) = (self.\n          getattr_getattr_L__self___features___3_____1___attn_relative_position_bias_table\n          )\n      (getattr_getattr_l__self___features___3_____1___attn_relative_position_index\n          ) = (self.\n          getattr_getattr_L__self___features___3_____1___attn_relative_position_index\n          )\n      relative_position_bias_12 = (\n          getattr_getattr_l__self___features___3_____1___attn_relative_position_bias_table\n          [\n          getattr_getattr_l__self___features___3_____1___attn_relative_position_index\n          ])\n      (\n          getattr_getattr_l__self___features___3_____1___attn_relative_position_bias_table\n          ) = None\n      (getattr_getattr_l__self___features___3_____1___attn_relative_position_index\n          ) = None\n      relative_position_bias_13 = relative_position_bias_12.view(49, 49, -1)\n      relative_position_bias_12 = None\n      permute_14 = relative_position_bias_13.permute(2, 0, 1)\n      relative_position_bias_13 = None\n      contiguous_6 = permute_14.contiguous()\n      permute_14 = None\n      relative_position_bias_15 = contiguous_6.unsqueeze(0)\n      contiguous_6 = None\n      getattr_getattr_l__self___features___3_____1___attn_qkv_weight = (self.\n          getattr_getattr_L__self___features___3_____1___attn_qkv_weight)\n      getattr_getattr_l__self___features___3_____1___attn_proj_weight = (self.\n          getattr_getattr_L__self___features___3_____1___attn_proj_weight)\n      getattr_getattr_l__self___features___3_____1___attn_qkv_bias = (self.\n          getattr_getattr_L__self___features___3_____1___attn_qkv_bias)\n      getattr_getattr_l__self___features___3_____1___attn_proj_bias = (self.\n          getattr_getattr_L__self___features___3_____1___attn_proj_bias)\n      x_40 = torch.nn.functional.pad(\n          getattr_getattr_l__self___features___3_____1___norm1, (0, 0, 0, 0, 0, 0))\n      getattr_getattr_l__self___features___3_____1___norm1 = None\n      x_41 = torch.roll(x_40, shifts=(-3, -3), dims=(1, 2))\n      x_40 = None\n      x_42 = x_41.view(1, 4, 7, 4, 7, 192)\n      x_41 = None\n      permute_15 = x_42.permute(0, 1, 3, 2, 4, 5)\n      x_42 = None\n      x_43 = permute_15.reshape(16, 49, 192)\n      permute_15 = None\n      qkv_6 = torch._C._nn.linear(x_43,\n          getattr_getattr_l__self___features___3_____1___attn_qkv_weight,\n          getattr_getattr_l__self___features___3_____1___attn_qkv_bias)\n      getattr_getattr_l__self___features___3_____1___attn_qkv_weight = None\n      getattr_getattr_l__self___features___3_____1___attn_qkv_bias = None\n      reshape_14 = qkv_6.reshape(16, 49, 3, 6, 32)\n      qkv_6 = None\n      qkv_7 = reshape_14.permute(2, 0, 3, 1, 4)\n      reshape_14 = None\n      q_6 = qkv_7[0]\n      k_3 = qkv_7[1]\n      v_3 = qkv_7[2]\n      qkv_7 = None\n      q_7 = q_6 * 0.1767766952966369\n      q_6 = None\n      transpose_6 = k_3.transpose(-2, -1)\n      k_3 = None\n      attn_15 = q_7.matmul(transpose_6)\n      q_7 = None\n      transpose_6 = None\n      attn_16 = attn_15 + relative_position_bias_15\n      attn_15 = None\n      relative_position_bias_15 = None\n      attn_mask_5 = x_43.new_zeros((28, 28))\n      x_43 = None\n      attn_mask_5[slice(0, -7, None), slice(0, -7, None)] = 0\n      setitem_9 = attn_mask_5\n      attn_mask_5[slice(0, -7, None), slice(-7, -3, None)] = 1\n      setitem_10 = attn_mask_5\n      attn_mask_5[slice(0, -7, None), slice(-3, None, None)] = 2\n      setitem_11 = attn_mask_5\n      attn_mask_5[slice(-7, -3, None), slice(0, -7, None)] = 3\n      setitem_12 = attn_mask_5\n      attn_mask_5[slice(-7, -3, None), slice(-7, -3, None)] = 4\n      setitem_13 = attn_mask_5\n      attn_mask_5[slice(-7, -3, None), slice(-3, None, None)] = 5\n      setitem_14 = attn_mask_5\n      attn_mask_5[slice(-3, None, None), slice(0, -7, None)] = 6\n      setitem_15 = attn_mask_5\n      attn_mask_5[slice(-3, None, None), slice(-7, -3, None)] = 7\n      setitem_16 = attn_mask_5\n      attn_mask_5[slice(-3, None, None), slice(-3, None, None)] = 8\n      setitem_17 = attn_mask_5\n      attn_mask_6 = attn_mask_5.view(4, 7, 4, 7)\n      attn_mask_5 = None\n      permute_17 = attn_mask_6.permute(0, 2, 1, 3)\n      attn_mask_6 = None\n      attn_mask_7 = permute_17.reshape(16, 49)\n      permute_17 = None\n      unsqueeze_8 = attn_mask_7.unsqueeze(1)\n      unsqueeze_9 = attn_mask_7.unsqueeze(2)\n      attn_mask_7 = None\n      attn_mask_8 = unsqueeze_8 - unsqueeze_9\n      unsqueeze_8 = None\n      unsqueeze_9 = None\n      ne_1 = attn_mask_8 != 0\n      masked_fill_2 = attn_mask_8.masked_fill(ne_1, -100.0)\n      ne_1 = None\n      eq_1 = attn_mask_8 == 0\n      attn_mask_8 = None\n      attn_mask_9 = masked_fill_2.masked_fill(eq_1, 0.0)\n      masked_fill_2 = None\n      eq_1 = None\n      attn_17 = attn_16.view(1, 16, 6, 49, 49)\n      attn_16 = None\n      unsqueeze_10 = attn_mask_9.unsqueeze(1)\n      attn_mask_9 = None\n      unsqueeze_11 = unsqueeze_10.unsqueeze(0)\n      unsqueeze_10 = None\n      attn_18 = attn_17 + unsqueeze_11\n      attn_17 = None\n      unsqueeze_11 = None\n      attn_19 = attn_18.view(-1, 6, 49, 49)\n      attn_18 = None\n      attn_20 = torch.nn.functional.softmax(attn_19, dim=-1)\n      attn_19 = None\n      attn_21 = torch.nn.functional.dropout(attn_20, p=0.0, training=True)\n      attn_20 = None\n      matmul_7 = attn_21.matmul(v_3)\n      attn_21 = None\n      v_3 = None\n      transpose_7 = matmul_7.transpose(1, 2)\n      matmul_7 = None\n      x_44 = transpose_7.reshape(16, 49, 192)\n      transpose_7 = None\n      x_45 = torch._C._nn.linear(x_44,\n          getattr_getattr_l__self___features___3_____1___attn_proj_weight,\n          getattr_getattr_l__self___features___3_____1___attn_proj_bias)\n      x_44 = None\n      getattr_getattr_l__self___features___3_____1___attn_proj_weight = None\n      getattr_getattr_l__self___features___3_____1___attn_proj_bias = None\n      x_46 = torch.nn.functional.dropout(x_45, p=0.0, training=True)\n      x_45 = None\n      x_47 = x_46.view(1, 4, 4, 7, 7, 192)\n      x_46 = None\n      permute_18 = x_47.permute(0, 1, 3, 2, 4, 5)\n      x_47 = None\n      x_48 = permute_18.reshape(1, 28, 28, 192)\n      permute_18 = None\n      x_49 = torch.roll(x_48, shifts=(3, 3), dims=(1, 2))\n      x_48 = None\n      getitem_23 = x_49[slice(None, None, None), slice(None, 28, None), slice(\n          None, 28, None), slice(None, None, None)]\n      x_49 = None\n      x_50 = getitem_23.contiguous()\n      getitem_23 = None\n      _log_api_usage_once_6 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      __temp_2748 = []\n      __temp_2748.extend((1, 1, 1, 1))\n      noise_8 = torch.empty(__temp_2748, dtype=torch.float32, device=device(type=\n          'cpu'))\n      noise_9 = noise_8.bernoulli_(0.9454545454545454)\n      noise_8 = None\n      div__4 = noise_9.div_(0.9454545454545454)\n      mul_8 = x_50 * noise_9\n      x_50 = None\n      noise_9 = None\n      x_51 = x_39 + mul_8\n      x_39 = None\n      mul_8 = None\n      getattr_getattr_l__self___features___3_____1___norm2 = (self.\n          getattr_getattr_L__self___features___3_____1___norm2(x_51))\n      getattr_getattr_l__self___features___3_____1___mlp_0 = (self.\n          getattr_getattr_L__self___features___3_____1___mlp_0(\n          getattr_getattr_l__self___features___3_____1___norm2))\n      getattr_getattr_l__self___features___3_____1___norm2 = None\n      getattr_getattr_l__self___features___3_____1___mlp_1 = (self.\n          getattr_getattr_L__self___features___3_____1___mlp_1(\n          getattr_getattr_l__self___features___3_____1___mlp_0))\n      getattr_getattr_l__self___features___3_____1___mlp_0 = None\n      getattr_getattr_l__self___features___3_____1___mlp_2 = (self.\n          getattr_getattr_L__self___features___3_____1___mlp_2(\n          getattr_getattr_l__self___features___3_____1___mlp_1))\n      getattr_getattr_l__self___features___3_____1___mlp_1 = None\n      getattr_getattr_l__self___features___3_____1___mlp_3 = (self.\n          getattr_getattr_L__self___features___3_____1___mlp_3(\n          getattr_getattr_l__self___features___3_____1___mlp_2))\n      getattr_getattr_l__self___features___3_____1___mlp_2 = None\n      getattr_getattr_l__self___features___3_____1___mlp_4 = (self.\n          getattr_getattr_L__self___features___3_____1___mlp_4(\n          getattr_getattr_l__self___features___3_____1___mlp_3))\n      getattr_getattr_l__self___features___3_____1___mlp_3 = None\n      _log_api_usage_once_7 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      __temp_2761 = []\n      __temp_2761.extend((1, 1, 1, 1))\n      noise_10 = torch.empty(__temp_2761, dtype=torch.float32, device=device(type\n          ='cpu'))\n      noise_11 = noise_10.bernoulli_(0.9454545454545454)\n      noise_10 = None\n      div__5 = noise_11.div_(0.9454545454545454)\n      mul_9 = getattr_getattr_l__self___features___3_____1___mlp_4 * noise_11\n      getattr_getattr_l__self___features___3_____1___mlp_4 = None\n      noise_11 = None\n      x_52 = x_51 + mul_9\n      x_51 = None\n      mul_9 = None\n      x_53 = torch.nn.functional.pad(x_52, (0, 0, 0, 0, 0, 0))\n      x_52 = None\n      x0_1 = x_53[Ellipsis, slice(0, None, 2), slice(0, None, 2), slice(None,\n          None, None)]\n      x1_1 = x_53[Ellipsis, slice(1, None, 2), slice(0, None, 2), slice(None,\n          None, None)]\n      x2_1 = x_53[Ellipsis, slice(0, None, 2), slice(1, None, 2), slice(None,\n          None, None)]\n      x3_1 = x_53[Ellipsis, slice(1, None, 2), slice(1, None, 2), slice(None,\n          None, None)]\n      x_53 = None\n      x_55 = torch.cat([x0_1, x1_1, x2_1, x3_1], -1)\n      x0_1 = None\n      x1_1 = None\n      x2_1 = None\n      x3_1 = None\n      x_56 = self.getattr_L__self___features___4___norm(x_55)\n      x_55 = None\n      x_57 = self.getattr_L__self___features___4___reduction(x_56)\n      x_56 = None\n      getattr_getattr_l__self___features___5_____0___norm1 = (self.\n          getattr_getattr_L__self___features___5_____0___norm1(x_57))\n      (\n          getattr_getattr_l__self___features___5_____0___attn_relative_position_bias_table\n          ) = (self.\n          getattr_getattr_L__self___features___5_____0___attn_relative_position_bias_table\n          )\n      (getattr_getattr_l__self___features___5_____0___attn_relative_position_index\n          ) = (self.\n          getattr_getattr_L__self___features___5_____0___attn_relative_position_index\n          )\n      relative_position_bias_16 = (\n          getattr_getattr_l__self___features___5_____0___attn_relative_position_bias_table\n          [\n          getattr_getattr_l__self___features___5_____0___attn_relative_position_index\n          ])\n      (\n          getattr_getattr_l__self___features___5_____0___attn_relative_position_bias_table\n          ) = None\n      (getattr_getattr_l__self___features___5_____0___attn_relative_position_index\n          ) = None\n      relative_position_bias_17 = relative_position_bias_16.view(49, 49, -1)\n      relative_position_bias_16 = None\n      permute_19 = relative_position_bias_17.permute(2, 0, 1)\n      relative_position_bias_17 = None\n      contiguous_8 = permute_19.contiguous()\n      permute_19 = None\n      relative_position_bias_19 = contiguous_8.unsqueeze(0)\n      contiguous_8 = None\n      getattr_getattr_l__self___features___5_____0___attn_qkv_weight = (self.\n          getattr_getattr_L__self___features___5_____0___attn_qkv_weight)\n      getattr_getattr_l__self___features___5_____0___attn_proj_weight = (self.\n          getattr_getattr_L__self___features___5_____0___attn_proj_weight)\n      getattr_getattr_l__self___features___5_____0___attn_qkv_bias = (self.\n          getattr_getattr_L__self___features___5_____0___attn_qkv_bias)\n      getattr_getattr_l__self___features___5_____0___attn_proj_bias = (self.\n          getattr_getattr_L__self___features___5_____0___attn_proj_bias)\n      x_58 = torch.nn.functional.pad(\n          getattr_getattr_l__self___features___5_____0___norm1, (0, 0, 0, 0, 0, 0))\n      getattr_getattr_l__self___features___5_____0___norm1 = None\n      x_59 = x_58.view(1, 2, 7, 2, 7, 384)\n      x_58 = None\n      permute_20 = x_59.permute(0, 1, 3, 2, 4, 5)\n      x_59 = None\n      x_60 = permute_20.reshape(4, 49, 384)\n      permute_20 = None\n      qkv_8 = torch._C._nn.linear(x_60,\n          getattr_getattr_l__self___features___5_____0___attn_qkv_weight,\n          getattr_getattr_l__self___features___5_____0___attn_qkv_bias)\n      x_60 = None\n      getattr_getattr_l__self___features___5_____0___attn_qkv_weight = None\n      getattr_getattr_l__self___features___5_____0___attn_qkv_bias = None\n      reshape_19 = qkv_8.reshape(4, 49, 3, 12, 32)\n      qkv_8 = None\n      qkv_9 = reshape_19.permute(2, 0, 3, 1, 4)\n      reshape_19 = None\n      q_8 = qkv_9[0]\n      k_4 = qkv_9[1]\n      v_4 = qkv_9[2]\n      qkv_9 = None\n      q_9 = q_8 * 0.1767766952966369\n      q_8 = None\n      transpose_8 = k_4.transpose(-2, -1)\n      k_4 = None\n      attn_22 = q_9.matmul(transpose_8)\n      q_9 = None\n      transpose_8 = None\n      attn_23 = attn_22 + relative_position_bias_19\n      attn_22 = None\n      relative_position_bias_19 = None\n      attn_24 = torch.nn.functional.softmax(attn_23, dim=-1)\n      attn_23 = None\n      attn_25 = torch.nn.functional.dropout(attn_24, p=0.0, training=True)\n      attn_24 = None\n      matmul_9 = attn_25.matmul(v_4)\n      attn_25 = None\n      v_4 = None\n      transpose_9 = matmul_9.transpose(1, 2)\n      matmul_9 = None\n      x_61 = transpose_9.reshape(4, 49, 384)\n      transpose_9 = None\n      x_62 = torch._C._nn.linear(x_61,\n          getattr_getattr_l__self___features___5_____0___attn_proj_weight,\n          getattr_getattr_l__self___features___5_____0___attn_proj_bias)\n      x_61 = None\n      getattr_getattr_l__self___features___5_____0___attn_proj_weight = None\n      getattr_getattr_l__self___features___5_____0___attn_proj_bias = None\n      x_63 = torch.nn.functional.dropout(x_62, p=0.0, training=True)\n      x_62 = None\n      x_64 = x_63.view(1, 2, 2, 7, 7, 384)\n      x_63 = None\n      permute_22 = x_64.permute(0, 1, 3, 2, 4, 5)\n      x_64 = None\n      x_65 = permute_22.reshape(1, 14, 14, 384)\n      permute_22 = None\n      getitem_32 = x_65[slice(None, None, None), slice(None, 14, None), slice(\n          None, 14, None), slice(None, None, None)]\n      x_65 = None\n      x_66 = getitem_32.contiguous()\n      getitem_32 = None\n      _log_api_usage_once_8 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      __temp_2814 = []\n      __temp_2814.extend((1, 1, 1, 1))\n      noise_12 = torch.empty(__temp_2814, dtype=torch.float32, device=device(type\n          ='cpu'))\n      noise_13 = noise_12.bernoulli_(0.9272727272727272)\n      noise_12 = None\n      div__6 = noise_13.div_(0.9272727272727272)\n      mul_11 = x_66 * noise_13\n      x_66 = None\n      noise_13 = None\n      x_67 = x_57 + mul_11\n      x_57 = None\n      mul_11 = None\n      getattr_getattr_l__self___features___5_____0___norm2 = (self.\n          getattr_getattr_L__self___features___5_____0___norm2(x_67))\n      getattr_getattr_l__self___features___5_____0___mlp_0 = (self.\n          getattr_getattr_L__self___features___5_____0___mlp_0(\n          getattr_getattr_l__self___features___5_____0___norm2))\n      getattr_getattr_l__self___features___5_____0___norm2 = None\n      getattr_getattr_l__self___features___5_____0___mlp_1 = (self.\n          getattr_getattr_L__self___features___5_____0___mlp_1(\n          getattr_getattr_l__self___features___5_____0___mlp_0))\n      getattr_getattr_l__self___features___5_____0___mlp_0 = None\n      getattr_getattr_l__self___features___5_____0___mlp_2 = (self.\n          getattr_getattr_L__self___features___5_____0___mlp_2(\n          getattr_getattr_l__self___features___5_____0___mlp_1))\n      getattr_getattr_l__self___features___5_____0___mlp_1 = None\n      getattr_getattr_l__self___features___5_____0___mlp_3 = (self.\n          getattr_getattr_L__self___features___5_____0___mlp_3(\n          getattr_getattr_l__self___features___5_____0___mlp_2))\n      getattr_getattr_l__self___features___5_____0___mlp_2 = None\n      getattr_getattr_l__self___features___5_____0___mlp_4 = (self.\n          getattr_getattr_L__self___features___5_____0___mlp_4(\n          getattr_getattr_l__self___features___5_____0___mlp_3))\n      getattr_getattr_l__self___features___5_____0___mlp_3 = None\n      _log_api_usage_once_9 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      __temp_2827 = []\n      __temp_2827.extend((1, 1, 1, 1))\n      noise_14 = torch.empty(__temp_2827, dtype=torch.float32, device=device(type\n          ='cpu'))\n      noise_15 = noise_14.bernoulli_(0.9272727272727272)\n      noise_14 = None\n      div__7 = noise_15.div_(0.9272727272727272)\n      mul_12 = getattr_getattr_l__self___features___5_____0___mlp_4 * noise_15\n      getattr_getattr_l__self___features___5_____0___mlp_4 = None\n      noise_15 = None\n      x_68 = x_67 + mul_12\n      x_67 = None\n      mul_12 = None\n      getattr_getattr_l__self___features___5_____1___norm1 = (self.\n          getattr_getattr_L__self___features___5_____1___norm1(x_68))\n      (\n          getattr_getattr_l__self___features___5_____1___attn_relative_position_bias_table\n          ) = (self.\n          getattr_getattr_L__self___features___5_____1___attn_relative_position_bias_table\n          )\n      (getattr_getattr_l__self___features___5_____1___attn_relative_position_index\n          ) = (self.\n          getattr_getattr_L__self___features___5_____1___attn_relative_position_index\n          )\n      relative_position_bias_20 = (\n          getattr_getattr_l__self___features___5_____1___attn_relative_position_bias_table\n          [\n          getattr_getattr_l__self___features___5_____1___attn_relative_position_index\n          ])\n      (\n          getattr_getattr_l__self___features___5_____1___attn_relative_position_bias_table\n          ) = None\n      (getattr_getattr_l__self___features___5_____1___attn_relative_position_index\n          ) = None\n      relative_position_bias_21 = relative_position_bias_20.view(49, 49, -1)\n      relative_position_bias_20 = None\n      permute_23 = relative_position_bias_21.permute(2, 0, 1)\n      relative_position_bias_21 = None\n      contiguous_10 = permute_23.contiguous()\n      permute_23 = None\n      relative_position_bias_23 = contiguous_10.unsqueeze(0)\n      contiguous_10 = None\n      getattr_getattr_l__self___features___5_____1___attn_qkv_weight = (self.\n          getattr_getattr_L__self___features___5_____1___attn_qkv_weight)\n      getattr_getattr_l__self___features___5_____1___attn_proj_weight = (self.\n          getattr_getattr_L__self___features___5_____1___attn_proj_weight)\n      getattr_getattr_l__self___features___5_____1___attn_qkv_bias = (self.\n          getattr_getattr_L__self___features___5_____1___attn_qkv_bias)\n      getattr_getattr_l__self___features___5_____1___attn_proj_bias = (self.\n          getattr_getattr_L__self___features___5_____1___attn_proj_bias)\n      x_69 = torch.nn.functional.pad(\n          getattr_getattr_l__self___features___5_____1___norm1, (0, 0, 0, 0, 0, 0))\n      getattr_getattr_l__self___features___5_____1___norm1 = None\n      x_70 = torch.roll(x_69, shifts=(-3, -3), dims=(1, 2))\n      x_69 = None\n      x_71 = x_70.view(1, 2, 7, 2, 7, 384)\n      x_70 = None\n      permute_24 = x_71.permute(0, 1, 3, 2, 4, 5)\n      x_71 = None\n      x_72 = permute_24.reshape(4, 49, 384)\n      permute_24 = None\n      qkv_10 = torch._C._nn.linear(x_72,\n          getattr_getattr_l__self___features___5_____1___attn_qkv_weight,\n          getattr_getattr_l__self___features___5_____1___attn_qkv_bias)\n      getattr_getattr_l__self___features___5_____1___attn_qkv_weight = None\n      getattr_getattr_l__self___features___5_____1___attn_qkv_bias = None\n      reshape_23 = qkv_10.reshape(4, 49, 3, 12, 32)\n      qkv_10 = None\n      qkv_11 = reshape_23.permute(2, 0, 3, 1, 4)\n      reshape_23 = None\n      q_10 = qkv_11[0]\n      k_5 = qkv_11[1]\n      v_5 = qkv_11[2]\n      qkv_11 = None\n      q_11 = q_10 * 0.1767766952966369\n      q_10 = None\n      transpose_10 = k_5.transpose(-2, -1)\n      k_5 = None\n      attn_26 = q_11.matmul(transpose_10)\n      q_11 = None\n      transpose_10 = None\n      attn_27 = attn_26 + relative_position_bias_23\n      attn_26 = None\n      relative_position_bias_23 = None\n      attn_mask_10 = x_72.new_zeros((14, 14))\n      x_72 = None\n      attn_mask_10[slice(0, -7, None), slice(0, -7, None)] = 0\n      setitem_18 = attn_mask_10\n      attn_mask_10[slice(0, -7, None), slice(-7, -3, None)] = 1\n      setitem_19 = attn_mask_10\n      attn_mask_10[slice(0, -7, None), slice(-3, None, None)] = 2\n      setitem_20 = attn_mask_10\n      attn_mask_10[slice(-7, -3, None), slice(0, -7, None)] = 3\n      setitem_21 = attn_mask_10\n      attn_mask_10[slice(-7, -3, None), slice(-7, -3, None)] = 4\n      setitem_22 = attn_mask_10\n      attn_mask_10[slice(-7, -3, None), slice(-3, None, None)] = 5\n      setitem_23 = attn_mask_10\n      attn_mask_10[slice(-3, None, None), slice(0, -7, None)] = 6\n      setitem_24 = attn_mask_10\n      attn_mask_10[slice(-3, None, None), slice(-7, -3, None)] = 7\n      setitem_25 = attn_mask_10\n      attn_mask_10[slice(-3, None, None), slice(-3, None, None)] = 8\n      setitem_26 = attn_mask_10\n      attn_mask_11 = attn_mask_10.view(2, 7, 2, 7)\n      attn_mask_10 = None\n      permute_26 = attn_mask_11.permute(0, 2, 1, 3)\n      attn_mask_11 = None\n      attn_mask_12 = permute_26.reshape(4, 49)\n      permute_26 = None\n      unsqueeze_14 = attn_mask_12.unsqueeze(1)\n      unsqueeze_15 = attn_mask_12.unsqueeze(2)\n      attn_mask_12 = None\n      attn_mask_13 = unsqueeze_14 - unsqueeze_15\n      unsqueeze_14 = None\n      unsqueeze_15 = None\n      ne_2 = attn_mask_13 != 0\n      masked_fill_4 = attn_mask_13.masked_fill(ne_2, -100.0)\n      ne_2 = None\n      eq_2 = attn_mask_13 == 0\n      attn_mask_13 = None\n      attn_mask_14 = masked_fill_4.masked_fill(eq_2, 0.0)\n      masked_fill_4 = None\n      eq_2 = None\n      attn_28 = attn_27.view(1, 4, 12, 49, 49)\n      attn_27 = None\n      unsqueeze_16 = attn_mask_14.unsqueeze(1)\n      attn_mask_14 = None\n      unsqueeze_17 = unsqueeze_16.unsqueeze(0)\n      unsqueeze_16 = None\n      attn_29 = attn_28 + unsqueeze_17\n      attn_28 = None\n      unsqueeze_17 = None\n      attn_30 = attn_29.view(-1, 12, 49, 49)\n      attn_29 = None\n      attn_31 = torch.nn.functional.softmax(attn_30, dim=-1)\n      attn_30 = None\n      attn_32 = torch.nn.functional.dropout(attn_31, p=0.0, training=True)\n      attn_31 = None\n      matmul_11 = attn_32.matmul(v_5)\n      attn_32 = None\n      v_5 = None\n      transpose_11 = matmul_11.transpose(1, 2)\n      matmul_11 = None\n      x_73 = transpose_11.reshape(4, 49, 384)\n      transpose_11 = None\n      x_74 = torch._C._nn.linear(x_73,\n          getattr_getattr_l__self___features___5_____1___attn_proj_weight,\n          getattr_getattr_l__self___features___5_____1___attn_proj_bias)\n      x_73 = None\n      getattr_getattr_l__self___features___5_____1___attn_proj_weight = None\n      getattr_getattr_l__self___features___5_____1___attn_proj_bias = None\n      x_75 = torch.nn.functional.dropout(x_74, p=0.0, training=True)\n      x_74 = None\n      x_76 = x_75.view(1, 2, 2, 7, 7, 384)\n      x_75 = None\n      permute_27 = x_76.permute(0, 1, 3, 2, 4, 5)\n      x_76 = None\n      x_77 = permute_27.reshape(1, 14, 14, 384)\n      permute_27 = None\n      x_78 = torch.roll(x_77, shifts=(3, 3), dims=(1, 2))\n      x_77 = None\n      getitem_37 = x_78[slice(None, None, None), slice(None, 14, None), slice(\n          None, 14, None), slice(None, None, None)]\n      x_78 = None\n      x_79 = getitem_37.contiguous()\n      getitem_37 = None\n      _log_api_usage_once_10 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      __temp_2895 = []\n      __temp_2895.extend((1, 1, 1, 1))\n      noise_16 = torch.empty(__temp_2895, dtype=torch.float32, device=device(type\n          ='cpu'))\n      noise_17 = noise_16.bernoulli_(0.9090909090909091)\n      noise_16 = None\n      div__8 = noise_17.div_(0.9090909090909091)\n      mul_14 = x_79 * noise_17\n      x_79 = None\n      noise_17 = None\n      x_80 = x_68 + mul_14\n      x_68 = None\n      mul_14 = None\n      getattr_getattr_l__self___features___5_____1___norm2 = (self.\n          getattr_getattr_L__self___features___5_____1___norm2(x_80))\n      getattr_getattr_l__self___features___5_____1___mlp_0 = (self.\n          getattr_getattr_L__self___features___5_____1___mlp_0(\n          getattr_getattr_l__self___features___5_____1___norm2))\n      getattr_getattr_l__self___features___5_____1___norm2 = None\n      getattr_getattr_l__self___features___5_____1___mlp_1 = (self.\n          getattr_getattr_L__self___features___5_____1___mlp_1(\n          getattr_getattr_l__self___features___5_____1___mlp_0))\n      getattr_getattr_l__self___features___5_____1___mlp_0 = None\n      getattr_getattr_l__self___features___5_____1___mlp_2 = (self.\n          getattr_getattr_L__self___features___5_____1___mlp_2(\n          getattr_getattr_l__self___features___5_____1___mlp_1))\n      getattr_getattr_l__self___features___5_____1___mlp_1 = None\n      getattr_getattr_l__self___features___5_____1___mlp_3 = (self.\n          getattr_getattr_L__self___features___5_____1___mlp_3(\n          getattr_getattr_l__self___features___5_____1___mlp_2))\n      getattr_getattr_l__self___features___5_____1___mlp_2 = None\n      getattr_getattr_l__self___features___5_____1___mlp_4 = (self.\n          getattr_getattr_L__self___features___5_____1___mlp_4(\n          getattr_getattr_l__self___features___5_____1___mlp_3))\n      getattr_getattr_l__self___features___5_____1___mlp_3 = None\n      _log_api_usage_once_11 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      __temp_2908 = []\n      __temp_2908.extend((1, 1, 1, 1))\n      noise_18 = torch.empty(__temp_2908, dtype=torch.float32, device=device(type\n          ='cpu'))\n      noise_19 = noise_18.bernoulli_(0.9090909090909091)\n      noise_18 = None\n      div__9 = noise_19.div_(0.9090909090909091)\n      mul_15 = getattr_getattr_l__self___features___5_____1___mlp_4 * noise_19\n      getattr_getattr_l__self___features___5_____1___mlp_4 = None\n      noise_19 = None\n      x_81 = x_80 + mul_15\n      x_80 = None\n      mul_15 = None\n      getattr_getattr_l__self___features___5_____2___norm1 = (self.\n          getattr_getattr_L__self___features___5_____2___norm1(x_81))\n      (\n          getattr_getattr_l__self___features___5_____2___attn_relative_position_bias_table\n          ) = (self.\n          getattr_getattr_L__self___features___5_____2___attn_relative_position_bias_table\n          )\n      (getattr_getattr_l__self___features___5_____2___attn_relative_position_index\n          ) = (self.\n          getattr_getattr_L__self___features___5_____2___attn_relative_position_index\n          )\n      relative_position_bias_24 = (\n          getattr_getattr_l__self___features___5_____2___attn_relative_position_bias_table\n          [\n          getattr_getattr_l__self___features___5_____2___attn_relative_position_index\n          ])\n      (\n          getattr_getattr_l__self___features___5_____2___attn_relative_position_bias_table\n          ) = None\n      (getattr_getattr_l__self___features___5_____2___attn_relative_position_index\n          ) = None\n      relative_position_bias_25 = relative_position_bias_24.view(49, 49, -1)\n      relative_position_bias_24 = None\n      permute_28 = relative_position_bias_25.permute(2, 0, 1)\n      relative_position_bias_25 = None\n      contiguous_12 = permute_28.contiguous()\n      permute_28 = None\n      relative_position_bias_27 = contiguous_12.unsqueeze(0)\n      contiguous_12 = None\n      getattr_getattr_l__self___features___5_____2___attn_qkv_weight = (self.\n          getattr_getattr_L__self___features___5_____2___attn_qkv_weight)\n      getattr_getattr_l__self___features___5_____2___attn_proj_weight = (self.\n          getattr_getattr_L__self___features___5_____2___attn_proj_weight)\n      getattr_getattr_l__self___features___5_____2___attn_qkv_bias = (self.\n          getattr_getattr_L__self___features___5_____2___attn_qkv_bias)\n      getattr_getattr_l__self___features___5_____2___attn_proj_bias = (self.\n          getattr_getattr_L__self___features___5_____2___attn_proj_bias)\n      x_82 = torch.nn.functional.pad(\n          getattr_getattr_l__self___features___5_____2___norm1, (0, 0, 0, 0, 0, 0))\n      getattr_getattr_l__self___features___5_____2___norm1 = None\n      x_83 = x_82.view(1, 2, 7, 2, 7, 384)\n      x_82 = None\n      permute_29 = x_83.permute(0, 1, 3, 2, 4, 5)\n      x_83 = None\n      x_84 = permute_29.reshape(4, 49, 384)\n      permute_29 = None\n      qkv_12 = torch._C._nn.linear(x_84,\n          getattr_getattr_l__self___features___5_____2___attn_qkv_weight,\n          getattr_getattr_l__self___features___5_____2___attn_qkv_bias)\n      x_84 = None\n      getattr_getattr_l__self___features___5_____2___attn_qkv_weight = None\n      getattr_getattr_l__self___features___5_____2___attn_qkv_bias = None\n      reshape_28 = qkv_12.reshape(4, 49, 3, 12, 32)\n      qkv_12 = None\n      qkv_13 = reshape_28.permute(2, 0, 3, 1, 4)\n      reshape_28 = None\n      q_12 = qkv_13[0]\n      k_6 = qkv_13[1]\n      v_6 = qkv_13[2]\n      qkv_13 = None\n      q_13 = q_12 * 0.1767766952966369\n      q_12 = None\n      transpose_12 = k_6.transpose(-2, -1)\n      k_6 = None\n      attn_33 = q_13.matmul(transpose_12)\n      q_13 = None\n      transpose_12 = None\n      attn_34 = attn_33 + relative_position_bias_27\n      attn_33 = None\n      relative_position_bias_27 = None\n      attn_35 = torch.nn.functional.softmax(attn_34, dim=-1)\n      attn_34 = None\n      attn_36 = torch.nn.functional.dropout(attn_35, p=0.0, training=True)\n      attn_35 = None\n      matmul_13 = attn_36.matmul(v_6)\n      attn_36 = None\n      v_6 = None\n      transpose_13 = matmul_13.transpose(1, 2)\n      matmul_13 = None\n      x_85 = transpose_13.reshape(4, 49, 384)\n      transpose_13 = None\n      x_86 = torch._C._nn.linear(x_85,\n          getattr_getattr_l__self___features___5_____2___attn_proj_weight,\n          getattr_getattr_l__self___features___5_____2___attn_proj_bias)\n      x_85 = None\n      getattr_getattr_l__self___features___5_____2___attn_proj_weight = None\n      getattr_getattr_l__self___features___5_____2___attn_proj_bias = None\n      x_87 = torch.nn.functional.dropout(x_86, p=0.0, training=True)\n      x_86 = None\n      x_88 = x_87.view(1, 2, 2, 7, 7, 384)\n      x_87 = None\n      permute_31 = x_88.permute(0, 1, 3, 2, 4, 5)\n      x_88 = None\n      x_89 = permute_31.reshape(1, 14, 14, 384)\n      permute_31 = None\n      getitem_42 = x_89[slice(None, None, None), slice(None, 14, None), slice(\n          None, 14, None), slice(None, None, None)]\n      x_89 = None\n      x_90 = getitem_42.contiguous()\n      getitem_42 = None\n      _log_api_usage_once_12 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      __temp_2944 = []\n      __temp_2944.extend((1, 1, 1, 1))\n      noise_20 = torch.empty(__temp_2944, dtype=torch.float32, device=device(type\n          ='cpu'))\n      noise_21 = noise_20.bernoulli_(0.8909090909090909)\n      noise_20 = None\n      div__10 = noise_21.div_(0.8909090909090909)\n      mul_17 = x_90 * noise_21\n      x_90 = None\n      noise_21 = None\n      x_91 = x_81 + mul_17\n      x_81 = None\n      mul_17 = None\n      getattr_getattr_l__self___features___5_____2___norm2 = (self.\n          getattr_getattr_L__self___features___5_____2___norm2(x_91))\n      getattr_getattr_l__self___features___5_____2___mlp_0 = (self.\n          getattr_getattr_L__self___features___5_____2___mlp_0(\n          getattr_getattr_l__self___features___5_____2___norm2))\n      getattr_getattr_l__self___features___5_____2___norm2 = None\n      getattr_getattr_l__self___features___5_____2___mlp_1 = (self.\n          getattr_getattr_L__self___features___5_____2___mlp_1(\n          getattr_getattr_l__self___features___5_____2___mlp_0))\n      getattr_getattr_l__self___features___5_____2___mlp_0 = None\n      getattr_getattr_l__self___features___5_____2___mlp_2 = (self.\n          getattr_getattr_L__self___features___5_____2___mlp_2(\n          getattr_getattr_l__self___features___5_____2___mlp_1))\n      getattr_getattr_l__self___features___5_____2___mlp_1 = None\n      getattr_getattr_l__self___features___5_____2___mlp_3 = (self.\n          getattr_getattr_L__self___features___5_____2___mlp_3(\n          getattr_getattr_l__self___features___5_____2___mlp_2))\n      getattr_getattr_l__self___features___5_____2___mlp_2 = None\n      getattr_getattr_l__self___features___5_____2___mlp_4 = (self.\n          getattr_getattr_L__self___features___5_____2___mlp_4(\n          getattr_getattr_l__self___features___5_____2___mlp_3))\n      getattr_getattr_l__self___features___5_____2___mlp_3 = None\n      _log_api_usage_once_13 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      __temp_2957 = []\n      __temp_2957.extend((1, 1, 1, 1))\n      noise_22 = torch.empty(__temp_2957, dtype=torch.float32, device=device(type\n          ='cpu'))\n      noise_23 = noise_22.bernoulli_(0.8909090909090909)\n      noise_22 = None\n      div__11 = noise_23.div_(0.8909090909090909)\n      mul_18 = getattr_getattr_l__self___features___5_____2___mlp_4 * noise_23\n      getattr_getattr_l__self___features___5_____2___mlp_4 = None\n      noise_23 = None\n      x_92 = x_91 + mul_18\n      x_91 = None\n      mul_18 = None\n      getattr_getattr_l__self___features___5_____3___norm1 = (self.\n          getattr_getattr_L__self___features___5_____3___norm1(x_92))\n      (\n          getattr_getattr_l__self___features___5_____3___attn_relative_position_bias_table\n          ) = (self.\n          getattr_getattr_L__self___features___5_____3___attn_relative_position_bias_table\n          )\n      (getattr_getattr_l__self___features___5_____3___attn_relative_position_index\n          ) = (self.\n          getattr_getattr_L__self___features___5_____3___attn_relative_position_index\n          )\n      relative_position_bias_28 = (\n          getattr_getattr_l__self___features___5_____3___attn_relative_position_bias_table\n          [\n          getattr_getattr_l__self___features___5_____3___attn_relative_position_index\n          ])\n      (\n          getattr_getattr_l__self___features___5_____3___attn_relative_position_bias_table\n          ) = None\n      (getattr_getattr_l__self___features___5_____3___attn_relative_position_index\n          ) = None\n      relative_position_bias_29 = relative_position_bias_28.view(49, 49, -1)\n      relative_position_bias_28 = None\n      permute_32 = relative_position_bias_29.permute(2, 0, 1)\n      relative_position_bias_29 = None\n      contiguous_14 = permute_32.contiguous()\n      permute_32 = None\n      relative_position_bias_31 = contiguous_14.unsqueeze(0)\n      contiguous_14 = None\n      getattr_getattr_l__self___features___5_____3___attn_qkv_weight = (self.\n          getattr_getattr_L__self___features___5_____3___attn_qkv_weight)\n      getattr_getattr_l__self___features___5_____3___attn_proj_weight = (self.\n          getattr_getattr_L__self___features___5_____3___attn_proj_weight)\n      getattr_getattr_l__self___features___5_____3___attn_qkv_bias = (self.\n          getattr_getattr_L__self___features___5_____3___attn_qkv_bias)\n      getattr_getattr_l__self___features___5_____3___attn_proj_bias = (self.\n          getattr_getattr_L__self___features___5_____3___attn_proj_bias)\n      x_93 = torch.nn.functional.pad(\n          getattr_getattr_l__self___features___5_____3___norm1, (0, 0, 0, 0, 0, 0))\n      getattr_getattr_l__self___features___5_____3___norm1 = None\n      x_94 = torch.roll(x_93, shifts=(-3, -3), dims=(1, 2))\n      x_93 = None\n      x_95 = x_94.view(1, 2, 7, 2, 7, 384)\n      x_94 = None\n      permute_33 = x_95.permute(0, 1, 3, 2, 4, 5)\n      x_95 = None\n      x_96 = permute_33.reshape(4, 49, 384)\n      permute_33 = None\n      qkv_14 = torch._C._nn.linear(x_96,\n          getattr_getattr_l__self___features___5_____3___attn_qkv_weight,\n          getattr_getattr_l__self___features___5_____3___attn_qkv_bias)\n      getattr_getattr_l__self___features___5_____3___attn_qkv_weight = None\n      getattr_getattr_l__self___features___5_____3___attn_qkv_bias = None\n      reshape_32 = qkv_14.reshape(4, 49, 3, 12, 32)\n      qkv_14 = None\n      qkv_15 = reshape_32.permute(2, 0, 3, 1, 4)\n      reshape_32 = None\n      q_14 = qkv_15[0]\n      k_7 = qkv_15[1]\n      v_7 = qkv_15[2]\n      qkv_15 = None\n      q_15 = q_14 * 0.1767766952966369\n      q_14 = None\n      transpose_14 = k_7.transpose(-2, -1)\n      k_7 = None\n      attn_37 = q_15.matmul(transpose_14)\n      q_15 = None\n      transpose_14 = None\n      attn_38 = attn_37 + relative_position_bias_31\n      attn_37 = None\n      relative_position_bias_31 = None\n      attn_mask_15 = x_96.new_zeros((14, 14))\n      x_96 = None\n      attn_mask_15[slice(0, -7, None), slice(0, -7, None)] = 0\n      setitem_27 = attn_mask_15\n      attn_mask_15[slice(0, -7, None), slice(-7, -3, None)] = 1\n      setitem_28 = attn_mask_15\n      attn_mask_15[slice(0, -7, None), slice(-3, None, None)] = 2\n      setitem_29 = attn_mask_15\n      attn_mask_15[slice(-7, -3, None), slice(0, -7, None)] = 3\n      setitem_30 = attn_mask_15\n      attn_mask_15[slice(-7, -3, None), slice(-7, -3, None)] = 4\n      setitem_31 = attn_mask_15\n      attn_mask_15[slice(-7, -3, None), slice(-3, None, None)] = 5\n      setitem_32 = attn_mask_15\n      attn_mask_15[slice(-3, None, None), slice(0, -7, None)] = 6\n      setitem_33 = attn_mask_15\n      attn_mask_15[slice(-3, None, None), slice(-7, -3, None)] = 7\n      setitem_34 = attn_mask_15\n      attn_mask_15[slice(-3, None, None), slice(-3, None, None)] = 8\n      setitem_35 = attn_mask_15\n      attn_mask_16 = attn_mask_15.view(2, 7, 2, 7)\n      attn_mask_15 = None\n      permute_35 = attn_mask_16.permute(0, 2, 1, 3)\n      attn_mask_16 = None\n      attn_mask_17 = permute_35.reshape(4, 49)\n      permute_35 = None\n      unsqueeze_20 = attn_mask_17.unsqueeze(1)\n      unsqueeze_21 = attn_mask_17.unsqueeze(2)\n      attn_mask_17 = None\n      attn_mask_18 = unsqueeze_20 - unsqueeze_21\n      unsqueeze_20 = None\n      unsqueeze_21 = None\n      ne_3 = attn_mask_18 != 0\n      masked_fill_6 = attn_mask_18.masked_fill(ne_3, -100.0)\n      ne_3 = None\n      eq_3 = attn_mask_18 == 0\n      attn_mask_18 = None\n      attn_mask_19 = masked_fill_6.masked_fill(eq_3, 0.0)\n      masked_fill_6 = None\n      eq_3 = None\n      attn_39 = attn_38.view(1, 4, 12, 49, 49)\n      attn_38 = None\n      unsqueeze_22 = attn_mask_19.unsqueeze(1)\n      attn_mask_19 = None\n      unsqueeze_23 = unsqueeze_22.unsqueeze(0)\n      unsqueeze_22 = None\n      attn_40 = attn_39 + unsqueeze_23\n      attn_39 = None\n      unsqueeze_23 = None\n      attn_41 = attn_40.view(-1, 12, 49, 49)\n      attn_40 = None\n      attn_42 = torch.nn.functional.softmax(attn_41, dim=-1)\n      attn_41 = None\n      attn_43 = torch.nn.functional.dropout(attn_42, p=0.0, training=True)\n      attn_42 = None\n      matmul_15 = attn_43.matmul(v_7)\n      attn_43 = None\n      v_7 = None\n      transpose_15 = matmul_15.transpose(1, 2)\n      matmul_15 = None\n      x_97 = transpose_15.reshape(4, 49, 384)\n      transpose_15 = None\n      x_98 = torch._C._nn.linear(x_97,\n          getattr_getattr_l__self___features___5_____3___attn_proj_weight,\n          getattr_getattr_l__self___features___5_____3___attn_proj_bias)\n      x_97 = None\n      getattr_getattr_l__self___features___5_____3___attn_proj_weight = None\n      getattr_getattr_l__self___features___5_____3___attn_proj_bias = None\n      x_99 = torch.nn.functional.dropout(x_98, p=0.0, training=True)\n      x_98 = None\n      x_100 = x_99.view(1, 2, 2, 7, 7, 384)\n      x_99 = None\n      permute_36 = x_100.permute(0, 1, 3, 2, 4, 5)\n      x_100 = None\n      x_101 = permute_36.reshape(1, 14, 14, 384)\n      permute_36 = None\n      x_102 = torch.roll(x_101, shifts=(3, 3), dims=(1, 2))\n      x_101 = None\n      getitem_47 = x_102[slice(None, None, None), slice(None, 14, None), slice(\n          None, 14, None), slice(None, None, None)]\n      x_102 = None\n      x_103 = getitem_47.contiguous()\n      getitem_47 = None\n      _log_api_usage_once_14 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      __temp_3025 = []\n      __temp_3025.extend((1, 1, 1, 1))\n      noise_24 = torch.empty(__temp_3025, dtype=torch.float32, device=device(type\n          ='cpu'))\n      noise_25 = noise_24.bernoulli_(0.8727272727272727)\n      noise_24 = None\n      div__12 = noise_25.div_(0.8727272727272727)\n      mul_20 = x_103 * noise_25\n      x_103 = None\n      noise_25 = None\n      x_104 = x_92 + mul_20\n      x_92 = None\n      mul_20 = None\n      getattr_getattr_l__self___features___5_____3___norm2 = (self.\n          getattr_getattr_L__self___features___5_____3___norm2(x_104))\n      getattr_getattr_l__self___features___5_____3___mlp_0 = (self.\n          getattr_getattr_L__self___features___5_____3___mlp_0(\n          getattr_getattr_l__self___features___5_____3___norm2))\n      getattr_getattr_l__self___features___5_____3___norm2 = None\n      getattr_getattr_l__self___features___5_____3___mlp_1 = (self.\n          getattr_getattr_L__self___features___5_____3___mlp_1(\n          getattr_getattr_l__self___features___5_____3___mlp_0))\n      getattr_getattr_l__self___features___5_____3___mlp_0 = None\n      getattr_getattr_l__self___features___5_____3___mlp_2 = (self.\n          getattr_getattr_L__self___features___5_____3___mlp_2(\n          getattr_getattr_l__self___features___5_____3___mlp_1))\n      getattr_getattr_l__self___features___5_____3___mlp_1 = None\n      getattr_getattr_l__self___features___5_____3___mlp_3 = (self.\n          getattr_getattr_L__self___features___5_____3___mlp_3(\n          getattr_getattr_l__self___features___5_____3___mlp_2))\n      getattr_getattr_l__self___features___5_____3___mlp_2 = None\n      getattr_getattr_l__self___features___5_____3___mlp_4 = (self.\n          getattr_getattr_L__self___features___5_____3___mlp_4(\n          getattr_getattr_l__self___features___5_____3___mlp_3))\n      getattr_getattr_l__self___features___5_____3___mlp_3 = None\n      _log_api_usage_once_15 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      __temp_3038 = []\n      __temp_3038.extend((1, 1, 1, 1))\n      noise_26 = torch.empty(__temp_3038, dtype=torch.float32, device=device(type\n          ='cpu'))\n      noise_27 = noise_26.bernoulli_(0.8727272727272727)\n      noise_26 = None\n      div__13 = noise_27.div_(0.8727272727272727)\n      mul_21 = getattr_getattr_l__self___features___5_____3___mlp_4 * noise_27\n      getattr_getattr_l__self___features___5_____3___mlp_4 = None\n      noise_27 = None\n      x_105 = x_104 + mul_21\n      x_104 = None\n      mul_21 = None\n      getattr_getattr_l__self___features___5_____4___norm1 = (self.\n          getattr_getattr_L__self___features___5_____4___norm1(x_105))\n      (\n          getattr_getattr_l__self___features___5_____4___attn_relative_position_bias_table\n          ) = (self.\n          getattr_getattr_L__self___features___5_____4___attn_relative_position_bias_table\n          )\n      (getattr_getattr_l__self___features___5_____4___attn_relative_position_index\n          ) = (self.\n          getattr_getattr_L__self___features___5_____4___attn_relative_position_index\n          )\n      relative_position_bias_32 = (\n          getattr_getattr_l__self___features___5_____4___attn_relative_position_bias_table\n          [\n          getattr_getattr_l__self___features___5_____4___attn_relative_position_index\n          ])\n      (\n          getattr_getattr_l__self___features___5_____4___attn_relative_position_bias_table\n          ) = None\n      (getattr_getattr_l__self___features___5_____4___attn_relative_position_index\n          ) = None\n      relative_position_bias_33 = relative_position_bias_32.view(49, 49, -1)\n      relative_position_bias_32 = None\n      permute_37 = relative_position_bias_33.permute(2, 0, 1)\n      relative_position_bias_33 = None\n      contiguous_16 = permute_37.contiguous()\n      permute_37 = None\n      relative_position_bias_35 = contiguous_16.unsqueeze(0)\n      contiguous_16 = None\n      getattr_getattr_l__self___features___5_____4___attn_qkv_weight = (self.\n          getattr_getattr_L__self___features___5_____4___attn_qkv_weight)\n      getattr_getattr_l__self___features___5_____4___attn_proj_weight = (self.\n          getattr_getattr_L__self___features___5_____4___attn_proj_weight)\n      getattr_getattr_l__self___features___5_____4___attn_qkv_bias = (self.\n          getattr_getattr_L__self___features___5_____4___attn_qkv_bias)\n      getattr_getattr_l__self___features___5_____4___attn_proj_bias = (self.\n          getattr_getattr_L__self___features___5_____4___attn_proj_bias)\n      x_106 = torch.nn.functional.pad(\n          getattr_getattr_l__self___features___5_____4___norm1, (0, 0, 0, 0, 0, 0))\n      getattr_getattr_l__self___features___5_____4___norm1 = None\n      x_107 = x_106.view(1, 2, 7, 2, 7, 384)\n      x_106 = None\n      permute_38 = x_107.permute(0, 1, 3, 2, 4, 5)\n      x_107 = None\n      x_108 = permute_38.reshape(4, 49, 384)\n      permute_38 = None\n      qkv_16 = torch._C._nn.linear(x_108,\n          getattr_getattr_l__self___features___5_____4___attn_qkv_weight,\n          getattr_getattr_l__self___features___5_____4___attn_qkv_bias)\n      x_108 = None\n      getattr_getattr_l__self___features___5_____4___attn_qkv_weight = None\n      getattr_getattr_l__self___features___5_____4___attn_qkv_bias = None\n      reshape_37 = qkv_16.reshape(4, 49, 3, 12, 32)\n      qkv_16 = None\n      qkv_17 = reshape_37.permute(2, 0, 3, 1, 4)\n      reshape_37 = None\n      q_16 = qkv_17[0]\n      k_8 = qkv_17[1]\n      v_8 = qkv_17[2]\n      qkv_17 = None\n      q_17 = q_16 * 0.1767766952966369\n      q_16 = None\n      transpose_16 = k_8.transpose(-2, -1)\n      k_8 = None\n      attn_44 = q_17.matmul(transpose_16)\n      q_17 = None\n      transpose_16 = None\n      attn_45 = attn_44 + relative_position_bias_35\n      attn_44 = None\n      relative_position_bias_35 = None\n      attn_46 = torch.nn.functional.softmax(attn_45, dim=-1)\n      attn_45 = None\n      attn_47 = torch.nn.functional.dropout(attn_46, p=0.0, training=True)\n      attn_46 = None\n      matmul_17 = attn_47.matmul(v_8)\n      attn_47 = None\n      v_8 = None\n      transpose_17 = matmul_17.transpose(1, 2)\n      matmul_17 = None\n      x_109 = transpose_17.reshape(4, 49, 384)\n      transpose_17 = None\n      x_110 = torch._C._nn.linear(x_109,\n          getattr_getattr_l__self___features___5_____4___attn_proj_weight,\n          getattr_getattr_l__self___features___5_____4___attn_proj_bias)\n      x_109 = None\n      getattr_getattr_l__self___features___5_____4___attn_proj_weight = None\n      getattr_getattr_l__self___features___5_____4___attn_proj_bias = None\n      x_111 = torch.nn.functional.dropout(x_110, p=0.0, training=True)\n      x_110 = None\n      x_112 = x_111.view(1, 2, 2, 7, 7, 384)\n      x_111 = None\n      permute_40 = x_112.permute(0, 1, 3, 2, 4, 5)\n      x_112 = None\n      x_113 = permute_40.reshape(1, 14, 14, 384)\n      permute_40 = None\n      getitem_52 = x_113[slice(None, None, None), slice(None, 14, None), slice(\n          None, 14, None), slice(None, None, None)]\n      x_113 = None\n      x_114 = getitem_52.contiguous()\n      getitem_52 = None\n      _log_api_usage_once_16 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      __temp_3074 = []\n      __temp_3074.extend((1, 1, 1, 1))\n      noise_28 = torch.empty(__temp_3074, dtype=torch.float32, device=device(type\n          ='cpu'))\n      noise_29 = noise_28.bernoulli_(0.8545454545454545)\n      noise_28 = None\n      div__14 = noise_29.div_(0.8545454545454545)\n      mul_23 = x_114 * noise_29\n      x_114 = None\n      noise_29 = None\n      x_115 = x_105 + mul_23\n      x_105 = None\n      mul_23 = None\n      getattr_getattr_l__self___features___5_____4___norm2 = (self.\n          getattr_getattr_L__self___features___5_____4___norm2(x_115))\n      getattr_getattr_l__self___features___5_____4___mlp_0 = (self.\n          getattr_getattr_L__self___features___5_____4___mlp_0(\n          getattr_getattr_l__self___features___5_____4___norm2))\n      getattr_getattr_l__self___features___5_____4___norm2 = None\n      getattr_getattr_l__self___features___5_____4___mlp_1 = (self.\n          getattr_getattr_L__self___features___5_____4___mlp_1(\n          getattr_getattr_l__self___features___5_____4___mlp_0))\n      getattr_getattr_l__self___features___5_____4___mlp_0 = None\n      getattr_getattr_l__self___features___5_____4___mlp_2 = (self.\n          getattr_getattr_L__self___features___5_____4___mlp_2(\n          getattr_getattr_l__self___features___5_____4___mlp_1))\n      getattr_getattr_l__self___features___5_____4___mlp_1 = None\n      getattr_getattr_l__self___features___5_____4___mlp_3 = (self.\n          getattr_getattr_L__self___features___5_____4___mlp_3(\n          getattr_getattr_l__self___features___5_____4___mlp_2))\n      getattr_getattr_l__self___features___5_____4___mlp_2 = None\n      getattr_getattr_l__self___features___5_____4___mlp_4 = (self.\n          getattr_getattr_L__self___features___5_____4___mlp_4(\n          getattr_getattr_l__self___features___5_____4___mlp_3))\n      getattr_getattr_l__self___features___5_____4___mlp_3 = None\n      _log_api_usage_once_17 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      __temp_3087 = []\n      __temp_3087.extend((1, 1, 1, 1))\n      noise_30 = torch.empty(__temp_3087, dtype=torch.float32, device=device(type\n          ='cpu'))\n      noise_31 = noise_30.bernoulli_(0.8545454545454545)\n      noise_30 = None\n      div__15 = noise_31.div_(0.8545454545454545)\n      mul_24 = getattr_getattr_l__self___features___5_____4___mlp_4 * noise_31\n      getattr_getattr_l__self___features___5_____4___mlp_4 = None\n      noise_31 = None\n      x_116 = x_115 + mul_24\n      x_115 = None\n      mul_24 = None\n      getattr_getattr_l__self___features___5_____5___norm1 = (self.\n          getattr_getattr_L__self___features___5_____5___norm1(x_116))\n      (\n          getattr_getattr_l__self___features___5_____5___attn_relative_position_bias_table\n          ) = (self.\n          getattr_getattr_L__self___features___5_____5___attn_relative_position_bias_table\n          )\n      (getattr_getattr_l__self___features___5_____5___attn_relative_position_index\n          ) = (self.\n          getattr_getattr_L__self___features___5_____5___attn_relative_position_index\n          )\n      relative_position_bias_36 = (\n          getattr_getattr_l__self___features___5_____5___attn_relative_position_bias_table\n          [\n          getattr_getattr_l__self___features___5_____5___attn_relative_position_index\n          ])\n      (\n          getattr_getattr_l__self___features___5_____5___attn_relative_position_bias_table\n          ) = None\n      (getattr_getattr_l__self___features___5_____5___attn_relative_position_index\n          ) = None\n      relative_position_bias_37 = relative_position_bias_36.view(49, 49, -1)\n      relative_position_bias_36 = None\n      permute_41 = relative_position_bias_37.permute(2, 0, 1)\n      relative_position_bias_37 = None\n      contiguous_18 = permute_41.contiguous()\n      permute_41 = None\n      relative_position_bias_39 = contiguous_18.unsqueeze(0)\n      contiguous_18 = None\n      getattr_getattr_l__self___features___5_____5___attn_qkv_weight = (self.\n          getattr_getattr_L__self___features___5_____5___attn_qkv_weight)\n      getattr_getattr_l__self___features___5_____5___attn_proj_weight = (self.\n          getattr_getattr_L__self___features___5_____5___attn_proj_weight)\n      getattr_getattr_l__self___features___5_____5___attn_qkv_bias = (self.\n          getattr_getattr_L__self___features___5_____5___attn_qkv_bias)\n      getattr_getattr_l__self___features___5_____5___attn_proj_bias = (self.\n          getattr_getattr_L__self___features___5_____5___attn_proj_bias)\n      x_117 = torch.nn.functional.pad(\n          getattr_getattr_l__self___features___5_____5___norm1, (0, 0, 0, 0, 0, 0))\n      getattr_getattr_l__self___features___5_____5___norm1 = None\n      x_118 = torch.roll(x_117, shifts=(-3, -3), dims=(1, 2))\n      x_117 = None\n      x_119 = x_118.view(1, 2, 7, 2, 7, 384)\n      x_118 = None\n      permute_42 = x_119.permute(0, 1, 3, 2, 4, 5)\n      x_119 = None\n      x_120 = permute_42.reshape(4, 49, 384)\n      permute_42 = None\n      qkv_18 = torch._C._nn.linear(x_120,\n          getattr_getattr_l__self___features___5_____5___attn_qkv_weight,\n          getattr_getattr_l__self___features___5_____5___attn_qkv_bias)\n      getattr_getattr_l__self___features___5_____5___attn_qkv_weight = None\n      getattr_getattr_l__self___features___5_____5___attn_qkv_bias = None\n      reshape_41 = qkv_18.reshape(4, 49, 3, 12, 32)\n      qkv_18 = None\n      qkv_19 = reshape_41.permute(2, 0, 3, 1, 4)\n      reshape_41 = None\n      q_18 = qkv_19[0]\n      k_9 = qkv_19[1]\n      v_9 = qkv_19[2]\n      qkv_19 = None\n      q_19 = q_18 * 0.1767766952966369\n      q_18 = None\n      transpose_18 = k_9.transpose(-2, -1)\n      k_9 = None\n      attn_48 = q_19.matmul(transpose_18)\n      q_19 = None\n      transpose_18 = None\n      attn_49 = attn_48 + relative_position_bias_39\n      attn_48 = None\n      relative_position_bias_39 = None\n      attn_mask_20 = x_120.new_zeros((14, 14))\n      x_120 = None\n      attn_mask_20[slice(0, -7, None), slice(0, -7, None)] = 0\n      setitem_36 = attn_mask_20\n      attn_mask_20[slice(0, -7, None), slice(-7, -3, None)] = 1\n      setitem_37 = attn_mask_20\n      attn_mask_20[slice(0, -7, None), slice(-3, None, None)] = 2\n      setitem_38 = attn_mask_20\n      attn_mask_20[slice(-7, -3, None), slice(0, -7, None)] = 3\n      setitem_39 = attn_mask_20\n      attn_mask_20[slice(-7, -3, None), slice(-7, -3, None)] = 4\n      setitem_40 = attn_mask_20\n      attn_mask_20[slice(-7, -3, None), slice(-3, None, None)] = 5\n      setitem_41 = attn_mask_20\n      attn_mask_20[slice(-3, None, None), slice(0, -7, None)] = 6\n      setitem_42 = attn_mask_20\n      attn_mask_20[slice(-3, None, None), slice(-7, -3, None)] = 7\n      setitem_43 = attn_mask_20\n      attn_mask_20[slice(-3, None, None), slice(-3, None, None)] = 8\n      setitem_44 = attn_mask_20\n      attn_mask_21 = attn_mask_20.view(2, 7, 2, 7)\n      attn_mask_20 = None\n      permute_44 = attn_mask_21.permute(0, 2, 1, 3)\n      attn_mask_21 = None\n      attn_mask_22 = permute_44.reshape(4, 49)\n      permute_44 = None\n      unsqueeze_26 = attn_mask_22.unsqueeze(1)\n      unsqueeze_27 = attn_mask_22.unsqueeze(2)\n      attn_mask_22 = None\n      attn_mask_23 = unsqueeze_26 - unsqueeze_27\n      unsqueeze_26 = None\n      unsqueeze_27 = None\n      ne_4 = attn_mask_23 != 0\n      masked_fill_8 = attn_mask_23.masked_fill(ne_4, -100.0)\n      ne_4 = None\n      eq_4 = attn_mask_23 == 0\n      attn_mask_23 = None\n      attn_mask_24 = masked_fill_8.masked_fill(eq_4, 0.0)\n      masked_fill_8 = None\n      eq_4 = None\n      attn_50 = attn_49.view(1, 4, 12, 49, 49)\n      attn_49 = None\n      unsqueeze_28 = attn_mask_24.unsqueeze(1)\n      attn_mask_24 = None\n      unsqueeze_29 = unsqueeze_28.unsqueeze(0)\n      unsqueeze_28 = None\n      attn_51 = attn_50 + unsqueeze_29\n      attn_50 = None\n      unsqueeze_29 = None\n      attn_52 = attn_51.view(-1, 12, 49, 49)\n      attn_51 = None\n      attn_53 = torch.nn.functional.softmax(attn_52, dim=-1)\n      attn_52 = None\n      attn_54 = torch.nn.functional.dropout(attn_53, p=0.0, training=True)\n      attn_53 = None\n      matmul_19 = attn_54.matmul(v_9)\n      attn_54 = None\n      v_9 = None\n      transpose_19 = matmul_19.transpose(1, 2)\n      matmul_19 = None\n      x_121 = transpose_19.reshape(4, 49, 384)\n      transpose_19 = None\n      x_122 = torch._C._nn.linear(x_121,\n          getattr_getattr_l__self___features___5_____5___attn_proj_weight,\n          getattr_getattr_l__self___features___5_____5___attn_proj_bias)\n      x_121 = None\n      getattr_getattr_l__self___features___5_____5___attn_proj_weight = None\n      getattr_getattr_l__self___features___5_____5___attn_proj_bias = None\n      x_123 = torch.nn.functional.dropout(x_122, p=0.0, training=True)\n      x_122 = None\n      x_124 = x_123.view(1, 2, 2, 7, 7, 384)\n      x_123 = None\n      permute_45 = x_124.permute(0, 1, 3, 2, 4, 5)\n      x_124 = None\n      x_125 = permute_45.reshape(1, 14, 14, 384)\n      permute_45 = None\n      x_126 = torch.roll(x_125, shifts=(3, 3), dims=(1, 2))\n      x_125 = None\n      getitem_57 = x_126[slice(None, None, None), slice(None, 14, None), slice(\n          None, 14, None), slice(None, None, None)]\n      x_126 = None\n      x_127 = getitem_57.contiguous()\n      getitem_57 = None\n      _log_api_usage_once_18 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      __temp_3155 = []\n      __temp_3155.extend((1, 1, 1, 1))\n      noise_32 = torch.empty(__temp_3155, dtype=torch.float32, device=device(type\n          ='cpu'))\n      noise_33 = noise_32.bernoulli_(0.8363636363636364)\n      noise_32 = None\n      div__16 = noise_33.div_(0.8363636363636364)\n      mul_26 = x_127 * noise_33\n      x_127 = None\n      noise_33 = None\n      x_128 = x_116 + mul_26\n      x_116 = None\n      mul_26 = None\n      getattr_getattr_l__self___features___5_____5___norm2 = (self.\n          getattr_getattr_L__self___features___5_____5___norm2(x_128))\n      getattr_getattr_l__self___features___5_____5___mlp_0 = (self.\n          getattr_getattr_L__self___features___5_____5___mlp_0(\n          getattr_getattr_l__self___features___5_____5___norm2))\n      getattr_getattr_l__self___features___5_____5___norm2 = None\n      getattr_getattr_l__self___features___5_____5___mlp_1 = (self.\n          getattr_getattr_L__self___features___5_____5___mlp_1(\n          getattr_getattr_l__self___features___5_____5___mlp_0))\n      getattr_getattr_l__self___features___5_____5___mlp_0 = None\n      getattr_getattr_l__self___features___5_____5___mlp_2 = (self.\n          getattr_getattr_L__self___features___5_____5___mlp_2(\n          getattr_getattr_l__self___features___5_____5___mlp_1))\n      getattr_getattr_l__self___features___5_____5___mlp_1 = None\n      getattr_getattr_l__self___features___5_____5___mlp_3 = (self.\n          getattr_getattr_L__self___features___5_____5___mlp_3(\n          getattr_getattr_l__self___features___5_____5___mlp_2))\n      getattr_getattr_l__self___features___5_____5___mlp_2 = None\n      getattr_getattr_l__self___features___5_____5___mlp_4 = (self.\n          getattr_getattr_L__self___features___5_____5___mlp_4(\n          getattr_getattr_l__self___features___5_____5___mlp_3))\n      getattr_getattr_l__self___features___5_____5___mlp_3 = None\n      _log_api_usage_once_19 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      __temp_3168 = []\n      __temp_3168.extend((1, 1, 1, 1))\n      noise_34 = torch.empty(__temp_3168, dtype=torch.float32, device=device(type\n          ='cpu'))\n      noise_35 = noise_34.bernoulli_(0.8363636363636364)\n      noise_34 = None\n      div__17 = noise_35.div_(0.8363636363636364)\n      mul_27 = getattr_getattr_l__self___features___5_____5___mlp_4 * noise_35\n      getattr_getattr_l__self___features___5_____5___mlp_4 = None\n      noise_35 = None\n      x_129 = x_128 + mul_27\n      x_128 = None\n      mul_27 = None\n      x_130 = torch.nn.functional.pad(x_129, (0, 0, 0, 0, 0, 0))\n      x_129 = None\n      x0_2 = x_130[Ellipsis, slice(0, None, 2), slice(0, None, 2), slice(None,\n          None, None)]\n      x1_2 = x_130[Ellipsis, slice(1, None, 2), slice(0, None, 2), slice(None,\n          None, None)]\n      x2_2 = x_130[Ellipsis, slice(0, None, 2), slice(1, None, 2), slice(None,\n          None, None)]\n      x3_2 = x_130[Ellipsis, slice(1, None, 2), slice(1, None, 2), slice(None,\n          None, None)]\n      x_130 = None\n      x_132 = torch.cat([x0_2, x1_2, x2_2, x3_2], -1)\n      x0_2 = None\n      x1_2 = None\n      x2_2 = None\n      x3_2 = None\n      x_133 = self.getattr_L__self___features___6___norm(x_132)\n      x_132 = None\n      x_134 = self.getattr_L__self___features___6___reduction(x_133)\n      x_133 = None\n      getattr_getattr_l__self___features___7_____0___norm1 = (self.\n          getattr_getattr_L__self___features___7_____0___norm1(x_134))\n      (\n          getattr_getattr_l__self___features___7_____0___attn_relative_position_bias_table\n          ) = (self.\n          getattr_getattr_L__self___features___7_____0___attn_relative_position_bias_table\n          )\n      (getattr_getattr_l__self___features___7_____0___attn_relative_position_index\n          ) = (self.\n          getattr_getattr_L__self___features___7_____0___attn_relative_position_index\n          )\n      relative_position_bias_40 = (\n          getattr_getattr_l__self___features___7_____0___attn_relative_position_bias_table\n          [\n          getattr_getattr_l__self___features___7_____0___attn_relative_position_index\n          ])\n      (\n          getattr_getattr_l__self___features___7_____0___attn_relative_position_bias_table\n          ) = None\n      (getattr_getattr_l__self___features___7_____0___attn_relative_position_index\n          ) = None\n      relative_position_bias_41 = relative_position_bias_40.view(49, 49, -1)\n      relative_position_bias_40 = None\n      permute_46 = relative_position_bias_41.permute(2, 0, 1)\n      relative_position_bias_41 = None\n      contiguous_20 = permute_46.contiguous()\n      permute_46 = None\n      relative_position_bias_43 = contiguous_20.unsqueeze(0)\n      contiguous_20 = None\n      getattr_getattr_l__self___features___7_____0___attn_qkv_weight = (self.\n          getattr_getattr_L__self___features___7_____0___attn_qkv_weight)\n      getattr_getattr_l__self___features___7_____0___attn_proj_weight = (self.\n          getattr_getattr_L__self___features___7_____0___attn_proj_weight)\n      getattr_getattr_l__self___features___7_____0___attn_qkv_bias = (self.\n          getattr_getattr_L__self___features___7_____0___attn_qkv_bias)\n      getattr_getattr_l__self___features___7_____0___attn_proj_bias = (self.\n          getattr_getattr_L__self___features___7_____0___attn_proj_bias)\n      x_135 = torch.nn.functional.pad(\n          getattr_getattr_l__self___features___7_____0___norm1, (0, 0, 0, 0, 0, 0))\n      getattr_getattr_l__self___features___7_____0___norm1 = None\n      x_136 = x_135.view(1, 1, 7, 1, 7, 768)\n      x_135 = None\n      permute_47 = x_136.permute(0, 1, 3, 2, 4, 5)\n      x_136 = None\n      x_137 = permute_47.reshape(1, 49, 768)\n      permute_47 = None\n      qkv_20 = torch._C._nn.linear(x_137,\n          getattr_getattr_l__self___features___7_____0___attn_qkv_weight,\n          getattr_getattr_l__self___features___7_____0___attn_qkv_bias)\n      x_137 = None\n      getattr_getattr_l__self___features___7_____0___attn_qkv_weight = None\n      getattr_getattr_l__self___features___7_____0___attn_qkv_bias = None\n      reshape_46 = qkv_20.reshape(1, 49, 3, 24, 32)\n      qkv_20 = None\n      qkv_21 = reshape_46.permute(2, 0, 3, 1, 4)\n      reshape_46 = None\n      q_20 = qkv_21[0]\n      k_10 = qkv_21[1]\n      v_10 = qkv_21[2]\n      qkv_21 = None\n      q_21 = q_20 * 0.1767766952966369\n      q_20 = None\n      transpose_20 = k_10.transpose(-2, -1)\n      k_10 = None\n      attn_55 = q_21.matmul(transpose_20)\n      q_21 = None\n      transpose_20 = None\n      attn_56 = attn_55 + relative_position_bias_43\n      attn_55 = None\n      relative_position_bias_43 = None\n      attn_57 = torch.nn.functional.softmax(attn_56, dim=-1)\n      attn_56 = None\n      attn_58 = torch.nn.functional.dropout(attn_57, p=0.0, training=True)\n      attn_57 = None\n      matmul_21 = attn_58.matmul(v_10)\n      attn_58 = None\n      v_10 = None\n      transpose_21 = matmul_21.transpose(1, 2)\n      matmul_21 = None\n      x_138 = transpose_21.reshape(1, 49, 768)\n      transpose_21 = None\n      x_139 = torch._C._nn.linear(x_138,\n          getattr_getattr_l__self___features___7_____0___attn_proj_weight,\n          getattr_getattr_l__self___features___7_____0___attn_proj_bias)\n      x_138 = None\n      getattr_getattr_l__self___features___7_____0___attn_proj_weight = None\n      getattr_getattr_l__self___features___7_____0___attn_proj_bias = None\n      x_140 = torch.nn.functional.dropout(x_139, p=0.0, training=True)\n      x_139 = None\n      x_141 = x_140.view(1, 1, 1, 7, 7, 768)\n      x_140 = None\n      permute_49 = x_141.permute(0, 1, 3, 2, 4, 5)\n      x_141 = None\n      x_142 = permute_49.reshape(1, 7, 7, 768)\n      permute_49 = None\n      getitem_66 = x_142[slice(None, None, None), slice(None, 7, None), slice(\n          None, 7, None), slice(None, None, None)]\n      x_142 = None\n      x_143 = getitem_66.contiguous()\n      getitem_66 = None\n      _log_api_usage_once_20 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      __temp_3221 = []\n      __temp_3221.extend((1, 1, 1, 1))\n      noise_36 = torch.empty(__temp_3221, dtype=torch.float32, device=device(type\n          ='cpu'))\n      noise_37 = noise_36.bernoulli_(0.8181818181818181)\n      noise_36 = None\n      div__18 = noise_37.div_(0.8181818181818181)\n      mul_29 = x_143 * noise_37\n      x_143 = None\n      noise_37 = None\n      x_144 = x_134 + mul_29\n      x_134 = None\n      mul_29 = None\n      getattr_getattr_l__self___features___7_____0___norm2 = (self.\n          getattr_getattr_L__self___features___7_____0___norm2(x_144))\n      getattr_getattr_l__self___features___7_____0___mlp_0 = (self.\n          getattr_getattr_L__self___features___7_____0___mlp_0(\n          getattr_getattr_l__self___features___7_____0___norm2))\n      getattr_getattr_l__self___features___7_____0___norm2 = None\n      getattr_getattr_l__self___features___7_____0___mlp_1 = (self.\n          getattr_getattr_L__self___features___7_____0___mlp_1(\n          getattr_getattr_l__self___features___7_____0___mlp_0))\n      getattr_getattr_l__self___features___7_____0___mlp_0 = None\n      getattr_getattr_l__self___features___7_____0___mlp_2 = (self.\n          getattr_getattr_L__self___features___7_____0___mlp_2(\n          getattr_getattr_l__self___features___7_____0___mlp_1))\n      getattr_getattr_l__self___features___7_____0___mlp_1 = None\n      getattr_getattr_l__self___features___7_____0___mlp_3 = (self.\n          getattr_getattr_L__self___features___7_____0___mlp_3(\n          getattr_getattr_l__self___features___7_____0___mlp_2))\n      getattr_getattr_l__self___features___7_____0___mlp_2 = None\n      getattr_getattr_l__self___features___7_____0___mlp_4 = (self.\n          getattr_getattr_L__self___features___7_____0___mlp_4(\n          getattr_getattr_l__self___features___7_____0___mlp_3))\n      getattr_getattr_l__self___features___7_____0___mlp_3 = None\n      _log_api_usage_once_21 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      __temp_3234 = []\n      __temp_3234.extend((1, 1, 1, 1))\n      noise_38 = torch.empty(__temp_3234, dtype=torch.float32, device=device(type\n          ='cpu'))\n      noise_39 = noise_38.bernoulli_(0.8181818181818181)\n      noise_38 = None\n      div__19 = noise_39.div_(0.8181818181818181)\n      mul_30 = getattr_getattr_l__self___features___7_____0___mlp_4 * noise_39\n      getattr_getattr_l__self___features___7_____0___mlp_4 = None\n      noise_39 = None\n      x_145 = x_144 + mul_30\n      x_144 = None\n      mul_30 = None\n      getattr_getattr_l__self___features___7_____1___norm1 = (self.\n          getattr_getattr_L__self___features___7_____1___norm1(x_145))\n      (\n          getattr_getattr_l__self___features___7_____1___attn_relative_position_bias_table\n          ) = (self.\n          getattr_getattr_L__self___features___7_____1___attn_relative_position_bias_table\n          )\n      (getattr_getattr_l__self___features___7_____1___attn_relative_position_index\n          ) = (self.\n          getattr_getattr_L__self___features___7_____1___attn_relative_position_index\n          )\n      relative_position_bias_44 = (\n          getattr_getattr_l__self___features___7_____1___attn_relative_position_bias_table\n          [\n          getattr_getattr_l__self___features___7_____1___attn_relative_position_index\n          ])\n      (\n          getattr_getattr_l__self___features___7_____1___attn_relative_position_bias_table\n          ) = None\n      (getattr_getattr_l__self___features___7_____1___attn_relative_position_index\n          ) = None\n      relative_position_bias_45 = relative_position_bias_44.view(49, 49, -1)\n      relative_position_bias_44 = None\n      permute_50 = relative_position_bias_45.permute(2, 0, 1)\n      relative_position_bias_45 = None\n      contiguous_22 = permute_50.contiguous()\n      permute_50 = None\n      relative_position_bias_47 = contiguous_22.unsqueeze(0)\n      contiguous_22 = None\n      getattr_getattr_l__self___features___7_____1___attn_qkv_weight = (self.\n          getattr_getattr_L__self___features___7_____1___attn_qkv_weight)\n      getattr_getattr_l__self___features___7_____1___attn_proj_weight = (self.\n          getattr_getattr_L__self___features___7_____1___attn_proj_weight)\n      getattr_getattr_l__self___features___7_____1___attn_qkv_bias = (self.\n          getattr_getattr_L__self___features___7_____1___attn_qkv_bias)\n      getattr_getattr_l__self___features___7_____1___attn_proj_bias = (self.\n          getattr_getattr_L__self___features___7_____1___attn_proj_bias)\n      x_146 = torch.nn.functional.pad(\n          getattr_getattr_l__self___features___7_____1___norm1, (0, 0, 0, 0, 0, 0))\n      getattr_getattr_l__self___features___7_____1___norm1 = None\n      x_147 = x_146.view(1, 1, 7, 1, 7, 768)\n      x_146 = None\n      permute_51 = x_147.permute(0, 1, 3, 2, 4, 5)\n      x_147 = None\n      x_148 = permute_51.reshape(1, 49, 768)\n      permute_51 = None\n      qkv_22 = torch._C._nn.linear(x_148,\n          getattr_getattr_l__self___features___7_____1___attn_qkv_weight,\n          getattr_getattr_l__self___features___7_____1___attn_qkv_bias)\n      x_148 = None\n      getattr_getattr_l__self___features___7_____1___attn_qkv_weight = None\n      getattr_getattr_l__self___features___7_____1___attn_qkv_bias = None\n      reshape_50 = qkv_22.reshape(1, 49, 3, 24, 32)\n      qkv_22 = None\n      qkv_23 = reshape_50.permute(2, 0, 3, 1, 4)\n      reshape_50 = None\n      q_22 = qkv_23[0]\n      k_11 = qkv_23[1]\n      v_11 = qkv_23[2]\n      qkv_23 = None\n      q_23 = q_22 * 0.1767766952966369\n      q_22 = None\n      transpose_22 = k_11.transpose(-2, -1)\n      k_11 = None\n      attn_59 = q_23.matmul(transpose_22)\n      q_23 = None\n      transpose_22 = None\n      attn_60 = attn_59 + relative_position_bias_47\n      attn_59 = None\n      relative_position_bias_47 = None\n      attn_61 = torch.nn.functional.softmax(attn_60, dim=-1)\n      attn_60 = None\n      attn_62 = torch.nn.functional.dropout(attn_61, p=0.0, training=True)\n      attn_61 = None\n      matmul_23 = attn_62.matmul(v_11)\n      attn_62 = None\n      v_11 = None\n      transpose_23 = matmul_23.transpose(1, 2)\n      matmul_23 = None\n      x_149 = transpose_23.reshape(1, 49, 768)\n      transpose_23 = None\n      x_150 = torch._C._nn.linear(x_149,\n          getattr_getattr_l__self___features___7_____1___attn_proj_weight,\n          getattr_getattr_l__self___features___7_____1___attn_proj_bias)\n      x_149 = None\n      getattr_getattr_l__self___features___7_____1___attn_proj_weight = None\n      getattr_getattr_l__self___features___7_____1___attn_proj_bias = None\n      x_151 = torch.nn.functional.dropout(x_150, p=0.0, training=True)\n      x_150 = None\n      x_152 = x_151.view(1, 1, 1, 7, 7, 768)\n      x_151 = None\n      permute_53 = x_152.permute(0, 1, 3, 2, 4, 5)\n      x_152 = None\n      x_153 = permute_53.reshape(1, 7, 7, 768)\n      permute_53 = None\n      getitem_71 = x_153[slice(None, None, None), slice(None, 7, None), slice(\n          None, 7, None), slice(None, None, None)]\n      x_153 = None\n      x_154 = getitem_71.contiguous()\n      getitem_71 = None\n      _log_api_usage_once_22 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      __temp_3270 = []\n      __temp_3270.extend((1, 1, 1, 1))\n      noise_40 = torch.empty(__temp_3270, dtype=torch.float32, device=device(type\n          ='cpu'))\n      noise_41 = noise_40.bernoulli_(0.8)\n      noise_40 = None\n      div__20 = noise_41.div_(0.8)\n      mul_32 = x_154 * noise_41\n      x_154 = None\n      noise_41 = None\n      x_155 = x_145 + mul_32\n      x_145 = None\n      mul_32 = None\n      getattr_getattr_l__self___features___7_____1___norm2 = (self.\n          getattr_getattr_L__self___features___7_____1___norm2(x_155))\n      getattr_getattr_l__self___features___7_____1___mlp_0 = (self.\n          getattr_getattr_L__self___features___7_____1___mlp_0(\n          getattr_getattr_l__self___features___7_____1___norm2))\n      getattr_getattr_l__self___features___7_____1___norm2 = None\n      getattr_getattr_l__self___features___7_____1___mlp_1 = (self.\n          getattr_getattr_L__self___features___7_____1___mlp_1(\n          getattr_getattr_l__self___features___7_____1___mlp_0))\n      getattr_getattr_l__self___features___7_____1___mlp_0 = None\n      getattr_getattr_l__self___features___7_____1___mlp_2 = (self.\n          getattr_getattr_L__self___features___7_____1___mlp_2(\n          getattr_getattr_l__self___features___7_____1___mlp_1))\n      getattr_getattr_l__self___features___7_____1___mlp_1 = None\n      getattr_getattr_l__self___features___7_____1___mlp_3 = (self.\n          getattr_getattr_L__self___features___7_____1___mlp_3(\n          getattr_getattr_l__self___features___7_____1___mlp_2))\n      getattr_getattr_l__self___features___7_____1___mlp_2 = None\n      getattr_getattr_l__self___features___7_____1___mlp_4 = (self.\n          getattr_getattr_L__self___features___7_____1___mlp_4(\n          getattr_getattr_l__self___features___7_____1___mlp_3))\n      getattr_getattr_l__self___features___7_____1___mlp_3 = None\n      _log_api_usage_once_23 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      __temp_3283 = []\n      __temp_3283.extend((1, 1, 1, 1))\n      noise_42 = torch.empty(__temp_3283, dtype=torch.float32, device=device(type\n          ='cpu'))\n      noise_43 = noise_42.bernoulli_(0.8)\n      noise_42 = None\n      div__21 = noise_43.div_(0.8)\n      mul_33 = getattr_getattr_l__self___features___7_____1___mlp_4 * noise_43\n      getattr_getattr_l__self___features___7_____1___mlp_4 = None\n      noise_43 = None\n      x_157 = x_155 + mul_33\n      x_155 = None\n      mul_33 = None\n      x_158 = self.L__self___norm(x_157)\n      x_157 = None\n      __temp_3290 = []\n      __temp_3290.extend((0, 3, 1, 2))\n      x_159 = torch.permute(x_158, __temp_3290)\n      x_158 = None\n      x_160 = self.L__self___avgpool(x_159)\n      x_159 = None\n      x_161 = self.L__self___flatten(x_160)\n      x_160 = None\n      x_162 = self.L__self___head(x_161)\n      x_161 = None\n      return x_162,\n\n  ```\n</details>\n<details>\n  <summary>forward</summary>\n\n  ```python\n  def forward(self, x):\n      x = self.features(x)\n      x = self.norm(x)\n      x = self.permute(x)\n      x = self.avgpool(x)\n      x = self.flatten(x)\n      x = self.head(x)\n      return x\n\n  ```\n</details>\n<details>\n  <summary>compiled_code_9</summary>\n\n  ```python\n  def compiled_code_9(self, x):\n      return __compiled_fn_7(x)[0]\n\n  ```\n</details>\n<details>\n  <summary>compiled_code_10</summary>\n\n  ```python\n  def compiled_code_10(self, x):\n      return __compiled_fn_6(x)[0]\n\n  ```\n</details>\n<details>\n  <summary>__compiled_fn_7</summary>\n\n  ```python\n  def __compiled_fn_7(self, L_x_):\n      l_x_ = L_x_\n      l__self___features_0_0 = self.L__self___features_0_0(l_x_)\n      l_x_ = None\n      __temp_1698 = []\n      __temp_1698.extend((0, 2, 3, 1))\n      permute = torch.permute(l__self___features_0_0, __temp_1698)\n      l__self___features_0_0 = None\n      l__self___features_0_2 = self.L__self___features_0_2(permute)\n      permute = None\n      getattr_getattr_l__self___features___1_____0___norm1 = (self.\n          getattr_getattr_L__self___features___1_____0___norm1(\n          l__self___features_0_2))\n      (\n          getattr_getattr_l__self___features___1_____0___attn_relative_position_bias_table\n          ) = (self.\n          getattr_getattr_L__self___features___1_____0___attn_relative_position_bias_table\n          )\n      (getattr_getattr_l__self___features___1_____0___attn_relative_position_index\n          ) = (self.\n          getattr_getattr_L__self___features___1_____0___attn_relative_position_index\n          )\n      relative_position_bias = (\n          getattr_getattr_l__self___features___1_____0___attn_relative_position_bias_table\n          [\n          getattr_getattr_l__self___features___1_____0___attn_relative_position_index\n          ])\n      (\n          getattr_getattr_l__self___features___1_____0___attn_relative_position_bias_table\n          ) = None\n      (getattr_getattr_l__self___features___1_____0___attn_relative_position_index\n          ) = None\n      relative_position_bias_1 = relative_position_bias.view(49, 49, -1)\n      relative_position_bias = None\n      permute_1 = relative_position_bias_1.permute(2, 0, 1)\n      relative_position_bias_1 = None\n      contiguous = permute_1.contiguous()\n      permute_1 = None\n      relative_position_bias_3 = contiguous.unsqueeze(0)\n      contiguous = None\n      getattr_getattr_l__self___features___1_____0___attn_qkv_weight = (self.\n          getattr_getattr_L__self___features___1_____0___attn_qkv_weight)\n      getattr_getattr_l__self___features___1_____0___attn_proj_weight = (self.\n          getattr_getattr_L__self___features___1_____0___attn_proj_weight)\n      getattr_getattr_l__self___features___1_____0___attn_qkv_bias = (self.\n          getattr_getattr_L__self___features___1_____0___attn_qkv_bias)\n      getattr_getattr_l__self___features___1_____0___attn_proj_bias = (self.\n          getattr_getattr_L__self___features___1_____0___attn_proj_bias)\n      x = torch.nn.functional.pad(\n          getattr_getattr_l__self___features___1_____0___norm1, (0, 0, 0, 0, 0, 0))\n      getattr_getattr_l__self___features___1_____0___norm1 = None\n      x_1 = x.view(1, 8, 7, 8, 7, 96)\n      x = None\n      permute_2 = x_1.permute(0, 1, 3, 2, 4, 5)\n      x_1 = None\n      x_2 = permute_2.reshape(64, 49, 96)\n      permute_2 = None\n      qkv = torch._C._nn.linear(x_2,\n          getattr_getattr_l__self___features___1_____0___attn_qkv_weight,\n          getattr_getattr_l__self___features___1_____0___attn_qkv_bias)\n      x_2 = None\n      getattr_getattr_l__self___features___1_____0___attn_qkv_weight = None\n      getattr_getattr_l__self___features___1_____0___attn_qkv_bias = None\n      reshape_1 = qkv.reshape(64, 49, 3, 3, 32)\n      qkv = None\n      qkv_1 = reshape_1.permute(2, 0, 3, 1, 4)\n      reshape_1 = None\n      q = qkv_1[0]\n      k = qkv_1[1]\n      v = qkv_1[2]\n      qkv_1 = None\n      q_1 = q * 0.1767766952966369\n      q = None\n      transpose = k.transpose(-2, -1)\n      k = None\n      attn = q_1.matmul(transpose)\n      q_1 = None\n      transpose = None\n      attn_1 = attn + relative_position_bias_3\n      attn = None\n      relative_position_bias_3 = None\n      attn_2 = torch.nn.functional.softmax(attn_1, dim=-1)\n      attn_1 = None\n      attn_3 = torch.nn.functional.dropout(attn_2, p=0.0, training=True)\n      attn_2 = None\n      matmul_1 = attn_3.matmul(v)\n      attn_3 = None\n      v = None\n      transpose_1 = matmul_1.transpose(1, 2)\n      matmul_1 = None\n      x_3 = transpose_1.reshape(64, 49, 96)\n      transpose_1 = None\n      x_4 = torch._C._nn.linear(x_3,\n          getattr_getattr_l__self___features___1_____0___attn_proj_weight,\n          getattr_getattr_l__self___features___1_____0___attn_proj_bias)\n      x_3 = None\n      getattr_getattr_l__self___features___1_____0___attn_proj_weight = None\n      getattr_getattr_l__self___features___1_____0___attn_proj_bias = None\n      x_5 = torch.nn.functional.dropout(x_4, p=0.0, training=True)\n      x_4 = None\n      x_6 = x_5.view(1, 8, 8, 7, 7, 96)\n      x_5 = None\n      permute_4 = x_6.permute(0, 1, 3, 2, 4, 5)\n      x_6 = None\n      x_7 = permute_4.reshape(1, 56, 56, 96)\n      permute_4 = None\n      getitem_4 = x_7[slice(None, None, None), slice(None, 56, None), slice(None,\n          56, None), slice(None, None, None)]\n      x_7 = None\n      x_8 = getitem_4.contiguous()\n      getitem_4 = None\n      _log_api_usage_once = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      x_9 = l__self___features_0_2 + x_8\n      l__self___features_0_2 = None\n      x_8 = None\n      getattr_getattr_l__self___features___1_____0___norm2 = (self.\n          getattr_getattr_L__self___features___1_____0___norm2(x_9))\n      getattr_getattr_l__self___features___1_____0___mlp_0 = (self.\n          getattr_getattr_L__self___features___1_____0___mlp_0(\n          getattr_getattr_l__self___features___1_____0___norm2))\n      getattr_getattr_l__self___features___1_____0___norm2 = None\n      getattr_getattr_l__self___features___1_____0___mlp_1 = (self.\n          getattr_getattr_L__self___features___1_____0___mlp_1(\n          getattr_getattr_l__self___features___1_____0___mlp_0))\n      getattr_getattr_l__self___features___1_____0___mlp_0 = None\n      getattr_getattr_l__self___features___1_____0___mlp_2 = (self.\n          getattr_getattr_L__self___features___1_____0___mlp_2(\n          getattr_getattr_l__self___features___1_____0___mlp_1))\n      getattr_getattr_l__self___features___1_____0___mlp_1 = None\n      getattr_getattr_l__self___features___1_____0___mlp_3 = (self.\n          getattr_getattr_L__self___features___1_____0___mlp_3(\n          getattr_getattr_l__self___features___1_____0___mlp_2))\n      getattr_getattr_l__self___features___1_____0___mlp_2 = None\n      getattr_getattr_l__self___features___1_____0___mlp_4 = (self.\n          getattr_getattr_L__self___features___1_____0___mlp_4(\n          getattr_getattr_l__self___features___1_____0___mlp_3))\n      getattr_getattr_l__self___features___1_____0___mlp_3 = None\n      _log_api_usage_once_1 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      x_10 = x_9 + getattr_getattr_l__self___features___1_____0___mlp_4\n      x_9 = None\n      getattr_getattr_l__self___features___1_____0___mlp_4 = None\n      getattr_getattr_l__self___features___1_____1___norm1 = (self.\n          getattr_getattr_L__self___features___1_____1___norm1(x_10))\n      (\n          getattr_getattr_l__self___features___1_____1___attn_relative_position_bias_table\n          ) = (self.\n          getattr_getattr_L__self___features___1_____1___attn_relative_position_bias_table\n          )\n      (getattr_getattr_l__self___features___1_____1___attn_relative_position_index\n          ) = (self.\n          getattr_getattr_L__self___features___1_____1___attn_relative_position_index\n          )\n      relative_position_bias_4 = (\n          getattr_getattr_l__self___features___1_____1___attn_relative_position_bias_table\n          [\n          getattr_getattr_l__self___features___1_____1___attn_relative_position_index\n          ])\n      (\n          getattr_getattr_l__self___features___1_____1___attn_relative_position_bias_table\n          ) = None\n      (getattr_getattr_l__self___features___1_____1___attn_relative_position_index\n          ) = None\n      relative_position_bias_5 = relative_position_bias_4.view(49, 49, -1)\n      relative_position_bias_4 = None\n      permute_5 = relative_position_bias_5.permute(2, 0, 1)\n      relative_position_bias_5 = None\n      contiguous_2 = permute_5.contiguous()\n      permute_5 = None\n      relative_position_bias_7 = contiguous_2.unsqueeze(0)\n      contiguous_2 = None\n      getattr_getattr_l__self___features___1_____1___attn_qkv_weight = (self.\n          getattr_getattr_L__self___features___1_____1___attn_qkv_weight)\n      getattr_getattr_l__self___features___1_____1___attn_proj_weight = (self.\n          getattr_getattr_L__self___features___1_____1___attn_proj_weight)\n      getattr_getattr_l__self___features___1_____1___attn_qkv_bias = (self.\n          getattr_getattr_L__self___features___1_____1___attn_qkv_bias)\n      getattr_getattr_l__self___features___1_____1___attn_proj_bias = (self.\n          getattr_getattr_L__self___features___1_____1___attn_proj_bias)\n      x_11 = torch.nn.functional.pad(\n          getattr_getattr_l__self___features___1_____1___norm1, (0, 0, 0, 0, 0, 0))\n      getattr_getattr_l__self___features___1_____1___norm1 = None\n      x_12 = torch.roll(x_11, shifts=(-3, -3), dims=(1, 2))\n      x_11 = None\n      x_13 = x_12.view(1, 8, 7, 8, 7, 96)\n      x_12 = None\n      permute_6 = x_13.permute(0, 1, 3, 2, 4, 5)\n      x_13 = None\n      x_14 = permute_6.reshape(64, 49, 96)\n      permute_6 = None\n      qkv_2 = torch._C._nn.linear(x_14,\n          getattr_getattr_l__self___features___1_____1___attn_qkv_weight,\n          getattr_getattr_l__self___features___1_____1___attn_qkv_bias)\n      getattr_getattr_l__self___features___1_____1___attn_qkv_weight = None\n      getattr_getattr_l__self___features___1_____1___attn_qkv_bias = None\n      reshape_5 = qkv_2.reshape(64, 49, 3, 3, 32)\n      qkv_2 = None\n      qkv_3 = reshape_5.permute(2, 0, 3, 1, 4)\n      reshape_5 = None\n      q_2 = qkv_3[0]\n      k_1 = qkv_3[1]\n      v_1 = qkv_3[2]\n      qkv_3 = None\n      q_3 = q_2 * 0.1767766952966369\n      q_2 = None\n      transpose_2 = k_1.transpose(-2, -1)\n      k_1 = None\n      attn_4 = q_3.matmul(transpose_2)\n      q_3 = None\n      transpose_2 = None\n      attn_5 = attn_4 + relative_position_bias_7\n      attn_4 = None\n      relative_position_bias_7 = None\n      attn_mask = x_14.new_zeros((56, 56))\n      x_14 = None\n      attn_mask[slice(0, -7, None), slice(0, -7, None)] = 0\n      setitem = attn_mask\n      attn_mask[slice(0, -7, None), slice(-7, -3, None)] = 1\n      setitem_1 = attn_mask\n      attn_mask[slice(0, -7, None), slice(-3, None, None)] = 2\n      setitem_2 = attn_mask\n      attn_mask[slice(-7, -3, None), slice(0, -7, None)] = 3\n      setitem_3 = attn_mask\n      attn_mask[slice(-7, -3, None), slice(-7, -3, None)] = 4\n      setitem_4 = attn_mask\n      attn_mask[slice(-7, -3, None), slice(-3, None, None)] = 5\n      setitem_5 = attn_mask\n      attn_mask[slice(-3, None, None), slice(0, -7, None)] = 6\n      setitem_6 = attn_mask\n      attn_mask[slice(-3, None, None), slice(-7, -3, None)] = 7\n      setitem_7 = attn_mask\n      attn_mask[slice(-3, None, None), slice(-3, None, None)] = 8\n      setitem_8 = attn_mask\n      attn_mask_1 = attn_mask.view(8, 7, 8, 7)\n      attn_mask = None\n      permute_8 = attn_mask_1.permute(0, 2, 1, 3)\n      attn_mask_1 = None\n      attn_mask_2 = permute_8.reshape(64, 49)\n      permute_8 = None\n      unsqueeze_2 = attn_mask_2.unsqueeze(1)\n      unsqueeze_3 = attn_mask_2.unsqueeze(2)\n      attn_mask_2 = None\n      attn_mask_3 = unsqueeze_2 - unsqueeze_3\n      unsqueeze_2 = None\n      unsqueeze_3 = None\n      ne = attn_mask_3 != 0\n      masked_fill = attn_mask_3.masked_fill(ne, -100.0)\n      ne = None\n      eq = attn_mask_3 == 0\n      attn_mask_3 = None\n      attn_mask_4 = masked_fill.masked_fill(eq, 0.0)\n      masked_fill = None\n      eq = None\n      attn_6 = attn_5.view(1, 64, 3, 49, 49)\n      attn_5 = None\n      unsqueeze_4 = attn_mask_4.unsqueeze(1)\n      attn_mask_4 = None\n      unsqueeze_5 = unsqueeze_4.unsqueeze(0)\n      unsqueeze_4 = None\n      attn_7 = attn_6 + unsqueeze_5\n      attn_6 = None\n      unsqueeze_5 = None\n      attn_8 = attn_7.view(-1, 3, 49, 49)\n      attn_7 = None\n      attn_9 = torch.nn.functional.softmax(attn_8, dim=-1)\n      attn_8 = None\n      attn_10 = torch.nn.functional.dropout(attn_9, p=0.0, training=True)\n      attn_9 = None\n      matmul_3 = attn_10.matmul(v_1)\n      attn_10 = None\n      v_1 = None\n      transpose_3 = matmul_3.transpose(1, 2)\n      matmul_3 = None\n      x_15 = transpose_3.reshape(64, 49, 96)\n      transpose_3 = None\n      x_16 = torch._C._nn.linear(x_15,\n          getattr_getattr_l__self___features___1_____1___attn_proj_weight,\n          getattr_getattr_l__self___features___1_____1___attn_proj_bias)\n      x_15 = None\n      getattr_getattr_l__self___features___1_____1___attn_proj_weight = None\n      getattr_getattr_l__self___features___1_____1___attn_proj_bias = None\n      x_17 = torch.nn.functional.dropout(x_16, p=0.0, training=True)\n      x_16 = None\n      x_18 = x_17.view(1, 8, 8, 7, 7, 96)\n      x_17 = None\n      permute_9 = x_18.permute(0, 1, 3, 2, 4, 5)\n      x_18 = None\n      x_19 = permute_9.reshape(1, 56, 56, 96)\n      permute_9 = None\n      x_20 = torch.roll(x_19, shifts=(3, 3), dims=(1, 2))\n      x_19 = None\n      getitem_9 = x_20[slice(None, None, None), slice(None, 56, None), slice(None,\n          56, None), slice(None, None, None)]\n      x_20 = None\n      x_21 = getitem_9.contiguous()\n      getitem_9 = None\n      _log_api_usage_once_2 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      __temp_1801 = []\n      __temp_1801.extend((1, 1, 1, 1))\n      noise = torch.empty(__temp_1801, dtype=torch.float32, device=device(type='cpu')\n          )\n      noise_1 = noise.bernoulli_(0.9818181818181818)\n      noise = None\n      div_ = noise_1.div_(0.9818181818181818)\n      mul_2 = x_21 * noise_1\n      x_21 = None\n      noise_1 = None\n      x_22 = x_10 + mul_2\n      x_10 = None\n      mul_2 = None\n      getattr_getattr_l__self___features___1_____1___norm2 = (self.\n          getattr_getattr_L__self___features___1_____1___norm2(x_22))\n      getattr_getattr_l__self___features___1_____1___mlp_0 = (self.\n          getattr_getattr_L__self___features___1_____1___mlp_0(\n          getattr_getattr_l__self___features___1_____1___norm2))\n      getattr_getattr_l__self___features___1_____1___norm2 = None\n      getattr_getattr_l__self___features___1_____1___mlp_1 = (self.\n          getattr_getattr_L__self___features___1_____1___mlp_1(\n          getattr_getattr_l__self___features___1_____1___mlp_0))\n      getattr_getattr_l__self___features___1_____1___mlp_0 = None\n      getattr_getattr_l__self___features___1_____1___mlp_2 = (self.\n          getattr_getattr_L__self___features___1_____1___mlp_2(\n          getattr_getattr_l__self___features___1_____1___mlp_1))\n      getattr_getattr_l__self___features___1_____1___mlp_1 = None\n      getattr_getattr_l__self___features___1_____1___mlp_3 = (self.\n          getattr_getattr_L__self___features___1_____1___mlp_3(\n          getattr_getattr_l__self___features___1_____1___mlp_2))\n      getattr_getattr_l__self___features___1_____1___mlp_2 = None\n      getattr_getattr_l__self___features___1_____1___mlp_4 = (self.\n          getattr_getattr_L__self___features___1_____1___mlp_4(\n          getattr_getattr_l__self___features___1_____1___mlp_3))\n      getattr_getattr_l__self___features___1_____1___mlp_3 = None\n      _log_api_usage_once_3 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      __temp_1814 = []\n      __temp_1814.extend((1, 1, 1, 1))\n      noise_2 = torch.empty(__temp_1814, dtype=torch.float32, device=device(type=\n          'cpu'))\n      noise_3 = noise_2.bernoulli_(0.9818181818181818)\n      noise_2 = None\n      div__1 = noise_3.div_(0.9818181818181818)\n      mul_3 = getattr_getattr_l__self___features___1_____1___mlp_4 * noise_3\n      getattr_getattr_l__self___features___1_____1___mlp_4 = None\n      noise_3 = None\n      x_23 = x_22 + mul_3\n      x_22 = None\n      mul_3 = None\n      x_24 = torch.nn.functional.pad(x_23, (0, 0, 0, 0, 0, 0))\n      x_23 = None\n      x0 = x_24[Ellipsis, slice(0, None, 2), slice(0, None, 2), slice(None, None,\n          None)]\n      x1 = x_24[Ellipsis, slice(1, None, 2), slice(0, None, 2), slice(None, None,\n          None)]\n      x2 = x_24[Ellipsis, slice(0, None, 2), slice(1, None, 2), slice(None, None,\n          None)]\n      x3 = x_24[Ellipsis, slice(1, None, 2), slice(1, None, 2), slice(None, None,\n          None)]\n      x_24 = None\n      x_26 = torch.cat([x0, x1, x2, x3], -1)\n      x0 = None\n      x1 = None\n      x2 = None\n      x3 = None\n      x_27 = self.getattr_L__self___features___2___norm(x_26)\n      x_26 = None\n      x_28 = self.getattr_L__self___features___2___reduction(x_27)\n      x_27 = None\n      getattr_getattr_l__self___features___3_____0___norm1 = (self.\n          getattr_getattr_L__self___features___3_____0___norm1(x_28))\n      (\n          getattr_getattr_l__self___features___3_____0___attn_relative_position_bias_table\n          ) = (self.\n          getattr_getattr_L__self___features___3_____0___attn_relative_position_bias_table\n          )\n      (getattr_getattr_l__self___features___3_____0___attn_relative_position_index\n          ) = (self.\n          getattr_getattr_L__self___features___3_____0___attn_relative_position_index\n          )\n      relative_position_bias_8 = (\n          getattr_getattr_l__self___features___3_____0___attn_relative_position_bias_table\n          [\n          getattr_getattr_l__self___features___3_____0___attn_relative_position_index\n          ])\n      (\n          getattr_getattr_l__self___features___3_____0___attn_relative_position_bias_table\n          ) = None\n      (getattr_getattr_l__self___features___3_____0___attn_relative_position_index\n          ) = None\n      relative_position_bias_9 = relative_position_bias_8.view(49, 49, -1)\n      relative_position_bias_8 = None\n      permute_10 = relative_position_bias_9.permute(2, 0, 1)\n      relative_position_bias_9 = None\n      contiguous_4 = permute_10.contiguous()\n      permute_10 = None\n      relative_position_bias_11 = contiguous_4.unsqueeze(0)\n      contiguous_4 = None\n      getattr_getattr_l__self___features___3_____0___attn_qkv_weight = (self.\n          getattr_getattr_L__self___features___3_____0___attn_qkv_weight)\n      getattr_getattr_l__self___features___3_____0___attn_proj_weight = (self.\n          getattr_getattr_L__self___features___3_____0___attn_proj_weight)\n      getattr_getattr_l__self___features___3_____0___attn_qkv_bias = (self.\n          getattr_getattr_L__self___features___3_____0___attn_qkv_bias)\n      getattr_getattr_l__self___features___3_____0___attn_proj_bias = (self.\n          getattr_getattr_L__self___features___3_____0___attn_proj_bias)\n      x_29 = torch.nn.functional.pad(\n          getattr_getattr_l__self___features___3_____0___norm1, (0, 0, 0, 0, 0, 0))\n      getattr_getattr_l__self___features___3_____0___norm1 = None\n      x_30 = x_29.view(1, 4, 7, 4, 7, 192)\n      x_29 = None\n      permute_11 = x_30.permute(0, 1, 3, 2, 4, 5)\n      x_30 = None\n      x_31 = permute_11.reshape(16, 49, 192)\n      permute_11 = None\n      qkv_4 = torch._C._nn.linear(x_31,\n          getattr_getattr_l__self___features___3_____0___attn_qkv_weight,\n          getattr_getattr_l__self___features___3_____0___attn_qkv_bias)\n      x_31 = None\n      getattr_getattr_l__self___features___3_____0___attn_qkv_weight = None\n      getattr_getattr_l__self___features___3_____0___attn_qkv_bias = None\n      reshape_10 = qkv_4.reshape(16, 49, 3, 6, 32)\n      qkv_4 = None\n      qkv_5 = reshape_10.permute(2, 0, 3, 1, 4)\n      reshape_10 = None\n      q_4 = qkv_5[0]\n      k_2 = qkv_5[1]\n      v_2 = qkv_5[2]\n      qkv_5 = None\n      q_5 = q_4 * 0.1767766952966369\n      q_4 = None\n      transpose_4 = k_2.transpose(-2, -1)\n      k_2 = None\n      attn_11 = q_5.matmul(transpose_4)\n      q_5 = None\n      transpose_4 = None\n      attn_12 = attn_11 + relative_position_bias_11\n      attn_11 = None\n      relative_position_bias_11 = None\n      attn_13 = torch.nn.functional.softmax(attn_12, dim=-1)\n      attn_12 = None\n      attn_14 = torch.nn.functional.dropout(attn_13, p=0.0, training=True)\n      attn_13 = None\n      matmul_5 = attn_14.matmul(v_2)\n      attn_14 = None\n      v_2 = None\n      transpose_5 = matmul_5.transpose(1, 2)\n      matmul_5 = None\n      x_32 = transpose_5.reshape(16, 49, 192)\n      transpose_5 = None\n      x_33 = torch._C._nn.linear(x_32,\n          getattr_getattr_l__self___features___3_____0___attn_proj_weight,\n          getattr_getattr_l__self___features___3_____0___attn_proj_bias)\n      x_32 = None\n      getattr_getattr_l__self___features___3_____0___attn_proj_weight = None\n      getattr_getattr_l__self___features___3_____0___attn_proj_bias = None\n      x_34 = torch.nn.functional.dropout(x_33, p=0.0, training=True)\n      x_33 = None\n      x_35 = x_34.view(1, 4, 4, 7, 7, 192)\n      x_34 = None\n      permute_13 = x_35.permute(0, 1, 3, 2, 4, 5)\n      x_35 = None\n      x_36 = permute_13.reshape(1, 28, 28, 192)\n      permute_13 = None\n      getitem_18 = x_36[slice(None, None, None), slice(None, 28, None), slice(\n          None, 28, None), slice(None, None, None)]\n      x_36 = None\n      x_37 = getitem_18.contiguous()\n      getitem_18 = None\n      _log_api_usage_once_4 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      __temp_1867 = []\n      __temp_1867.extend((1, 1, 1, 1))\n      noise_4 = torch.empty(__temp_1867, dtype=torch.float32, device=device(type=\n          'cpu'))\n      noise_5 = noise_4.bernoulli_(0.9636363636363636)\n      noise_4 = None\n      div__2 = noise_5.div_(0.9636363636363636)\n      mul_5 = x_37 * noise_5\n      x_37 = None\n      noise_5 = None\n      x_38 = x_28 + mul_5\n      x_28 = None\n      mul_5 = None\n      getattr_getattr_l__self___features___3_____0___norm2 = (self.\n          getattr_getattr_L__self___features___3_____0___norm2(x_38))\n      getattr_getattr_l__self___features___3_____0___mlp_0 = (self.\n          getattr_getattr_L__self___features___3_____0___mlp_0(\n          getattr_getattr_l__self___features___3_____0___norm2))\n      getattr_getattr_l__self___features___3_____0___norm2 = None\n      getattr_getattr_l__self___features___3_____0___mlp_1 = (self.\n          getattr_getattr_L__self___features___3_____0___mlp_1(\n          getattr_getattr_l__self___features___3_____0___mlp_0))\n      getattr_getattr_l__self___features___3_____0___mlp_0 = None\n      getattr_getattr_l__self___features___3_____0___mlp_2 = (self.\n          getattr_getattr_L__self___features___3_____0___mlp_2(\n          getattr_getattr_l__self___features___3_____0___mlp_1))\n      getattr_getattr_l__self___features___3_____0___mlp_1 = None\n      getattr_getattr_l__self___features___3_____0___mlp_3 = (self.\n          getattr_getattr_L__self___features___3_____0___mlp_3(\n          getattr_getattr_l__self___features___3_____0___mlp_2))\n      getattr_getattr_l__self___features___3_____0___mlp_2 = None\n      getattr_getattr_l__self___features___3_____0___mlp_4 = (self.\n          getattr_getattr_L__self___features___3_____0___mlp_4(\n          getattr_getattr_l__self___features___3_____0___mlp_3))\n      getattr_getattr_l__self___features___3_____0___mlp_3 = None\n      _log_api_usage_once_5 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      __temp_1880 = []\n      __temp_1880.extend((1, 1, 1, 1))\n      noise_6 = torch.empty(__temp_1880, dtype=torch.float32, device=device(type=\n          'cpu'))\n      noise_7 = noise_6.bernoulli_(0.9636363636363636)\n      noise_6 = None\n      div__3 = noise_7.div_(0.9636363636363636)\n      mul_6 = getattr_getattr_l__self___features___3_____0___mlp_4 * noise_7\n      getattr_getattr_l__self___features___3_____0___mlp_4 = None\n      noise_7 = None\n      x_39 = x_38 + mul_6\n      x_38 = None\n      mul_6 = None\n      getattr_getattr_l__self___features___3_____1___norm1 = (self.\n          getattr_getattr_L__self___features___3_____1___norm1(x_39))\n      (\n          getattr_getattr_l__self___features___3_____1___attn_relative_position_bias_table\n          ) = (self.\n          getattr_getattr_L__self___features___3_____1___attn_relative_position_bias_table\n          )\n      (getattr_getattr_l__self___features___3_____1___attn_relative_position_index\n          ) = (self.\n          getattr_getattr_L__self___features___3_____1___attn_relative_position_index\n          )\n      relative_position_bias_12 = (\n          getattr_getattr_l__self___features___3_____1___attn_relative_position_bias_table\n          [\n          getattr_getattr_l__self___features___3_____1___attn_relative_position_index\n          ])\n      (\n          getattr_getattr_l__self___features___3_____1___attn_relative_position_bias_table\n          ) = None\n      (getattr_getattr_l__self___features___3_____1___attn_relative_position_index\n          ) = None\n      relative_position_bias_13 = relative_position_bias_12.view(49, 49, -1)\n      relative_position_bias_12 = None\n      permute_14 = relative_position_bias_13.permute(2, 0, 1)\n      relative_position_bias_13 = None\n      contiguous_6 = permute_14.contiguous()\n      permute_14 = None\n      relative_position_bias_15 = contiguous_6.unsqueeze(0)\n      contiguous_6 = None\n      getattr_getattr_l__self___features___3_____1___attn_qkv_weight = (self.\n          getattr_getattr_L__self___features___3_____1___attn_qkv_weight)\n      getattr_getattr_l__self___features___3_____1___attn_proj_weight = (self.\n          getattr_getattr_L__self___features___3_____1___attn_proj_weight)\n      getattr_getattr_l__self___features___3_____1___attn_qkv_bias = (self.\n          getattr_getattr_L__self___features___3_____1___attn_qkv_bias)\n      getattr_getattr_l__self___features___3_____1___attn_proj_bias = (self.\n          getattr_getattr_L__self___features___3_____1___attn_proj_bias)\n      x_40 = torch.nn.functional.pad(\n          getattr_getattr_l__self___features___3_____1___norm1, (0, 0, 0, 0, 0, 0))\n      getattr_getattr_l__self___features___3_____1___norm1 = None\n      x_41 = torch.roll(x_40, shifts=(-3, -3), dims=(1, 2))\n      x_40 = None\n      x_42 = x_41.view(1, 4, 7, 4, 7, 192)\n      x_41 = None\n      permute_15 = x_42.permute(0, 1, 3, 2, 4, 5)\n      x_42 = None\n      x_43 = permute_15.reshape(16, 49, 192)\n      permute_15 = None\n      qkv_6 = torch._C._nn.linear(x_43,\n          getattr_getattr_l__self___features___3_____1___attn_qkv_weight,\n          getattr_getattr_l__self___features___3_____1___attn_qkv_bias)\n      getattr_getattr_l__self___features___3_____1___attn_qkv_weight = None\n      getattr_getattr_l__self___features___3_____1___attn_qkv_bias = None\n      reshape_14 = qkv_6.reshape(16, 49, 3, 6, 32)\n      qkv_6 = None\n      qkv_7 = reshape_14.permute(2, 0, 3, 1, 4)\n      reshape_14 = None\n      q_6 = qkv_7[0]\n      k_3 = qkv_7[1]\n      v_3 = qkv_7[2]\n      qkv_7 = None\n      q_7 = q_6 * 0.1767766952966369\n      q_6 = None\n      transpose_6 = k_3.transpose(-2, -1)\n      k_3 = None\n      attn_15 = q_7.matmul(transpose_6)\n      q_7 = None\n      transpose_6 = None\n      attn_16 = attn_15 + relative_position_bias_15\n      attn_15 = None\n      relative_position_bias_15 = None\n      attn_mask_5 = x_43.new_zeros((28, 28))\n      x_43 = None\n      attn_mask_5[slice(0, -7, None), slice(0, -7, None)] = 0\n      setitem_9 = attn_mask_5\n      attn_mask_5[slice(0, -7, None), slice(-7, -3, None)] = 1\n      setitem_10 = attn_mask_5\n      attn_mask_5[slice(0, -7, None), slice(-3, None, None)] = 2\n      setitem_11 = attn_mask_5\n      attn_mask_5[slice(-7, -3, None), slice(0, -7, None)] = 3\n      setitem_12 = attn_mask_5\n      attn_mask_5[slice(-7, -3, None), slice(-7, -3, None)] = 4\n      setitem_13 = attn_mask_5\n      attn_mask_5[slice(-7, -3, None), slice(-3, None, None)] = 5\n      setitem_14 = attn_mask_5\n      attn_mask_5[slice(-3, None, None), slice(0, -7, None)] = 6\n      setitem_15 = attn_mask_5\n      attn_mask_5[slice(-3, None, None), slice(-7, -3, None)] = 7\n      setitem_16 = attn_mask_5\n      attn_mask_5[slice(-3, None, None), slice(-3, None, None)] = 8\n      setitem_17 = attn_mask_5\n      attn_mask_6 = attn_mask_5.view(4, 7, 4, 7)\n      attn_mask_5 = None\n      permute_17 = attn_mask_6.permute(0, 2, 1, 3)\n      attn_mask_6 = None\n      attn_mask_7 = permute_17.reshape(16, 49)\n      permute_17 = None\n      unsqueeze_8 = attn_mask_7.unsqueeze(1)\n      unsqueeze_9 = attn_mask_7.unsqueeze(2)\n      attn_mask_7 = None\n      attn_mask_8 = unsqueeze_8 - unsqueeze_9\n      unsqueeze_8 = None\n      unsqueeze_9 = None\n      ne_1 = attn_mask_8 != 0\n      masked_fill_2 = attn_mask_8.masked_fill(ne_1, -100.0)\n      ne_1 = None\n      eq_1 = attn_mask_8 == 0\n      attn_mask_8 = None\n      attn_mask_9 = masked_fill_2.masked_fill(eq_1, 0.0)\n      masked_fill_2 = None\n      eq_1 = None\n      attn_17 = attn_16.view(1, 16, 6, 49, 49)\n      attn_16 = None\n      unsqueeze_10 = attn_mask_9.unsqueeze(1)\n      attn_mask_9 = None\n      unsqueeze_11 = unsqueeze_10.unsqueeze(0)\n      unsqueeze_10 = None\n      attn_18 = attn_17 + unsqueeze_11\n      attn_17 = None\n      unsqueeze_11 = None\n      attn_19 = attn_18.view(-1, 6, 49, 49)\n      attn_18 = None\n      attn_20 = torch.nn.functional.softmax(attn_19, dim=-1)\n      attn_19 = None\n      attn_21 = torch.nn.functional.dropout(attn_20, p=0.0, training=True)\n      attn_20 = None\n      matmul_7 = attn_21.matmul(v_3)\n      attn_21 = None\n      v_3 = None\n      transpose_7 = matmul_7.transpose(1, 2)\n      matmul_7 = None\n      x_44 = transpose_7.reshape(16, 49, 192)\n      transpose_7 = None\n      x_45 = torch._C._nn.linear(x_44,\n          getattr_getattr_l__self___features___3_____1___attn_proj_weight,\n          getattr_getattr_l__self___features___3_____1___attn_proj_bias)\n      x_44 = None\n      getattr_getattr_l__self___features___3_____1___attn_proj_weight = None\n      getattr_getattr_l__self___features___3_____1___attn_proj_bias = None\n      x_46 = torch.nn.functional.dropout(x_45, p=0.0, training=True)\n      x_45 = None\n      x_47 = x_46.view(1, 4, 4, 7, 7, 192)\n      x_46 = None\n      permute_18 = x_47.permute(0, 1, 3, 2, 4, 5)\n      x_47 = None\n      x_48 = permute_18.reshape(1, 28, 28, 192)\n      permute_18 = None\n      x_49 = torch.roll(x_48, shifts=(3, 3), dims=(1, 2))\n      x_48 = None\n      getitem_23 = x_49[slice(None, None, None), slice(None, 28, None), slice(\n          None, 28, None), slice(None, None, None)]\n      x_49 = None\n      x_50 = getitem_23.contiguous()\n      getitem_23 = None\n      _log_api_usage_once_6 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      __temp_1948 = []\n      __temp_1948.extend((1, 1, 1, 1))\n      noise_8 = torch.empty(__temp_1948, dtype=torch.float32, device=device(type=\n          'cpu'))\n      noise_9 = noise_8.bernoulli_(0.9454545454545454)\n      noise_8 = None\n      div__4 = noise_9.div_(0.9454545454545454)\n      mul_8 = x_50 * noise_9\n      x_50 = None\n      noise_9 = None\n      x_51 = x_39 + mul_8\n      x_39 = None\n      mul_8 = None\n      getattr_getattr_l__self___features___3_____1___norm2 = (self.\n          getattr_getattr_L__self___features___3_____1___norm2(x_51))\n      getattr_getattr_l__self___features___3_____1___mlp_0 = (self.\n          getattr_getattr_L__self___features___3_____1___mlp_0(\n          getattr_getattr_l__self___features___3_____1___norm2))\n      getattr_getattr_l__self___features___3_____1___norm2 = None\n      getattr_getattr_l__self___features___3_____1___mlp_1 = (self.\n          getattr_getattr_L__self___features___3_____1___mlp_1(\n          getattr_getattr_l__self___features___3_____1___mlp_0))\n      getattr_getattr_l__self___features___3_____1___mlp_0 = None\n      getattr_getattr_l__self___features___3_____1___mlp_2 = (self.\n          getattr_getattr_L__self___features___3_____1___mlp_2(\n          getattr_getattr_l__self___features___3_____1___mlp_1))\n      getattr_getattr_l__self___features___3_____1___mlp_1 = None\n      getattr_getattr_l__self___features___3_____1___mlp_3 = (self.\n          getattr_getattr_L__self___features___3_____1___mlp_3(\n          getattr_getattr_l__self___features___3_____1___mlp_2))\n      getattr_getattr_l__self___features___3_____1___mlp_2 = None\n      getattr_getattr_l__self___features___3_____1___mlp_4 = (self.\n          getattr_getattr_L__self___features___3_____1___mlp_4(\n          getattr_getattr_l__self___features___3_____1___mlp_3))\n      getattr_getattr_l__self___features___3_____1___mlp_3 = None\n      _log_api_usage_once_7 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      __temp_1961 = []\n      __temp_1961.extend((1, 1, 1, 1))\n      noise_10 = torch.empty(__temp_1961, dtype=torch.float32, device=device(type\n          ='cpu'))\n      noise_11 = noise_10.bernoulli_(0.9454545454545454)\n      noise_10 = None\n      div__5 = noise_11.div_(0.9454545454545454)\n      mul_9 = getattr_getattr_l__self___features___3_____1___mlp_4 * noise_11\n      getattr_getattr_l__self___features___3_____1___mlp_4 = None\n      noise_11 = None\n      x_52 = x_51 + mul_9\n      x_51 = None\n      mul_9 = None\n      x_53 = torch.nn.functional.pad(x_52, (0, 0, 0, 0, 0, 0))\n      x_52 = None\n      x0_1 = x_53[Ellipsis, slice(0, None, 2), slice(0, None, 2), slice(None,\n          None, None)]\n      x1_1 = x_53[Ellipsis, slice(1, None, 2), slice(0, None, 2), slice(None,\n          None, None)]\n      x2_1 = x_53[Ellipsis, slice(0, None, 2), slice(1, None, 2), slice(None,\n          None, None)]\n      x3_1 = x_53[Ellipsis, slice(1, None, 2), slice(1, None, 2), slice(None,\n          None, None)]\n      x_53 = None\n      x_55 = torch.cat([x0_1, x1_1, x2_1, x3_1], -1)\n      x0_1 = None\n      x1_1 = None\n      x2_1 = None\n      x3_1 = None\n      x_56 = self.getattr_L__self___features___4___norm(x_55)\n      x_55 = None\n      x_57 = self.getattr_L__self___features___4___reduction(x_56)\n      x_56 = None\n      getattr_getattr_l__self___features___5_____0___norm1 = (self.\n          getattr_getattr_L__self___features___5_____0___norm1(x_57))\n      (\n          getattr_getattr_l__self___features___5_____0___attn_relative_position_bias_table\n          ) = (self.\n          getattr_getattr_L__self___features___5_____0___attn_relative_position_bias_table\n          )\n      (getattr_getattr_l__self___features___5_____0___attn_relative_position_index\n          ) = (self.\n          getattr_getattr_L__self___features___5_____0___attn_relative_position_index\n          )\n      relative_position_bias_16 = (\n          getattr_getattr_l__self___features___5_____0___attn_relative_position_bias_table\n          [\n          getattr_getattr_l__self___features___5_____0___attn_relative_position_index\n          ])\n      (\n          getattr_getattr_l__self___features___5_____0___attn_relative_position_bias_table\n          ) = None\n      (getattr_getattr_l__self___features___5_____0___attn_relative_position_index\n          ) = None\n      relative_position_bias_17 = relative_position_bias_16.view(49, 49, -1)\n      relative_position_bias_16 = None\n      permute_19 = relative_position_bias_17.permute(2, 0, 1)\n      relative_position_bias_17 = None\n      contiguous_8 = permute_19.contiguous()\n      permute_19 = None\n      relative_position_bias_19 = contiguous_8.unsqueeze(0)\n      contiguous_8 = None\n      getattr_getattr_l__self___features___5_____0___attn_qkv_weight = (self.\n          getattr_getattr_L__self___features___5_____0___attn_qkv_weight)\n      getattr_getattr_l__self___features___5_____0___attn_proj_weight = (self.\n          getattr_getattr_L__self___features___5_____0___attn_proj_weight)\n      getattr_getattr_l__self___features___5_____0___attn_qkv_bias = (self.\n          getattr_getattr_L__self___features___5_____0___attn_qkv_bias)\n      getattr_getattr_l__self___features___5_____0___attn_proj_bias = (self.\n          getattr_getattr_L__self___features___5_____0___attn_proj_bias)\n      x_58 = torch.nn.functional.pad(\n          getattr_getattr_l__self___features___5_____0___norm1, (0, 0, 0, 0, 0, 0))\n      getattr_getattr_l__self___features___5_____0___norm1 = None\n      x_59 = x_58.view(1, 2, 7, 2, 7, 384)\n      x_58 = None\n      permute_20 = x_59.permute(0, 1, 3, 2, 4, 5)\n      x_59 = None\n      x_60 = permute_20.reshape(4, 49, 384)\n      permute_20 = None\n      qkv_8 = torch._C._nn.linear(x_60,\n          getattr_getattr_l__self___features___5_____0___attn_qkv_weight,\n          getattr_getattr_l__self___features___5_____0___attn_qkv_bias)\n      x_60 = None\n      getattr_getattr_l__self___features___5_____0___attn_qkv_weight = None\n      getattr_getattr_l__self___features___5_____0___attn_qkv_bias = None\n      reshape_19 = qkv_8.reshape(4, 49, 3, 12, 32)\n      qkv_8 = None\n      qkv_9 = reshape_19.permute(2, 0, 3, 1, 4)\n      reshape_19 = None\n      q_8 = qkv_9[0]\n      k_4 = qkv_9[1]\n      v_4 = qkv_9[2]\n      qkv_9 = None\n      q_9 = q_8 * 0.1767766952966369\n      q_8 = None\n      transpose_8 = k_4.transpose(-2, -1)\n      k_4 = None\n      attn_22 = q_9.matmul(transpose_8)\n      q_9 = None\n      transpose_8 = None\n      attn_23 = attn_22 + relative_position_bias_19\n      attn_22 = None\n      relative_position_bias_19 = None\n      attn_24 = torch.nn.functional.softmax(attn_23, dim=-1)\n      attn_23 = None\n      attn_25 = torch.nn.functional.dropout(attn_24, p=0.0, training=True)\n      attn_24 = None\n      matmul_9 = attn_25.matmul(v_4)\n      attn_25 = None\n      v_4 = None\n      transpose_9 = matmul_9.transpose(1, 2)\n      matmul_9 = None\n      x_61 = transpose_9.reshape(4, 49, 384)\n      transpose_9 = None\n      x_62 = torch._C._nn.linear(x_61,\n          getattr_getattr_l__self___features___5_____0___attn_proj_weight,\n          getattr_getattr_l__self___features___5_____0___attn_proj_bias)\n      x_61 = None\n      getattr_getattr_l__self___features___5_____0___attn_proj_weight = None\n      getattr_getattr_l__self___features___5_____0___attn_proj_bias = None\n      x_63 = torch.nn.functional.dropout(x_62, p=0.0, training=True)\n      x_62 = None\n      x_64 = x_63.view(1, 2, 2, 7, 7, 384)\n      x_63 = None\n      permute_22 = x_64.permute(0, 1, 3, 2, 4, 5)\n      x_64 = None\n      x_65 = permute_22.reshape(1, 14, 14, 384)\n      permute_22 = None\n      getitem_32 = x_65[slice(None, None, None), slice(None, 14, None), slice(\n          None, 14, None), slice(None, None, None)]\n      x_65 = None\n      x_66 = getitem_32.contiguous()\n      getitem_32 = None\n      _log_api_usage_once_8 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      __temp_2014 = []\n      __temp_2014.extend((1, 1, 1, 1))\n      noise_12 = torch.empty(__temp_2014, dtype=torch.float32, device=device(type\n          ='cpu'))\n      noise_13 = noise_12.bernoulli_(0.9272727272727272)\n      noise_12 = None\n      div__6 = noise_13.div_(0.9272727272727272)\n      mul_11 = x_66 * noise_13\n      x_66 = None\n      noise_13 = None\n      x_67 = x_57 + mul_11\n      x_57 = None\n      mul_11 = None\n      getattr_getattr_l__self___features___5_____0___norm2 = (self.\n          getattr_getattr_L__self___features___5_____0___norm2(x_67))\n      getattr_getattr_l__self___features___5_____0___mlp_0 = (self.\n          getattr_getattr_L__self___features___5_____0___mlp_0(\n          getattr_getattr_l__self___features___5_____0___norm2))\n      getattr_getattr_l__self___features___5_____0___norm2 = None\n      getattr_getattr_l__self___features___5_____0___mlp_1 = (self.\n          getattr_getattr_L__self___features___5_____0___mlp_1(\n          getattr_getattr_l__self___features___5_____0___mlp_0))\n      getattr_getattr_l__self___features___5_____0___mlp_0 = None\n      getattr_getattr_l__self___features___5_____0___mlp_2 = (self.\n          getattr_getattr_L__self___features___5_____0___mlp_2(\n          getattr_getattr_l__self___features___5_____0___mlp_1))\n      getattr_getattr_l__self___features___5_____0___mlp_1 = None\n      getattr_getattr_l__self___features___5_____0___mlp_3 = (self.\n          getattr_getattr_L__self___features___5_____0___mlp_3(\n          getattr_getattr_l__self___features___5_____0___mlp_2))\n      getattr_getattr_l__self___features___5_____0___mlp_2 = None\n      getattr_getattr_l__self___features___5_____0___mlp_4 = (self.\n          getattr_getattr_L__self___features___5_____0___mlp_4(\n          getattr_getattr_l__self___features___5_____0___mlp_3))\n      getattr_getattr_l__self___features___5_____0___mlp_3 = None\n      _log_api_usage_once_9 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      __temp_2027 = []\n      __temp_2027.extend((1, 1, 1, 1))\n      noise_14 = torch.empty(__temp_2027, dtype=torch.float32, device=device(type\n          ='cpu'))\n      noise_15 = noise_14.bernoulli_(0.9272727272727272)\n      noise_14 = None\n      div__7 = noise_15.div_(0.9272727272727272)\n      mul_12 = getattr_getattr_l__self___features___5_____0___mlp_4 * noise_15\n      getattr_getattr_l__self___features___5_____0___mlp_4 = None\n      noise_15 = None\n      x_68 = x_67 + mul_12\n      x_67 = None\n      mul_12 = None\n      getattr_getattr_l__self___features___5_____1___norm1 = (self.\n          getattr_getattr_L__self___features___5_____1___norm1(x_68))\n      (\n          getattr_getattr_l__self___features___5_____1___attn_relative_position_bias_table\n          ) = (self.\n          getattr_getattr_L__self___features___5_____1___attn_relative_position_bias_table\n          )\n      (getattr_getattr_l__self___features___5_____1___attn_relative_position_index\n          ) = (self.\n          getattr_getattr_L__self___features___5_____1___attn_relative_position_index\n          )\n      relative_position_bias_20 = (\n          getattr_getattr_l__self___features___5_____1___attn_relative_position_bias_table\n          [\n          getattr_getattr_l__self___features___5_____1___attn_relative_position_index\n          ])\n      (\n          getattr_getattr_l__self___features___5_____1___attn_relative_position_bias_table\n          ) = None\n      (getattr_getattr_l__self___features___5_____1___attn_relative_position_index\n          ) = None\n      relative_position_bias_21 = relative_position_bias_20.view(49, 49, -1)\n      relative_position_bias_20 = None\n      permute_23 = relative_position_bias_21.permute(2, 0, 1)\n      relative_position_bias_21 = None\n      contiguous_10 = permute_23.contiguous()\n      permute_23 = None\n      relative_position_bias_23 = contiguous_10.unsqueeze(0)\n      contiguous_10 = None\n      getattr_getattr_l__self___features___5_____1___attn_qkv_weight = (self.\n          getattr_getattr_L__self___features___5_____1___attn_qkv_weight)\n      getattr_getattr_l__self___features___5_____1___attn_proj_weight = (self.\n          getattr_getattr_L__self___features___5_____1___attn_proj_weight)\n      getattr_getattr_l__self___features___5_____1___attn_qkv_bias = (self.\n          getattr_getattr_L__self___features___5_____1___attn_qkv_bias)\n      getattr_getattr_l__self___features___5_____1___attn_proj_bias = (self.\n          getattr_getattr_L__self___features___5_____1___attn_proj_bias)\n      x_69 = torch.nn.functional.pad(\n          getattr_getattr_l__self___features___5_____1___norm1, (0, 0, 0, 0, 0, 0))\n      getattr_getattr_l__self___features___5_____1___norm1 = None\n      x_70 = torch.roll(x_69, shifts=(-3, -3), dims=(1, 2))\n      x_69 = None\n      x_71 = x_70.view(1, 2, 7, 2, 7, 384)\n      x_70 = None\n      permute_24 = x_71.permute(0, 1, 3, 2, 4, 5)\n      x_71 = None\n      x_72 = permute_24.reshape(4, 49, 384)\n      permute_24 = None\n      qkv_10 = torch._C._nn.linear(x_72,\n          getattr_getattr_l__self___features___5_____1___attn_qkv_weight,\n          getattr_getattr_l__self___features___5_____1___attn_qkv_bias)\n      getattr_getattr_l__self___features___5_____1___attn_qkv_weight = None\n      getattr_getattr_l__self___features___5_____1___attn_qkv_bias = None\n      reshape_23 = qkv_10.reshape(4, 49, 3, 12, 32)\n      qkv_10 = None\n      qkv_11 = reshape_23.permute(2, 0, 3, 1, 4)\n      reshape_23 = None\n      q_10 = qkv_11[0]\n      k_5 = qkv_11[1]\n      v_5 = qkv_11[2]\n      qkv_11 = None\n      q_11 = q_10 * 0.1767766952966369\n      q_10 = None\n      transpose_10 = k_5.transpose(-2, -1)\n      k_5 = None\n      attn_26 = q_11.matmul(transpose_10)\n      q_11 = None\n      transpose_10 = None\n      attn_27 = attn_26 + relative_position_bias_23\n      attn_26 = None\n      relative_position_bias_23 = None\n      attn_mask_10 = x_72.new_zeros((14, 14))\n      x_72 = None\n      attn_mask_10[slice(0, -7, None), slice(0, -7, None)] = 0\n      setitem_18 = attn_mask_10\n      attn_mask_10[slice(0, -7, None), slice(-7, -3, None)] = 1\n      setitem_19 = attn_mask_10\n      attn_mask_10[slice(0, -7, None), slice(-3, None, None)] = 2\n      setitem_20 = attn_mask_10\n      attn_mask_10[slice(-7, -3, None), slice(0, -7, None)] = 3\n      setitem_21 = attn_mask_10\n      attn_mask_10[slice(-7, -3, None), slice(-7, -3, None)] = 4\n      setitem_22 = attn_mask_10\n      attn_mask_10[slice(-7, -3, None), slice(-3, None, None)] = 5\n      setitem_23 = attn_mask_10\n      attn_mask_10[slice(-3, None, None), slice(0, -7, None)] = 6\n      setitem_24 = attn_mask_10\n      attn_mask_10[slice(-3, None, None), slice(-7, -3, None)] = 7\n      setitem_25 = attn_mask_10\n      attn_mask_10[slice(-3, None, None), slice(-3, None, None)] = 8\n      setitem_26 = attn_mask_10\n      attn_mask_11 = attn_mask_10.view(2, 7, 2, 7)\n      attn_mask_10 = None\n      permute_26 = attn_mask_11.permute(0, 2, 1, 3)\n      attn_mask_11 = None\n      attn_mask_12 = permute_26.reshape(4, 49)\n      permute_26 = None\n      unsqueeze_14 = attn_mask_12.unsqueeze(1)\n      unsqueeze_15 = attn_mask_12.unsqueeze(2)\n      attn_mask_12 = None\n      attn_mask_13 = unsqueeze_14 - unsqueeze_15\n      unsqueeze_14 = None\n      unsqueeze_15 = None\n      ne_2 = attn_mask_13 != 0\n      masked_fill_4 = attn_mask_13.masked_fill(ne_2, -100.0)\n      ne_2 = None\n      eq_2 = attn_mask_13 == 0\n      attn_mask_13 = None\n      attn_mask_14 = masked_fill_4.masked_fill(eq_2, 0.0)\n      masked_fill_4 = None\n      eq_2 = None\n      attn_28 = attn_27.view(1, 4, 12, 49, 49)\n      attn_27 = None\n      unsqueeze_16 = attn_mask_14.unsqueeze(1)\n      attn_mask_14 = None\n      unsqueeze_17 = unsqueeze_16.unsqueeze(0)\n      unsqueeze_16 = None\n      attn_29 = attn_28 + unsqueeze_17\n      attn_28 = None\n      unsqueeze_17 = None\n      attn_30 = attn_29.view(-1, 12, 49, 49)\n      attn_29 = None\n      attn_31 = torch.nn.functional.softmax(attn_30, dim=-1)\n      attn_30 = None\n      attn_32 = torch.nn.functional.dropout(attn_31, p=0.0, training=True)\n      attn_31 = None\n      matmul_11 = attn_32.matmul(v_5)\n      attn_32 = None\n      v_5 = None\n      transpose_11 = matmul_11.transpose(1, 2)\n      matmul_11 = None\n      x_73 = transpose_11.reshape(4, 49, 384)\n      transpose_11 = None\n      x_74 = torch._C._nn.linear(x_73,\n          getattr_getattr_l__self___features___5_____1___attn_proj_weight,\n          getattr_getattr_l__self___features___5_____1___attn_proj_bias)\n      x_73 = None\n      getattr_getattr_l__self___features___5_____1___attn_proj_weight = None\n      getattr_getattr_l__self___features___5_____1___attn_proj_bias = None\n      x_75 = torch.nn.functional.dropout(x_74, p=0.0, training=True)\n      x_74 = None\n      x_76 = x_75.view(1, 2, 2, 7, 7, 384)\n      x_75 = None\n      permute_27 = x_76.permute(0, 1, 3, 2, 4, 5)\n      x_76 = None\n      x_77 = permute_27.reshape(1, 14, 14, 384)\n      permute_27 = None\n      x_78 = torch.roll(x_77, shifts=(3, 3), dims=(1, 2))\n      x_77 = None\n      getitem_37 = x_78[slice(None, None, None), slice(None, 14, None), slice(\n          None, 14, None), slice(None, None, None)]\n      x_78 = None\n      x_79 = getitem_37.contiguous()\n      getitem_37 = None\n      _log_api_usage_once_10 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      __temp_2095 = []\n      __temp_2095.extend((1, 1, 1, 1))\n      noise_16 = torch.empty(__temp_2095, dtype=torch.float32, device=device(type\n          ='cpu'))\n      noise_17 = noise_16.bernoulli_(0.9090909090909091)\n      noise_16 = None\n      div__8 = noise_17.div_(0.9090909090909091)\n      mul_14 = x_79 * noise_17\n      x_79 = None\n      noise_17 = None\n      x_80 = x_68 + mul_14\n      x_68 = None\n      mul_14 = None\n      getattr_getattr_l__self___features___5_____1___norm2 = (self.\n          getattr_getattr_L__self___features___5_____1___norm2(x_80))\n      getattr_getattr_l__self___features___5_____1___mlp_0 = (self.\n          getattr_getattr_L__self___features___5_____1___mlp_0(\n          getattr_getattr_l__self___features___5_____1___norm2))\n      getattr_getattr_l__self___features___5_____1___norm2 = None\n      getattr_getattr_l__self___features___5_____1___mlp_1 = (self.\n          getattr_getattr_L__self___features___5_____1___mlp_1(\n          getattr_getattr_l__self___features___5_____1___mlp_0))\n      getattr_getattr_l__self___features___5_____1___mlp_0 = None\n      getattr_getattr_l__self___features___5_____1___mlp_2 = (self.\n          getattr_getattr_L__self___features___5_____1___mlp_2(\n          getattr_getattr_l__self___features___5_____1___mlp_1))\n      getattr_getattr_l__self___features___5_____1___mlp_1 = None\n      getattr_getattr_l__self___features___5_____1___mlp_3 = (self.\n          getattr_getattr_L__self___features___5_____1___mlp_3(\n          getattr_getattr_l__self___features___5_____1___mlp_2))\n      getattr_getattr_l__self___features___5_____1___mlp_2 = None\n      getattr_getattr_l__self___features___5_____1___mlp_4 = (self.\n          getattr_getattr_L__self___features___5_____1___mlp_4(\n          getattr_getattr_l__self___features___5_____1___mlp_3))\n      getattr_getattr_l__self___features___5_____1___mlp_3 = None\n      _log_api_usage_once_11 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      __temp_2108 = []\n      __temp_2108.extend((1, 1, 1, 1))\n      noise_18 = torch.empty(__temp_2108, dtype=torch.float32, device=device(type\n          ='cpu'))\n      noise_19 = noise_18.bernoulli_(0.9090909090909091)\n      noise_18 = None\n      div__9 = noise_19.div_(0.9090909090909091)\n      mul_15 = getattr_getattr_l__self___features___5_____1___mlp_4 * noise_19\n      getattr_getattr_l__self___features___5_____1___mlp_4 = None\n      noise_19 = None\n      x_81 = x_80 + mul_15\n      x_80 = None\n      mul_15 = None\n      getattr_getattr_l__self___features___5_____2___norm1 = (self.\n          getattr_getattr_L__self___features___5_____2___norm1(x_81))\n      (\n          getattr_getattr_l__self___features___5_____2___attn_relative_position_bias_table\n          ) = (self.\n          getattr_getattr_L__self___features___5_____2___attn_relative_position_bias_table\n          )\n      (getattr_getattr_l__self___features___5_____2___attn_relative_position_index\n          ) = (self.\n          getattr_getattr_L__self___features___5_____2___attn_relative_position_index\n          )\n      relative_position_bias_24 = (\n          getattr_getattr_l__self___features___5_____2___attn_relative_position_bias_table\n          [\n          getattr_getattr_l__self___features___5_____2___attn_relative_position_index\n          ])\n      (\n          getattr_getattr_l__self___features___5_____2___attn_relative_position_bias_table\n          ) = None\n      (getattr_getattr_l__self___features___5_____2___attn_relative_position_index\n          ) = None\n      relative_position_bias_25 = relative_position_bias_24.view(49, 49, -1)\n      relative_position_bias_24 = None\n      permute_28 = relative_position_bias_25.permute(2, 0, 1)\n      relative_position_bias_25 = None\n      contiguous_12 = permute_28.contiguous()\n      permute_28 = None\n      relative_position_bias_27 = contiguous_12.unsqueeze(0)\n      contiguous_12 = None\n      getattr_getattr_l__self___features___5_____2___attn_qkv_weight = (self.\n          getattr_getattr_L__self___features___5_____2___attn_qkv_weight)\n      getattr_getattr_l__self___features___5_____2___attn_proj_weight = (self.\n          getattr_getattr_L__self___features___5_____2___attn_proj_weight)\n      getattr_getattr_l__self___features___5_____2___attn_qkv_bias = (self.\n          getattr_getattr_L__self___features___5_____2___attn_qkv_bias)\n      getattr_getattr_l__self___features___5_____2___attn_proj_bias = (self.\n          getattr_getattr_L__self___features___5_____2___attn_proj_bias)\n      x_82 = torch.nn.functional.pad(\n          getattr_getattr_l__self___features___5_____2___norm1, (0, 0, 0, 0, 0, 0))\n      getattr_getattr_l__self___features___5_____2___norm1 = None\n      x_83 = x_82.view(1, 2, 7, 2, 7, 384)\n      x_82 = None\n      permute_29 = x_83.permute(0, 1, 3, 2, 4, 5)\n      x_83 = None\n      x_84 = permute_29.reshape(4, 49, 384)\n      permute_29 = None\n      qkv_12 = torch._C._nn.linear(x_84,\n          getattr_getattr_l__self___features___5_____2___attn_qkv_weight,\n          getattr_getattr_l__self___features___5_____2___attn_qkv_bias)\n      x_84 = None\n      getattr_getattr_l__self___features___5_____2___attn_qkv_weight = None\n      getattr_getattr_l__self___features___5_____2___attn_qkv_bias = None\n      reshape_28 = qkv_12.reshape(4, 49, 3, 12, 32)\n      qkv_12 = None\n      qkv_13 = reshape_28.permute(2, 0, 3, 1, 4)\n      reshape_28 = None\n      q_12 = qkv_13[0]\n      k_6 = qkv_13[1]\n      v_6 = qkv_13[2]\n      qkv_13 = None\n      q_13 = q_12 * 0.1767766952966369\n      q_12 = None\n      transpose_12 = k_6.transpose(-2, -1)\n      k_6 = None\n      attn_33 = q_13.matmul(transpose_12)\n      q_13 = None\n      transpose_12 = None\n      attn_34 = attn_33 + relative_position_bias_27\n      attn_33 = None\n      relative_position_bias_27 = None\n      attn_35 = torch.nn.functional.softmax(attn_34, dim=-1)\n      attn_34 = None\n      attn_36 = torch.nn.functional.dropout(attn_35, p=0.0, training=True)\n      attn_35 = None\n      matmul_13 = attn_36.matmul(v_6)\n      attn_36 = None\n      v_6 = None\n      transpose_13 = matmul_13.transpose(1, 2)\n      matmul_13 = None\n      x_85 = transpose_13.reshape(4, 49, 384)\n      transpose_13 = None\n      x_86 = torch._C._nn.linear(x_85,\n          getattr_getattr_l__self___features___5_____2___attn_proj_weight,\n          getattr_getattr_l__self___features___5_____2___attn_proj_bias)\n      x_85 = None\n      getattr_getattr_l__self___features___5_____2___attn_proj_weight = None\n      getattr_getattr_l__self___features___5_____2___attn_proj_bias = None\n      x_87 = torch.nn.functional.dropout(x_86, p=0.0, training=True)\n      x_86 = None\n      x_88 = x_87.view(1, 2, 2, 7, 7, 384)\n      x_87 = None\n      permute_31 = x_88.permute(0, 1, 3, 2, 4, 5)\n      x_88 = None\n      x_89 = permute_31.reshape(1, 14, 14, 384)\n      permute_31 = None\n      getitem_42 = x_89[slice(None, None, None), slice(None, 14, None), slice(\n          None, 14, None), slice(None, None, None)]\n      x_89 = None\n      x_90 = getitem_42.contiguous()\n      getitem_42 = None\n      _log_api_usage_once_12 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      __temp_2144 = []\n      __temp_2144.extend((1, 1, 1, 1))\n      noise_20 = torch.empty(__temp_2144, dtype=torch.float32, device=device(type\n          ='cpu'))\n      noise_21 = noise_20.bernoulli_(0.8909090909090909)\n      noise_20 = None\n      div__10 = noise_21.div_(0.8909090909090909)\n      mul_17 = x_90 * noise_21\n      x_90 = None\n      noise_21 = None\n      x_91 = x_81 + mul_17\n      x_81 = None\n      mul_17 = None\n      getattr_getattr_l__self___features___5_____2___norm2 = (self.\n          getattr_getattr_L__self___features___5_____2___norm2(x_91))\n      getattr_getattr_l__self___features___5_____2___mlp_0 = (self.\n          getattr_getattr_L__self___features___5_____2___mlp_0(\n          getattr_getattr_l__self___features___5_____2___norm2))\n      getattr_getattr_l__self___features___5_____2___norm2 = None\n      getattr_getattr_l__self___features___5_____2___mlp_1 = (self.\n          getattr_getattr_L__self___features___5_____2___mlp_1(\n          getattr_getattr_l__self___features___5_____2___mlp_0))\n      getattr_getattr_l__self___features___5_____2___mlp_0 = None\n      getattr_getattr_l__self___features___5_____2___mlp_2 = (self.\n          getattr_getattr_L__self___features___5_____2___mlp_2(\n          getattr_getattr_l__self___features___5_____2___mlp_1))\n      getattr_getattr_l__self___features___5_____2___mlp_1 = None\n      getattr_getattr_l__self___features___5_____2___mlp_3 = (self.\n          getattr_getattr_L__self___features___5_____2___mlp_3(\n          getattr_getattr_l__self___features___5_____2___mlp_2))\n      getattr_getattr_l__self___features___5_____2___mlp_2 = None\n      getattr_getattr_l__self___features___5_____2___mlp_4 = (self.\n          getattr_getattr_L__self___features___5_____2___mlp_4(\n          getattr_getattr_l__self___features___5_____2___mlp_3))\n      getattr_getattr_l__self___features___5_____2___mlp_3 = None\n      _log_api_usage_once_13 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      __temp_2157 = []\n      __temp_2157.extend((1, 1, 1, 1))\n      noise_22 = torch.empty(__temp_2157, dtype=torch.float32, device=device(type\n          ='cpu'))\n      noise_23 = noise_22.bernoulli_(0.8909090909090909)\n      noise_22 = None\n      div__11 = noise_23.div_(0.8909090909090909)\n      mul_18 = getattr_getattr_l__self___features___5_____2___mlp_4 * noise_23\n      getattr_getattr_l__self___features___5_____2___mlp_4 = None\n      noise_23 = None\n      x_92 = x_91 + mul_18\n      x_91 = None\n      mul_18 = None\n      getattr_getattr_l__self___features___5_____3___norm1 = (self.\n          getattr_getattr_L__self___features___5_____3___norm1(x_92))\n      (\n          getattr_getattr_l__self___features___5_____3___attn_relative_position_bias_table\n          ) = (self.\n          getattr_getattr_L__self___features___5_____3___attn_relative_position_bias_table\n          )\n      (getattr_getattr_l__self___features___5_____3___attn_relative_position_index\n          ) = (self.\n          getattr_getattr_L__self___features___5_____3___attn_relative_position_index\n          )\n      relative_position_bias_28 = (\n          getattr_getattr_l__self___features___5_____3___attn_relative_position_bias_table\n          [\n          getattr_getattr_l__self___features___5_____3___attn_relative_position_index\n          ])\n      (\n          getattr_getattr_l__self___features___5_____3___attn_relative_position_bias_table\n          ) = None\n      (getattr_getattr_l__self___features___5_____3___attn_relative_position_index\n          ) = None\n      relative_position_bias_29 = relative_position_bias_28.view(49, 49, -1)\n      relative_position_bias_28 = None\n      permute_32 = relative_position_bias_29.permute(2, 0, 1)\n      relative_position_bias_29 = None\n      contiguous_14 = permute_32.contiguous()\n      permute_32 = None\n      relative_position_bias_31 = contiguous_14.unsqueeze(0)\n      contiguous_14 = None\n      getattr_getattr_l__self___features___5_____3___attn_qkv_weight = (self.\n          getattr_getattr_L__self___features___5_____3___attn_qkv_weight)\n      getattr_getattr_l__self___features___5_____3___attn_proj_weight = (self.\n          getattr_getattr_L__self___features___5_____3___attn_proj_weight)\n      getattr_getattr_l__self___features___5_____3___attn_qkv_bias = (self.\n          getattr_getattr_L__self___features___5_____3___attn_qkv_bias)\n      getattr_getattr_l__self___features___5_____3___attn_proj_bias = (self.\n          getattr_getattr_L__self___features___5_____3___attn_proj_bias)\n      x_93 = torch.nn.functional.pad(\n          getattr_getattr_l__self___features___5_____3___norm1, (0, 0, 0, 0, 0, 0))\n      getattr_getattr_l__self___features___5_____3___norm1 = None\n      x_94 = torch.roll(x_93, shifts=(-3, -3), dims=(1, 2))\n      x_93 = None\n      x_95 = x_94.view(1, 2, 7, 2, 7, 384)\n      x_94 = None\n      permute_33 = x_95.permute(0, 1, 3, 2, 4, 5)\n      x_95 = None\n      x_96 = permute_33.reshape(4, 49, 384)\n      permute_33 = None\n      qkv_14 = torch._C._nn.linear(x_96,\n          getattr_getattr_l__self___features___5_____3___attn_qkv_weight,\n          getattr_getattr_l__self___features___5_____3___attn_qkv_bias)\n      getattr_getattr_l__self___features___5_____3___attn_qkv_weight = None\n      getattr_getattr_l__self___features___5_____3___attn_qkv_bias = None\n      reshape_32 = qkv_14.reshape(4, 49, 3, 12, 32)\n      qkv_14 = None\n      qkv_15 = reshape_32.permute(2, 0, 3, 1, 4)\n      reshape_32 = None\n      q_14 = qkv_15[0]\n      k_7 = qkv_15[1]\n      v_7 = qkv_15[2]\n      qkv_15 = None\n      q_15 = q_14 * 0.1767766952966369\n      q_14 = None\n      transpose_14 = k_7.transpose(-2, -1)\n      k_7 = None\n      attn_37 = q_15.matmul(transpose_14)\n      q_15 = None\n      transpose_14 = None\n      attn_38 = attn_37 + relative_position_bias_31\n      attn_37 = None\n      relative_position_bias_31 = None\n      attn_mask_15 = x_96.new_zeros((14, 14))\n      x_96 = None\n      attn_mask_15[slice(0, -7, None), slice(0, -7, None)] = 0\n      setitem_27 = attn_mask_15\n      attn_mask_15[slice(0, -7, None), slice(-7, -3, None)] = 1\n      setitem_28 = attn_mask_15\n      attn_mask_15[slice(0, -7, None), slice(-3, None, None)] = 2\n      setitem_29 = attn_mask_15\n      attn_mask_15[slice(-7, -3, None), slice(0, -7, None)] = 3\n      setitem_30 = attn_mask_15\n      attn_mask_15[slice(-7, -3, None), slice(-7, -3, None)] = 4\n      setitem_31 = attn_mask_15\n      attn_mask_15[slice(-7, -3, None), slice(-3, None, None)] = 5\n      setitem_32 = attn_mask_15\n      attn_mask_15[slice(-3, None, None), slice(0, -7, None)] = 6\n      setitem_33 = attn_mask_15\n      attn_mask_15[slice(-3, None, None), slice(-7, -3, None)] = 7\n      setitem_34 = attn_mask_15\n      attn_mask_15[slice(-3, None, None), slice(-3, None, None)] = 8\n      setitem_35 = attn_mask_15\n      attn_mask_16 = attn_mask_15.view(2, 7, 2, 7)\n      attn_mask_15 = None\n      permute_35 = attn_mask_16.permute(0, 2, 1, 3)\n      attn_mask_16 = None\n      attn_mask_17 = permute_35.reshape(4, 49)\n      permute_35 = None\n      unsqueeze_20 = attn_mask_17.unsqueeze(1)\n      unsqueeze_21 = attn_mask_17.unsqueeze(2)\n      attn_mask_17 = None\n      attn_mask_18 = unsqueeze_20 - unsqueeze_21\n      unsqueeze_20 = None\n      unsqueeze_21 = None\n      ne_3 = attn_mask_18 != 0\n      masked_fill_6 = attn_mask_18.masked_fill(ne_3, -100.0)\n      ne_3 = None\n      eq_3 = attn_mask_18 == 0\n      attn_mask_18 = None\n      attn_mask_19 = masked_fill_6.masked_fill(eq_3, 0.0)\n      masked_fill_6 = None\n      eq_3 = None\n      attn_39 = attn_38.view(1, 4, 12, 49, 49)\n      attn_38 = None\n      unsqueeze_22 = attn_mask_19.unsqueeze(1)\n      attn_mask_19 = None\n      unsqueeze_23 = unsqueeze_22.unsqueeze(0)\n      unsqueeze_22 = None\n      attn_40 = attn_39 + unsqueeze_23\n      attn_39 = None\n      unsqueeze_23 = None\n      attn_41 = attn_40.view(-1, 12, 49, 49)\n      attn_40 = None\n      attn_42 = torch.nn.functional.softmax(attn_41, dim=-1)\n      attn_41 = None\n      attn_43 = torch.nn.functional.dropout(attn_42, p=0.0, training=True)\n      attn_42 = None\n      matmul_15 = attn_43.matmul(v_7)\n      attn_43 = None\n      v_7 = None\n      transpose_15 = matmul_15.transpose(1, 2)\n      matmul_15 = None\n      x_97 = transpose_15.reshape(4, 49, 384)\n      transpose_15 = None\n      x_98 = torch._C._nn.linear(x_97,\n          getattr_getattr_l__self___features___5_____3___attn_proj_weight,\n          getattr_getattr_l__self___features___5_____3___attn_proj_bias)\n      x_97 = None\n      getattr_getattr_l__self___features___5_____3___attn_proj_weight = None\n      getattr_getattr_l__self___features___5_____3___attn_proj_bias = None\n      x_99 = torch.nn.functional.dropout(x_98, p=0.0, training=True)\n      x_98 = None\n      x_100 = x_99.view(1, 2, 2, 7, 7, 384)\n      x_99 = None\n      permute_36 = x_100.permute(0, 1, 3, 2, 4, 5)\n      x_100 = None\n      x_101 = permute_36.reshape(1, 14, 14, 384)\n      permute_36 = None\n      x_102 = torch.roll(x_101, shifts=(3, 3), dims=(1, 2))\n      x_101 = None\n      getitem_47 = x_102[slice(None, None, None), slice(None, 14, None), slice(\n          None, 14, None), slice(None, None, None)]\n      x_102 = None\n      x_103 = getitem_47.contiguous()\n      getitem_47 = None\n      _log_api_usage_once_14 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      __temp_2225 = []\n      __temp_2225.extend((1, 1, 1, 1))\n      noise_24 = torch.empty(__temp_2225, dtype=torch.float32, device=device(type\n          ='cpu'))\n      noise_25 = noise_24.bernoulli_(0.8727272727272727)\n      noise_24 = None\n      div__12 = noise_25.div_(0.8727272727272727)\n      mul_20 = x_103 * noise_25\n      x_103 = None\n      noise_25 = None\n      x_104 = x_92 + mul_20\n      x_92 = None\n      mul_20 = None\n      getattr_getattr_l__self___features___5_____3___norm2 = (self.\n          getattr_getattr_L__self___features___5_____3___norm2(x_104))\n      getattr_getattr_l__self___features___5_____3___mlp_0 = (self.\n          getattr_getattr_L__self___features___5_____3___mlp_0(\n          getattr_getattr_l__self___features___5_____3___norm2))\n      getattr_getattr_l__self___features___5_____3___norm2 = None\n      getattr_getattr_l__self___features___5_____3___mlp_1 = (self.\n          getattr_getattr_L__self___features___5_____3___mlp_1(\n          getattr_getattr_l__self___features___5_____3___mlp_0))\n      getattr_getattr_l__self___features___5_____3___mlp_0 = None\n      getattr_getattr_l__self___features___5_____3___mlp_2 = (self.\n          getattr_getattr_L__self___features___5_____3___mlp_2(\n          getattr_getattr_l__self___features___5_____3___mlp_1))\n      getattr_getattr_l__self___features___5_____3___mlp_1 = None\n      getattr_getattr_l__self___features___5_____3___mlp_3 = (self.\n          getattr_getattr_L__self___features___5_____3___mlp_3(\n          getattr_getattr_l__self___features___5_____3___mlp_2))\n      getattr_getattr_l__self___features___5_____3___mlp_2 = None\n      getattr_getattr_l__self___features___5_____3___mlp_4 = (self.\n          getattr_getattr_L__self___features___5_____3___mlp_4(\n          getattr_getattr_l__self___features___5_____3___mlp_3))\n      getattr_getattr_l__self___features___5_____3___mlp_3 = None\n      _log_api_usage_once_15 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      __temp_2238 = []\n      __temp_2238.extend((1, 1, 1, 1))\n      noise_26 = torch.empty(__temp_2238, dtype=torch.float32, device=device(type\n          ='cpu'))\n      noise_27 = noise_26.bernoulli_(0.8727272727272727)\n      noise_26 = None\n      div__13 = noise_27.div_(0.8727272727272727)\n      mul_21 = getattr_getattr_l__self___features___5_____3___mlp_4 * noise_27\n      getattr_getattr_l__self___features___5_____3___mlp_4 = None\n      noise_27 = None\n      x_105 = x_104 + mul_21\n      x_104 = None\n      mul_21 = None\n      getattr_getattr_l__self___features___5_____4___norm1 = (self.\n          getattr_getattr_L__self___features___5_____4___norm1(x_105))\n      (\n          getattr_getattr_l__self___features___5_____4___attn_relative_position_bias_table\n          ) = (self.\n          getattr_getattr_L__self___features___5_____4___attn_relative_position_bias_table\n          )\n      (getattr_getattr_l__self___features___5_____4___attn_relative_position_index\n          ) = (self.\n          getattr_getattr_L__self___features___5_____4___attn_relative_position_index\n          )\n      relative_position_bias_32 = (\n          getattr_getattr_l__self___features___5_____4___attn_relative_position_bias_table\n          [\n          getattr_getattr_l__self___features___5_____4___attn_relative_position_index\n          ])\n      (\n          getattr_getattr_l__self___features___5_____4___attn_relative_position_bias_table\n          ) = None\n      (getattr_getattr_l__self___features___5_____4___attn_relative_position_index\n          ) = None\n      relative_position_bias_33 = relative_position_bias_32.view(49, 49, -1)\n      relative_position_bias_32 = None\n      permute_37 = relative_position_bias_33.permute(2, 0, 1)\n      relative_position_bias_33 = None\n      contiguous_16 = permute_37.contiguous()\n      permute_37 = None\n      relative_position_bias_35 = contiguous_16.unsqueeze(0)\n      contiguous_16 = None\n      getattr_getattr_l__self___features___5_____4___attn_qkv_weight = (self.\n          getattr_getattr_L__self___features___5_____4___attn_qkv_weight)\n      getattr_getattr_l__self___features___5_____4___attn_proj_weight = (self.\n          getattr_getattr_L__self___features___5_____4___attn_proj_weight)\n      getattr_getattr_l__self___features___5_____4___attn_qkv_bias = (self.\n          getattr_getattr_L__self___features___5_____4___attn_qkv_bias)\n      getattr_getattr_l__self___features___5_____4___attn_proj_bias = (self.\n          getattr_getattr_L__self___features___5_____4___attn_proj_bias)\n      x_106 = torch.nn.functional.pad(\n          getattr_getattr_l__self___features___5_____4___norm1, (0, 0, 0, 0, 0, 0))\n      getattr_getattr_l__self___features___5_____4___norm1 = None\n      x_107 = x_106.view(1, 2, 7, 2, 7, 384)\n      x_106 = None\n      permute_38 = x_107.permute(0, 1, 3, 2, 4, 5)\n      x_107 = None\n      x_108 = permute_38.reshape(4, 49, 384)\n      permute_38 = None\n      qkv_16 = torch._C._nn.linear(x_108,\n          getattr_getattr_l__self___features___5_____4___attn_qkv_weight,\n          getattr_getattr_l__self___features___5_____4___attn_qkv_bias)\n      x_108 = None\n      getattr_getattr_l__self___features___5_____4___attn_qkv_weight = None\n      getattr_getattr_l__self___features___5_____4___attn_qkv_bias = None\n      reshape_37 = qkv_16.reshape(4, 49, 3, 12, 32)\n      qkv_16 = None\n      qkv_17 = reshape_37.permute(2, 0, 3, 1, 4)\n      reshape_37 = None\n      q_16 = qkv_17[0]\n      k_8 = qkv_17[1]\n      v_8 = qkv_17[2]\n      qkv_17 = None\n      q_17 = q_16 * 0.1767766952966369\n      q_16 = None\n      transpose_16 = k_8.transpose(-2, -1)\n      k_8 = None\n      attn_44 = q_17.matmul(transpose_16)\n      q_17 = None\n      transpose_16 = None\n      attn_45 = attn_44 + relative_position_bias_35\n      attn_44 = None\n      relative_position_bias_35 = None\n      attn_46 = torch.nn.functional.softmax(attn_45, dim=-1)\n      attn_45 = None\n      attn_47 = torch.nn.functional.dropout(attn_46, p=0.0, training=True)\n      attn_46 = None\n      matmul_17 = attn_47.matmul(v_8)\n      attn_47 = None\n      v_8 = None\n      transpose_17 = matmul_17.transpose(1, 2)\n      matmul_17 = None\n      x_109 = transpose_17.reshape(4, 49, 384)\n      transpose_17 = None\n      x_110 = torch._C._nn.linear(x_109,\n          getattr_getattr_l__self___features___5_____4___attn_proj_weight,\n          getattr_getattr_l__self___features___5_____4___attn_proj_bias)\n      x_109 = None\n      getattr_getattr_l__self___features___5_____4___attn_proj_weight = None\n      getattr_getattr_l__self___features___5_____4___attn_proj_bias = None\n      x_111 = torch.nn.functional.dropout(x_110, p=0.0, training=True)\n      x_110 = None\n      x_112 = x_111.view(1, 2, 2, 7, 7, 384)\n      x_111 = None\n      permute_40 = x_112.permute(0, 1, 3, 2, 4, 5)\n      x_112 = None\n      x_113 = permute_40.reshape(1, 14, 14, 384)\n      permute_40 = None\n      getitem_52 = x_113[slice(None, None, None), slice(None, 14, None), slice(\n          None, 14, None), slice(None, None, None)]\n      x_113 = None\n      x_114 = getitem_52.contiguous()\n      getitem_52 = None\n      _log_api_usage_once_16 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      __temp_2274 = []\n      __temp_2274.extend((1, 1, 1, 1))\n      noise_28 = torch.empty(__temp_2274, dtype=torch.float32, device=device(type\n          ='cpu'))\n      noise_29 = noise_28.bernoulli_(0.8545454545454545)\n      noise_28 = None\n      div__14 = noise_29.div_(0.8545454545454545)\n      mul_23 = x_114 * noise_29\n      x_114 = None\n      noise_29 = None\n      x_115 = x_105 + mul_23\n      x_105 = None\n      mul_23 = None\n      getattr_getattr_l__self___features___5_____4___norm2 = (self.\n          getattr_getattr_L__self___features___5_____4___norm2(x_115))\n      getattr_getattr_l__self___features___5_____4___mlp_0 = (self.\n          getattr_getattr_L__self___features___5_____4___mlp_0(\n          getattr_getattr_l__self___features___5_____4___norm2))\n      getattr_getattr_l__self___features___5_____4___norm2 = None\n      getattr_getattr_l__self___features___5_____4___mlp_1 = (self.\n          getattr_getattr_L__self___features___5_____4___mlp_1(\n          getattr_getattr_l__self___features___5_____4___mlp_0))\n      getattr_getattr_l__self___features___5_____4___mlp_0 = None\n      getattr_getattr_l__self___features___5_____4___mlp_2 = (self.\n          getattr_getattr_L__self___features___5_____4___mlp_2(\n          getattr_getattr_l__self___features___5_____4___mlp_1))\n      getattr_getattr_l__self___features___5_____4___mlp_1 = None\n      getattr_getattr_l__self___features___5_____4___mlp_3 = (self.\n          getattr_getattr_L__self___features___5_____4___mlp_3(\n          getattr_getattr_l__self___features___5_____4___mlp_2))\n      getattr_getattr_l__self___features___5_____4___mlp_2 = None\n      getattr_getattr_l__self___features___5_____4___mlp_4 = (self.\n          getattr_getattr_L__self___features___5_____4___mlp_4(\n          getattr_getattr_l__self___features___5_____4___mlp_3))\n      getattr_getattr_l__self___features___5_____4___mlp_3 = None\n      _log_api_usage_once_17 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      __temp_2287 = []\n      __temp_2287.extend((1, 1, 1, 1))\n      noise_30 = torch.empty(__temp_2287, dtype=torch.float32, device=device(type\n          ='cpu'))\n      noise_31 = noise_30.bernoulli_(0.8545454545454545)\n      noise_30 = None\n      div__15 = noise_31.div_(0.8545454545454545)\n      mul_24 = getattr_getattr_l__self___features___5_____4___mlp_4 * noise_31\n      getattr_getattr_l__self___features___5_____4___mlp_4 = None\n      noise_31 = None\n      x_116 = x_115 + mul_24\n      x_115 = None\n      mul_24 = None\n      getattr_getattr_l__self___features___5_____5___norm1 = (self.\n          getattr_getattr_L__self___features___5_____5___norm1(x_116))\n      (\n          getattr_getattr_l__self___features___5_____5___attn_relative_position_bias_table\n          ) = (self.\n          getattr_getattr_L__self___features___5_____5___attn_relative_position_bias_table\n          )\n      (getattr_getattr_l__self___features___5_____5___attn_relative_position_index\n          ) = (self.\n          getattr_getattr_L__self___features___5_____5___attn_relative_position_index\n          )\n      relative_position_bias_36 = (\n          getattr_getattr_l__self___features___5_____5___attn_relative_position_bias_table\n          [\n          getattr_getattr_l__self___features___5_____5___attn_relative_position_index\n          ])\n      (\n          getattr_getattr_l__self___features___5_____5___attn_relative_position_bias_table\n          ) = None\n      (getattr_getattr_l__self___features___5_____5___attn_relative_position_index\n          ) = None\n      relative_position_bias_37 = relative_position_bias_36.view(49, 49, -1)\n      relative_position_bias_36 = None\n      permute_41 = relative_position_bias_37.permute(2, 0, 1)\n      relative_position_bias_37 = None\n      contiguous_18 = permute_41.contiguous()\n      permute_41 = None\n      relative_position_bias_39 = contiguous_18.unsqueeze(0)\n      contiguous_18 = None\n      getattr_getattr_l__self___features___5_____5___attn_qkv_weight = (self.\n          getattr_getattr_L__self___features___5_____5___attn_qkv_weight)\n      getattr_getattr_l__self___features___5_____5___attn_proj_weight = (self.\n          getattr_getattr_L__self___features___5_____5___attn_proj_weight)\n      getattr_getattr_l__self___features___5_____5___attn_qkv_bias = (self.\n          getattr_getattr_L__self___features___5_____5___attn_qkv_bias)\n      getattr_getattr_l__self___features___5_____5___attn_proj_bias = (self.\n          getattr_getattr_L__self___features___5_____5___attn_proj_bias)\n      x_117 = torch.nn.functional.pad(\n          getattr_getattr_l__self___features___5_____5___norm1, (0, 0, 0, 0, 0, 0))\n      getattr_getattr_l__self___features___5_____5___norm1 = None\n      x_118 = torch.roll(x_117, shifts=(-3, -3), dims=(1, 2))\n      x_117 = None\n      x_119 = x_118.view(1, 2, 7, 2, 7, 384)\n      x_118 = None\n      permute_42 = x_119.permute(0, 1, 3, 2, 4, 5)\n      x_119 = None\n      x_120 = permute_42.reshape(4, 49, 384)\n      permute_42 = None\n      qkv_18 = torch._C._nn.linear(x_120,\n          getattr_getattr_l__self___features___5_____5___attn_qkv_weight,\n          getattr_getattr_l__self___features___5_____5___attn_qkv_bias)\n      getattr_getattr_l__self___features___5_____5___attn_qkv_weight = None\n      getattr_getattr_l__self___features___5_____5___attn_qkv_bias = None\n      reshape_41 = qkv_18.reshape(4, 49, 3, 12, 32)\n      qkv_18 = None\n      qkv_19 = reshape_41.permute(2, 0, 3, 1, 4)\n      reshape_41 = None\n      q_18 = qkv_19[0]\n      k_9 = qkv_19[1]\n      v_9 = qkv_19[2]\n      qkv_19 = None\n      q_19 = q_18 * 0.1767766952966369\n      q_18 = None\n      transpose_18 = k_9.transpose(-2, -1)\n      k_9 = None\n      attn_48 = q_19.matmul(transpose_18)\n      q_19 = None\n      transpose_18 = None\n      attn_49 = attn_48 + relative_position_bias_39\n      attn_48 = None\n      relative_position_bias_39 = None\n      attn_mask_20 = x_120.new_zeros((14, 14))\n      x_120 = None\n      attn_mask_20[slice(0, -7, None), slice(0, -7, None)] = 0\n      setitem_36 = attn_mask_20\n      attn_mask_20[slice(0, -7, None), slice(-7, -3, None)] = 1\n      setitem_37 = attn_mask_20\n      attn_mask_20[slice(0, -7, None), slice(-3, None, None)] = 2\n      setitem_38 = attn_mask_20\n      attn_mask_20[slice(-7, -3, None), slice(0, -7, None)] = 3\n      setitem_39 = attn_mask_20\n      attn_mask_20[slice(-7, -3, None), slice(-7, -3, None)] = 4\n      setitem_40 = attn_mask_20\n      attn_mask_20[slice(-7, -3, None), slice(-3, None, None)] = 5\n      setitem_41 = attn_mask_20\n      attn_mask_20[slice(-3, None, None), slice(0, -7, None)] = 6\n      setitem_42 = attn_mask_20\n      attn_mask_20[slice(-3, None, None), slice(-7, -3, None)] = 7\n      setitem_43 = attn_mask_20\n      attn_mask_20[slice(-3, None, None), slice(-3, None, None)] = 8\n      setitem_44 = attn_mask_20\n      attn_mask_21 = attn_mask_20.view(2, 7, 2, 7)\n      attn_mask_20 = None\n      permute_44 = attn_mask_21.permute(0, 2, 1, 3)\n      attn_mask_21 = None\n      attn_mask_22 = permute_44.reshape(4, 49)\n      permute_44 = None\n      unsqueeze_26 = attn_mask_22.unsqueeze(1)\n      unsqueeze_27 = attn_mask_22.unsqueeze(2)\n      attn_mask_22 = None\n      attn_mask_23 = unsqueeze_26 - unsqueeze_27\n      unsqueeze_26 = None\n      unsqueeze_27 = None\n      ne_4 = attn_mask_23 != 0\n      masked_fill_8 = attn_mask_23.masked_fill(ne_4, -100.0)\n      ne_4 = None\n      eq_4 = attn_mask_23 == 0\n      attn_mask_23 = None\n      attn_mask_24 = masked_fill_8.masked_fill(eq_4, 0.0)\n      masked_fill_8 = None\n      eq_4 = None\n      attn_50 = attn_49.view(1, 4, 12, 49, 49)\n      attn_49 = None\n      unsqueeze_28 = attn_mask_24.unsqueeze(1)\n      attn_mask_24 = None\n      unsqueeze_29 = unsqueeze_28.unsqueeze(0)\n      unsqueeze_28 = None\n      attn_51 = attn_50 + unsqueeze_29\n      attn_50 = None\n      unsqueeze_29 = None\n      attn_52 = attn_51.view(-1, 12, 49, 49)\n      attn_51 = None\n      attn_53 = torch.nn.functional.softmax(attn_52, dim=-1)\n      attn_52 = None\n      attn_54 = torch.nn.functional.dropout(attn_53, p=0.0, training=True)\n      attn_53 = None\n      matmul_19 = attn_54.matmul(v_9)\n      attn_54 = None\n      v_9 = None\n      transpose_19 = matmul_19.transpose(1, 2)\n      matmul_19 = None\n      x_121 = transpose_19.reshape(4, 49, 384)\n      transpose_19 = None\n      x_122 = torch._C._nn.linear(x_121,\n          getattr_getattr_l__self___features___5_____5___attn_proj_weight,\n          getattr_getattr_l__self___features___5_____5___attn_proj_bias)\n      x_121 = None\n      getattr_getattr_l__self___features___5_____5___attn_proj_weight = None\n      getattr_getattr_l__self___features___5_____5___attn_proj_bias = None\n      x_123 = torch.nn.functional.dropout(x_122, p=0.0, training=True)\n      x_122 = None\n      x_124 = x_123.view(1, 2, 2, 7, 7, 384)\n      x_123 = None\n      permute_45 = x_124.permute(0, 1, 3, 2, 4, 5)\n      x_124 = None\n      x_125 = permute_45.reshape(1, 14, 14, 384)\n      permute_45 = None\n      x_126 = torch.roll(x_125, shifts=(3, 3), dims=(1, 2))\n      x_125 = None\n      getitem_57 = x_126[slice(None, None, None), slice(None, 14, None), slice(\n          None, 14, None), slice(None, None, None)]\n      x_126 = None\n      x_127 = getitem_57.contiguous()\n      getitem_57 = None\n      _log_api_usage_once_18 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      __temp_2355 = []\n      __temp_2355.extend((1, 1, 1, 1))\n      noise_32 = torch.empty(__temp_2355, dtype=torch.float32, device=device(type\n          ='cpu'))\n      noise_33 = noise_32.bernoulli_(0.8363636363636364)\n      noise_32 = None\n      div__16 = noise_33.div_(0.8363636363636364)\n      mul_26 = x_127 * noise_33\n      x_127 = None\n      noise_33 = None\n      x_128 = x_116 + mul_26\n      x_116 = None\n      mul_26 = None\n      getattr_getattr_l__self___features___5_____5___norm2 = (self.\n          getattr_getattr_L__self___features___5_____5___norm2(x_128))\n      getattr_getattr_l__self___features___5_____5___mlp_0 = (self.\n          getattr_getattr_L__self___features___5_____5___mlp_0(\n          getattr_getattr_l__self___features___5_____5___norm2))\n      getattr_getattr_l__self___features___5_____5___norm2 = None\n      getattr_getattr_l__self___features___5_____5___mlp_1 = (self.\n          getattr_getattr_L__self___features___5_____5___mlp_1(\n          getattr_getattr_l__self___features___5_____5___mlp_0))\n      getattr_getattr_l__self___features___5_____5___mlp_0 = None\n      getattr_getattr_l__self___features___5_____5___mlp_2 = (self.\n          getattr_getattr_L__self___features___5_____5___mlp_2(\n          getattr_getattr_l__self___features___5_____5___mlp_1))\n      getattr_getattr_l__self___features___5_____5___mlp_1 = None\n      getattr_getattr_l__self___features___5_____5___mlp_3 = (self.\n          getattr_getattr_L__self___features___5_____5___mlp_3(\n          getattr_getattr_l__self___features___5_____5___mlp_2))\n      getattr_getattr_l__self___features___5_____5___mlp_2 = None\n      getattr_getattr_l__self___features___5_____5___mlp_4 = (self.\n          getattr_getattr_L__self___features___5_____5___mlp_4(\n          getattr_getattr_l__self___features___5_____5___mlp_3))\n      getattr_getattr_l__self___features___5_____5___mlp_3 = None\n      _log_api_usage_once_19 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      __temp_2368 = []\n      __temp_2368.extend((1, 1, 1, 1))\n      noise_34 = torch.empty(__temp_2368, dtype=torch.float32, device=device(type\n          ='cpu'))\n      noise_35 = noise_34.bernoulli_(0.8363636363636364)\n      noise_34 = None\n      div__17 = noise_35.div_(0.8363636363636364)\n      mul_27 = getattr_getattr_l__self___features___5_____5___mlp_4 * noise_35\n      getattr_getattr_l__self___features___5_____5___mlp_4 = None\n      noise_35 = None\n      x_129 = x_128 + mul_27\n      x_128 = None\n      mul_27 = None\n      x_130 = torch.nn.functional.pad(x_129, (0, 0, 0, 0, 0, 0))\n      x_129 = None\n      x0_2 = x_130[Ellipsis, slice(0, None, 2), slice(0, None, 2), slice(None,\n          None, None)]\n      x1_2 = x_130[Ellipsis, slice(1, None, 2), slice(0, None, 2), slice(None,\n          None, None)]\n      x2_2 = x_130[Ellipsis, slice(0, None, 2), slice(1, None, 2), slice(None,\n          None, None)]\n      x3_2 = x_130[Ellipsis, slice(1, None, 2), slice(1, None, 2), slice(None,\n          None, None)]\n      x_130 = None\n      x_132 = torch.cat([x0_2, x1_2, x2_2, x3_2], -1)\n      x0_2 = None\n      x1_2 = None\n      x2_2 = None\n      x3_2 = None\n      x_133 = self.getattr_L__self___features___6___norm(x_132)\n      x_132 = None\n      x_134 = self.getattr_L__self___features___6___reduction(x_133)\n      x_133 = None\n      getattr_getattr_l__self___features___7_____0___norm1 = (self.\n          getattr_getattr_L__self___features___7_____0___norm1(x_134))\n      (\n          getattr_getattr_l__self___features___7_____0___attn_relative_position_bias_table\n          ) = (self.\n          getattr_getattr_L__self___features___7_____0___attn_relative_position_bias_table\n          )\n      (getattr_getattr_l__self___features___7_____0___attn_relative_position_index\n          ) = (self.\n          getattr_getattr_L__self___features___7_____0___attn_relative_position_index\n          )\n      relative_position_bias_40 = (\n          getattr_getattr_l__self___features___7_____0___attn_relative_position_bias_table\n          [\n          getattr_getattr_l__self___features___7_____0___attn_relative_position_index\n          ])\n      (\n          getattr_getattr_l__self___features___7_____0___attn_relative_position_bias_table\n          ) = None\n      (getattr_getattr_l__self___features___7_____0___attn_relative_position_index\n          ) = None\n      relative_position_bias_41 = relative_position_bias_40.view(49, 49, -1)\n      relative_position_bias_40 = None\n      permute_46 = relative_position_bias_41.permute(2, 0, 1)\n      relative_position_bias_41 = None\n      contiguous_20 = permute_46.contiguous()\n      permute_46 = None\n      relative_position_bias_43 = contiguous_20.unsqueeze(0)\n      contiguous_20 = None\n      getattr_getattr_l__self___features___7_____0___attn_qkv_weight = (self.\n          getattr_getattr_L__self___features___7_____0___attn_qkv_weight)\n      getattr_getattr_l__self___features___7_____0___attn_proj_weight = (self.\n          getattr_getattr_L__self___features___7_____0___attn_proj_weight)\n      getattr_getattr_l__self___features___7_____0___attn_qkv_bias = (self.\n          getattr_getattr_L__self___features___7_____0___attn_qkv_bias)\n      getattr_getattr_l__self___features___7_____0___attn_proj_bias = (self.\n          getattr_getattr_L__self___features___7_____0___attn_proj_bias)\n      x_135 = torch.nn.functional.pad(\n          getattr_getattr_l__self___features___7_____0___norm1, (0, 0, 0, 0, 0, 0))\n      getattr_getattr_l__self___features___7_____0___norm1 = None\n      x_136 = x_135.view(1, 1, 7, 1, 7, 768)\n      x_135 = None\n      permute_47 = x_136.permute(0, 1, 3, 2, 4, 5)\n      x_136 = None\n      x_137 = permute_47.reshape(1, 49, 768)\n      permute_47 = None\n      qkv_20 = torch._C._nn.linear(x_137,\n          getattr_getattr_l__self___features___7_____0___attn_qkv_weight,\n          getattr_getattr_l__self___features___7_____0___attn_qkv_bias)\n      x_137 = None\n      getattr_getattr_l__self___features___7_____0___attn_qkv_weight = None\n      getattr_getattr_l__self___features___7_____0___attn_qkv_bias = None\n      reshape_46 = qkv_20.reshape(1, 49, 3, 24, 32)\n      qkv_20 = None\n      qkv_21 = reshape_46.permute(2, 0, 3, 1, 4)\n      reshape_46 = None\n      q_20 = qkv_21[0]\n      k_10 = qkv_21[1]\n      v_10 = qkv_21[2]\n      qkv_21 = None\n      q_21 = q_20 * 0.1767766952966369\n      q_20 = None\n      transpose_20 = k_10.transpose(-2, -1)\n      k_10 = None\n      attn_55 = q_21.matmul(transpose_20)\n      q_21 = None\n      transpose_20 = None\n      attn_56 = attn_55 + relative_position_bias_43\n      attn_55 = None\n      relative_position_bias_43 = None\n      attn_57 = torch.nn.functional.softmax(attn_56, dim=-1)\n      attn_56 = None\n      attn_58 = torch.nn.functional.dropout(attn_57, p=0.0, training=True)\n      attn_57 = None\n      matmul_21 = attn_58.matmul(v_10)\n      attn_58 = None\n      v_10 = None\n      transpose_21 = matmul_21.transpose(1, 2)\n      matmul_21 = None\n      x_138 = transpose_21.reshape(1, 49, 768)\n      transpose_21 = None\n      x_139 = torch._C._nn.linear(x_138,\n          getattr_getattr_l__self___features___7_____0___attn_proj_weight,\n          getattr_getattr_l__self___features___7_____0___attn_proj_bias)\n      x_138 = None\n      getattr_getattr_l__self___features___7_____0___attn_proj_weight = None\n      getattr_getattr_l__self___features___7_____0___attn_proj_bias = None\n      x_140 = torch.nn.functional.dropout(x_139, p=0.0, training=True)\n      x_139 = None\n      x_141 = x_140.view(1, 1, 1, 7, 7, 768)\n      x_140 = None\n      permute_49 = x_141.permute(0, 1, 3, 2, 4, 5)\n      x_141 = None\n      x_142 = permute_49.reshape(1, 7, 7, 768)\n      permute_49 = None\n      getitem_66 = x_142[slice(None, None, None), slice(None, 7, None), slice(\n          None, 7, None), slice(None, None, None)]\n      x_142 = None\n      x_143 = getitem_66.contiguous()\n      getitem_66 = None\n      _log_api_usage_once_20 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      __temp_2421 = []\n      __temp_2421.extend((1, 1, 1, 1))\n      noise_36 = torch.empty(__temp_2421, dtype=torch.float32, device=device(type\n          ='cpu'))\n      noise_37 = noise_36.bernoulli_(0.8181818181818181)\n      noise_36 = None\n      div__18 = noise_37.div_(0.8181818181818181)\n      mul_29 = x_143 * noise_37\n      x_143 = None\n      noise_37 = None\n      x_144 = x_134 + mul_29\n      x_134 = None\n      mul_29 = None\n      getattr_getattr_l__self___features___7_____0___norm2 = (self.\n          getattr_getattr_L__self___features___7_____0___norm2(x_144))\n      getattr_getattr_l__self___features___7_____0___mlp_0 = (self.\n          getattr_getattr_L__self___features___7_____0___mlp_0(\n          getattr_getattr_l__self___features___7_____0___norm2))\n      getattr_getattr_l__self___features___7_____0___norm2 = None\n      getattr_getattr_l__self___features___7_____0___mlp_1 = (self.\n          getattr_getattr_L__self___features___7_____0___mlp_1(\n          getattr_getattr_l__self___features___7_____0___mlp_0))\n      getattr_getattr_l__self___features___7_____0___mlp_0 = None\n      getattr_getattr_l__self___features___7_____0___mlp_2 = (self.\n          getattr_getattr_L__self___features___7_____0___mlp_2(\n          getattr_getattr_l__self___features___7_____0___mlp_1))\n      getattr_getattr_l__self___features___7_____0___mlp_1 = None\n      getattr_getattr_l__self___features___7_____0___mlp_3 = (self.\n          getattr_getattr_L__self___features___7_____0___mlp_3(\n          getattr_getattr_l__self___features___7_____0___mlp_2))\n      getattr_getattr_l__self___features___7_____0___mlp_2 = None\n      getattr_getattr_l__self___features___7_____0___mlp_4 = (self.\n          getattr_getattr_L__self___features___7_____0___mlp_4(\n          getattr_getattr_l__self___features___7_____0___mlp_3))\n      getattr_getattr_l__self___features___7_____0___mlp_3 = None\n      _log_api_usage_once_21 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      __temp_2434 = []\n      __temp_2434.extend((1, 1, 1, 1))\n      noise_38 = torch.empty(__temp_2434, dtype=torch.float32, device=device(type\n          ='cpu'))\n      noise_39 = noise_38.bernoulli_(0.8181818181818181)\n      noise_38 = None\n      div__19 = noise_39.div_(0.8181818181818181)\n      mul_30 = getattr_getattr_l__self___features___7_____0___mlp_4 * noise_39\n      getattr_getattr_l__self___features___7_____0___mlp_4 = None\n      noise_39 = None\n      x_145 = x_144 + mul_30\n      x_144 = None\n      mul_30 = None\n      getattr_getattr_l__self___features___7_____1___norm1 = (self.\n          getattr_getattr_L__self___features___7_____1___norm1(x_145))\n      (\n          getattr_getattr_l__self___features___7_____1___attn_relative_position_bias_table\n          ) = (self.\n          getattr_getattr_L__self___features___7_____1___attn_relative_position_bias_table\n          )\n      (getattr_getattr_l__self___features___7_____1___attn_relative_position_index\n          ) = (self.\n          getattr_getattr_L__self___features___7_____1___attn_relative_position_index\n          )\n      relative_position_bias_44 = (\n          getattr_getattr_l__self___features___7_____1___attn_relative_position_bias_table\n          [\n          getattr_getattr_l__self___features___7_____1___attn_relative_position_index\n          ])\n      (\n          getattr_getattr_l__self___features___7_____1___attn_relative_position_bias_table\n          ) = None\n      (getattr_getattr_l__self___features___7_____1___attn_relative_position_index\n          ) = None\n      relative_position_bias_45 = relative_position_bias_44.view(49, 49, -1)\n      relative_position_bias_44 = None\n      permute_50 = relative_position_bias_45.permute(2, 0, 1)\n      relative_position_bias_45 = None\n      contiguous_22 = permute_50.contiguous()\n      permute_50 = None\n      relative_position_bias_47 = contiguous_22.unsqueeze(0)\n      contiguous_22 = None\n      getattr_getattr_l__self___features___7_____1___attn_qkv_weight = (self.\n          getattr_getattr_L__self___features___7_____1___attn_qkv_weight)\n      getattr_getattr_l__self___features___7_____1___attn_proj_weight = (self.\n          getattr_getattr_L__self___features___7_____1___attn_proj_weight)\n      getattr_getattr_l__self___features___7_____1___attn_qkv_bias = (self.\n          getattr_getattr_L__self___features___7_____1___attn_qkv_bias)\n      getattr_getattr_l__self___features___7_____1___attn_proj_bias = (self.\n          getattr_getattr_L__self___features___7_____1___attn_proj_bias)\n      x_146 = torch.nn.functional.pad(\n          getattr_getattr_l__self___features___7_____1___norm1, (0, 0, 0, 0, 0, 0))\n      getattr_getattr_l__self___features___7_____1___norm1 = None\n      x_147 = x_146.view(1, 1, 7, 1, 7, 768)\n      x_146 = None\n      permute_51 = x_147.permute(0, 1, 3, 2, 4, 5)\n      x_147 = None\n      x_148 = permute_51.reshape(1, 49, 768)\n      permute_51 = None\n      qkv_22 = torch._C._nn.linear(x_148,\n          getattr_getattr_l__self___features___7_____1___attn_qkv_weight,\n          getattr_getattr_l__self___features___7_____1___attn_qkv_bias)\n      x_148 = None\n      getattr_getattr_l__self___features___7_____1___attn_qkv_weight = None\n      getattr_getattr_l__self___features___7_____1___attn_qkv_bias = None\n      reshape_50 = qkv_22.reshape(1, 49, 3, 24, 32)\n      qkv_22 = None\n      qkv_23 = reshape_50.permute(2, 0, 3, 1, 4)\n      reshape_50 = None\n      q_22 = qkv_23[0]\n      k_11 = qkv_23[1]\n      v_11 = qkv_23[2]\n      qkv_23 = None\n      q_23 = q_22 * 0.1767766952966369\n      q_22 = None\n      transpose_22 = k_11.transpose(-2, -1)\n      k_11 = None\n      attn_59 = q_23.matmul(transpose_22)\n      q_23 = None\n      transpose_22 = None\n      attn_60 = attn_59 + relative_position_bias_47\n      attn_59 = None\n      relative_position_bias_47 = None\n      attn_61 = torch.nn.functional.softmax(attn_60, dim=-1)\n      attn_60 = None\n      attn_62 = torch.nn.functional.dropout(attn_61, p=0.0, training=True)\n      attn_61 = None\n      matmul_23 = attn_62.matmul(v_11)\n      attn_62 = None\n      v_11 = None\n      transpose_23 = matmul_23.transpose(1, 2)\n      matmul_23 = None\n      x_149 = transpose_23.reshape(1, 49, 768)\n      transpose_23 = None\n      x_150 = torch._C._nn.linear(x_149,\n          getattr_getattr_l__self___features___7_____1___attn_proj_weight,\n          getattr_getattr_l__self___features___7_____1___attn_proj_bias)\n      x_149 = None\n      getattr_getattr_l__self___features___7_____1___attn_proj_weight = None\n      getattr_getattr_l__self___features___7_____1___attn_proj_bias = None\n      x_151 = torch.nn.functional.dropout(x_150, p=0.0, training=True)\n      x_150 = None\n      x_152 = x_151.view(1, 1, 1, 7, 7, 768)\n      x_151 = None\n      permute_53 = x_152.permute(0, 1, 3, 2, 4, 5)\n      x_152 = None\n      x_153 = permute_53.reshape(1, 7, 7, 768)\n      permute_53 = None\n      getitem_71 = x_153[slice(None, None, None), slice(None, 7, None), slice(\n          None, 7, None), slice(None, None, None)]\n      x_153 = None\n      x_154 = getitem_71.contiguous()\n      getitem_71 = None\n      _log_api_usage_once_22 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      __temp_2470 = []\n      __temp_2470.extend((1, 1, 1, 1))\n      noise_40 = torch.empty(__temp_2470, dtype=torch.float32, device=device(type\n          ='cpu'))\n      noise_41 = noise_40.bernoulli_(0.8)\n      noise_40 = None\n      div__20 = noise_41.div_(0.8)\n      mul_32 = x_154 * noise_41\n      x_154 = None\n      noise_41 = None\n      x_155 = x_145 + mul_32\n      x_145 = None\n      mul_32 = None\n      getattr_getattr_l__self___features___7_____1___norm2 = (self.\n          getattr_getattr_L__self___features___7_____1___norm2(x_155))\n      getattr_getattr_l__self___features___7_____1___mlp_0 = (self.\n          getattr_getattr_L__self___features___7_____1___mlp_0(\n          getattr_getattr_l__self___features___7_____1___norm2))\n      getattr_getattr_l__self___features___7_____1___norm2 = None\n      getattr_getattr_l__self___features___7_____1___mlp_1 = (self.\n          getattr_getattr_L__self___features___7_____1___mlp_1(\n          getattr_getattr_l__self___features___7_____1___mlp_0))\n      getattr_getattr_l__self___features___7_____1___mlp_0 = None\n      getattr_getattr_l__self___features___7_____1___mlp_2 = (self.\n          getattr_getattr_L__self___features___7_____1___mlp_2(\n          getattr_getattr_l__self___features___7_____1___mlp_1))\n      getattr_getattr_l__self___features___7_____1___mlp_1 = None\n      getattr_getattr_l__self___features___7_____1___mlp_3 = (self.\n          getattr_getattr_L__self___features___7_____1___mlp_3(\n          getattr_getattr_l__self___features___7_____1___mlp_2))\n      getattr_getattr_l__self___features___7_____1___mlp_2 = None\n      getattr_getattr_l__self___features___7_____1___mlp_4 = (self.\n          getattr_getattr_L__self___features___7_____1___mlp_4(\n          getattr_getattr_l__self___features___7_____1___mlp_3))\n      getattr_getattr_l__self___features___7_____1___mlp_3 = None\n      _log_api_usage_once_23 = torch._C._log_api_usage_once(\n          'torchvision.ops.stochastic_depth.stochastic_depth')\n      __temp_2483 = []\n      __temp_2483.extend((1, 1, 1, 1))\n      noise_42 = torch.empty(__temp_2483, dtype=torch.float32, device=device(type\n          ='cpu'))\n      noise_43 = noise_42.bernoulli_(0.8)\n      noise_42 = None\n      div__21 = noise_43.div_(0.8)\n      mul_33 = getattr_getattr_l__self___features___7_____1___mlp_4 * noise_43\n      getattr_getattr_l__self___features___7_____1___mlp_4 = None\n      noise_43 = None\n      x_157 = x_155 + mul_33\n      x_155 = None\n      mul_33 = None\n      x_158 = self.L__self___norm(x_157)\n      x_157 = None\n      __temp_2490 = []\n      __temp_2490.extend((0, 3, 1, 2))\n      x_159 = torch.permute(x_158, __temp_2490)\n      x_158 = None\n      x_160 = self.L__self___avgpool(x_159)\n      x_159 = None\n      x_161 = self.L__self___flatten(x_160)\n      x_160 = None\n      x_162 = self.L__self___head(x_161)\n      x_161 = None\n      return x_162,\n\n  ```\n</details>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interactive_explain(model_compile)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T15:01:10.736301Z",
     "start_time": "2023-12-02T15:00:50.656521Z"
    }
   },
   "id": "99748d0f4bf26b0f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a40d2ad403ffa29b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
