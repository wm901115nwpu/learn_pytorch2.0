{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "Q7vmkS5RgbsF",
    "outputId": "be199526-384c-465a-f5e6-c9758cba5f53"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nWelcome to PyTorch 2 Tutorial!\\n\\nIn this notebook, we will demonstrate introductory concepts for running TorchDynamo and the tools\\nto understand the graph capture process.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Welcome to the PyTorch 2 Tutorial!\n",
    "\n",
    "In this notebook, we will demonstrate introductory concepts for running TorchDynamo and the tools\n",
    "to understand the graph capture process.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T3NPbpqkcg8i",
    "outputId": "21cc8c43-da92-4e19-87ef-66679aa46bb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.2.1+cu121\n",
      "Uninstalling torch-2.2.1+cu121:\n",
      "  Successfully uninstalled torch-2.2.1+cu121\n",
      "Found existing installation: fastai 2.7.14\n",
      "Uninstalling fastai-2.7.14:\n",
      "  Successfully uninstalled fastai-2.7.14\n",
      "Found existing installation: torchtext 0.17.1\n",
      "Uninstalling torchtext-0.17.1:\n",
      "  Successfully uninstalled torchtext-0.17.1\n",
      "Looking in indexes: https://download.pytorch.org/whl/nightly/cpu\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cpu/torch-2.4.0.dev20240422%2Bcpu-cp310-cp310-linux_x86_64.whl (192.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.0/192.0 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
      "Installing collected packages: torch\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 2.4.0.dev20240422+cpu which is incompatible.\n",
      "torchvision 0.17.1+cu121 requires torch==2.2.1, but you have torch 2.4.0.dev20240422+cpu which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-2.4.0.dev20240422+cpu\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Install the latest PyTorch Build.\n",
    "ETA: 1 minute\n",
    "\"\"\"\n",
    "# resolve dependency conflict on colab and may not be necessary on local environement\n",
    "!pip uninstall torch -y\n",
    "!pip uninstall fastai -y\n",
    "!pip uninstall torchtext -y\n",
    "\n",
    "!pip install torch==2.3.1+cu121 --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "Qbc8rGOqdqlG",
    "outputId": "04402d1a-040b-4af7-fd83-06c6b0ed8c84"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'2.4.0.dev20240422+cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__ # 2.4.0.dev20240422+cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rW_kPBnucyku",
    "outputId": "86e8ee51-92c3-4cc0-f8cd-1b72f7250b97"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-26 07:29:02,700] [1/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-04-26 07:29:02,701] [1/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['x'], '_dynamo_dynamic_indices') == False           # x *= x  # <ipython-input-2-2a36c5f136f4>:13 in fn\n",
      "[2024-04-26 07:29:02,703] [1/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['y'], '_dynamo_dynamic_indices') == False           # x /= y  # <ipython-input-2-2a36c5f136f4>:14 in fn\n",
      "[2024-04-26 07:29:02,705] [1/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:379 in init_ambient_guards\n",
      "[2024-04-26 07:29:02,707] [1/0] torch._dynamo.guards.__guards: [DEBUG] (___skip_backend_check() or ___current_backend() == ___lookup_backend(138809320518080))  # _dynamo/output_graph.py:385 in init_ambient_guards\n",
      "[2024-04-26 07:29:02,709] [1/0] torch._dynamo.guards.__guards: [DEBUG] ___compile_config_hash() == 'afe34f4bda34a849c5a40bd5f182778f'  # _dynamo/output_graph.py:387 in init_ambient_guards\n",
      "[2024-04-26 07:29:02,711] [1/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['x'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[2, 2], stride=[2, 1])  # x *= x  # <ipython-input-2-2a36c5f136f4>:13 in fn\n",
      "[2024-04-26 07:29:02,712] [1/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['y'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[2, 2], stride=[2, 1])  # x /= y  # <ipython-input-2-2a36c5f136f4>:14 in fn\n",
      "[2024-04-26 07:29:02,723] torch._dynamo.guards.__recompiles: [DEBUG] Recompiling function fn in <ipython-input-2-2a36c5f136f4>:11\n",
      "[2024-04-26 07:29:02,723] torch._dynamo.guards.__recompiles: [DEBUG]     triggered by the following guard failure(s):\n",
      "[2024-04-26 07:29:02,723] torch._dynamo.guards.__recompiles: [DEBUG]     - tensor 'L['x']' size mismatch at index 0. expected 2, actual 4\n",
      "[2024-04-26 07:29:02,725] torch._dynamo.convert_frame.__recompiles: [DEBUG] Current config does not match config saved when compiling\n",
      "[2024-04-26 07:29:02,725] torch._dynamo.convert_frame.__recompiles: [DEBUG] Saved hash: afe34f4, Current hash: 88a14d4\n",
      "[2024-04-26 07:29:02,725] torch._dynamo.convert_frame.__recompiles: [DEBUG] Restoring saved config.\n",
      "[2024-04-26 07:29:02,727] torch._dynamo.convert_frame.__recompiles: [DEBUG] * automatic_dynamic_shapes=False (prev: True)\n",
      "[2024-04-26 07:29:02,803] [1/1] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-04-26 07:29:02,805] [1/1] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['x'], '_dynamo_dynamic_indices') == False           # x *= x  # <ipython-input-2-2a36c5f136f4>:13 in fn\n",
      "[2024-04-26 07:29:02,806] [1/1] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['y'], '_dynamo_dynamic_indices') == False           # x /= y  # <ipython-input-2-2a36c5f136f4>:14 in fn\n",
      "[2024-04-26 07:29:02,808] [1/1] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:379 in init_ambient_guards\n",
      "[2024-04-26 07:29:02,810] [1/1] torch._dynamo.guards.__guards: [DEBUG] (___skip_backend_check() or ___current_backend() == ___lookup_backend(138809320518080))  # _dynamo/output_graph.py:385 in init_ambient_guards\n",
      "[2024-04-26 07:29:02,812] [1/1] torch._dynamo.guards.__guards: [DEBUG] ___compile_config_hash() == 'afe34f4bda34a849c5a40bd5f182778f'  # _dynamo/output_graph.py:387 in init_ambient_guards\n",
      "[2024-04-26 07:29:02,814] [1/1] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['x'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[4, 2], stride=[2, 1])  # x *= x  # <ipython-input-2-2a36c5f136f4>:13 in fn\n",
      "[2024-04-26 07:29:02,815] [1/1] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['y'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[4, 2], stride=[2, 1])  # x /= y  # <ipython-input-2-2a36c5f136f4>:14 in fn\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Example 1: Compiling a basic python function\n",
    "\n",
    "In this first example we'll compile a basic python function using torch.compile\n",
    "and demonstrate how to use logging to view the guards and recompiles if guards fail\n",
    "\n",
    "\"\"\"\n",
    "import torch\n",
    "\n",
    "# Disable dynamic shapes for the purposes of this example\n",
    "@torch.compile(dynamic=False)\n",
    "def fn(x, y):\n",
    "  x *= x\n",
    "  x /= y\n",
    "  return x + 1\n",
    "\n",
    "# Before running our function,\n",
    "# we set logs to observe different artifacts of the compilation process\n",
    "# in this case setting the guards kwarg to True will print the relevant guards\n",
    "torch._logging.set_logs(guards=True)\n",
    "fn(torch.ones(2, 2), torch.ones(2, 2))\n",
    "\n",
    "# Other useful options:\n",
    "# guards - display generated guards\n",
    "# graph - display captured graph\n",
    "# output_code - display the generated output code from inductor\n",
    "# bytecode - display the rewritten bytecode for the function you are compiling\n",
    "# recompiles - print which guard failed if the function has been compiled previously\n",
    "torch._logging.set_logs(recompiles=True, guards=True)\n",
    "fn(torch.ones(4, 2), torch.ones(4, 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W8EyZfJnggXf",
    "outputId": "42508f3a-daec-405f-d657-43f02b388b41"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-26 07:32:56,338] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-04-26 07:32:56,338] [2/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_4 <eval_with_key>.57 opcode         name    target                   args          kwargs\n",
      "[2024-04-26 07:32:56,338] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  ------  -----------------------  ------------  --------\n",
      "[2024-04-26 07:32:56,338] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_x_    L_x_                     ()            {}\n",
      "[2024-04-26 07:32:56,338] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_y_    L_y_                     ()            {}\n",
      "[2024-04-26 07:32:56,338] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_z_    L_z_                     ()            {}\n",
      "[2024-04-26 07:32:56,338] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul     <built-in function mul>  (l_x_, l_y_)  {}\n",
      "[2024-04-26 07:32:56,338] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add     <built-in function add>  (mul, l_z_)   {}\n",
      "[2024-04-26 07:32:56,338] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output  output                   ((add,),)     {}\n",
      "[2024-04-26 07:32:56,338] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-04-26 07:32:57,905] [2/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-04-26 07:32:57,906] [2/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['n'], 95938460250912)                      # if n > 0:  # <ipython-input-3-6f5b09f6080d>:14 in with_int\n",
      "[2024-04-26 07:32:57,909] [2/0] torch._dynamo.guards.__guards: [DEBUG] L['n'] == 0                                                   # if n > 0:  # <ipython-input-3-6f5b09f6080d>:14 in with_int\n",
      "[2024-04-26 07:32:57,911] [2/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['x'], '_dynamo_dynamic_indices') == False           # return x * y + z  # <ipython-input-3-6f5b09f6080d>:17 in with_int\n",
      "[2024-04-26 07:32:57,914] [2/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['y'], '_dynamo_dynamic_indices') == False           # return x * y + z  # <ipython-input-3-6f5b09f6080d>:17 in with_int\n",
      "[2024-04-26 07:32:57,916] [2/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['z'], '_dynamo_dynamic_indices') == False           # return x * y + z  # <ipython-input-3-6f5b09f6080d>:17 in with_int\n",
      "[2024-04-26 07:32:57,920] [2/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:379 in init_ambient_guards\n",
      "[2024-04-26 07:32:57,921] [2/0] torch._dynamo.guards.__guards: [DEBUG] (___skip_backend_check() or ___current_backend() == ___lookup_backend(138809436597424))  # _dynamo/output_graph.py:385 in init_ambient_guards\n",
      "[2024-04-26 07:32:57,923] [2/0] torch._dynamo.guards.__guards: [DEBUG] ___compile_config_hash() == '88a14d47e62622e2d97d70c8d06ad8bd'  # _dynamo/output_graph.py:387 in init_ambient_guards\n",
      "[2024-04-26 07:32:57,924] [2/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['x'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[2, 2], stride=[2, 1])  # return x * y + z  # <ipython-input-3-6f5b09f6080d>:17 in with_int\n",
      "[2024-04-26 07:32:57,925] [2/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['y'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[2, 2], stride=[2, 1])  # return x * y + z  # <ipython-input-3-6f5b09f6080d>:17 in with_int\n",
      "[2024-04-26 07:32:57,926] [2/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['z'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[2, 2], stride=[2, 1])  # return x * y + z  # <ipython-input-3-6f5b09f6080d>:17 in with_int\n",
      "[2024-04-26 07:32:57,933] torch._dynamo.guards.__recompiles: [DEBUG] Recompiling function with_int in <ipython-input-3-6f5b09f6080d>:12\n",
      "[2024-04-26 07:32:57,933] torch._dynamo.guards.__recompiles: [DEBUG]     triggered by the following guard failure(s):\n",
      "[2024-04-26 07:32:57,933] torch._dynamo.guards.__recompiles: [DEBUG]     - L['n'] == 0                                                   # if n > 0:  # <ipython-input-3-6f5b09f6080d>:14 in with_int\n",
      "[2024-04-26 07:32:57,950] [2/1] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-04-26 07:32:57,950] [2/1] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_5 <eval_with_key>.64 opcode         name    target                    args          kwargs\n",
      "[2024-04-26 07:32:57,950] [2/1] torch._dynamo.output_graph.__graph: [DEBUG] -------------  ------  ------------------------  ------------  --------\n",
      "[2024-04-26 07:32:57,950] [2/1] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_x_    L_x_                      ()            {}\n",
      "[2024-04-26 07:32:57,950] [2/1] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_y_    L_y_                      ()            {}\n",
      "[2024-04-26 07:32:57,950] [2/1] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_z_    L_z_                      ()            {}\n",
      "[2024-04-26 07:32:57,950] [2/1] torch._dynamo.output_graph.__graph: [DEBUG] call_function  x       <built-in function iadd>  (l_x_, l_y_)  {}\n",
      "[2024-04-26 07:32:57,950] [2/1] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul     <built-in function mul>   (x, l_y_)     {}\n",
      "[2024-04-26 07:32:57,950] [2/1] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add     <built-in function add>   (mul, l_z_)   {}\n",
      "[2024-04-26 07:32:57,950] [2/1] torch._dynamo.output_graph.__graph: [DEBUG] output         output  output                    ((add,),)     {}\n",
      "[2024-04-26 07:32:57,950] [2/1] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-04-26 07:32:59,612] [2/1] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-04-26 07:32:59,613] [2/1] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['n'], 95938460250912)                      # if n > 0:  # <ipython-input-3-6f5b09f6080d>:14 in with_int\n",
      "[2024-04-26 07:32:59,615] [2/1] torch._dynamo.guards.__guards: [DEBUG] L['n'] == 1                                                   # if n > 0:  # <ipython-input-3-6f5b09f6080d>:14 in with_int\n",
      "[2024-04-26 07:32:59,617] [2/1] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['x'], '_dynamo_dynamic_indices') == False           # x += y  # <ipython-input-3-6f5b09f6080d>:15 in with_int\n",
      "[2024-04-26 07:32:59,619] [2/1] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['y'], '_dynamo_dynamic_indices') == False           # x += y  # <ipython-input-3-6f5b09f6080d>:15 in with_int\n",
      "[2024-04-26 07:32:59,622] [2/1] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['z'], '_dynamo_dynamic_indices') == False           # return x * y + z  # <ipython-input-3-6f5b09f6080d>:17 in with_int\n",
      "[2024-04-26 07:32:59,625] [2/1] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:379 in init_ambient_guards\n",
      "[2024-04-26 07:32:59,627] [2/1] torch._dynamo.guards.__guards: [DEBUG] (___skip_backend_check() or ___current_backend() == ___lookup_backend(138809436597424))  # _dynamo/output_graph.py:385 in init_ambient_guards\n",
      "[2024-04-26 07:32:59,628] [2/1] torch._dynamo.guards.__guards: [DEBUG] ___compile_config_hash() == '88a14d47e62622e2d97d70c8d06ad8bd'  # _dynamo/output_graph.py:387 in init_ambient_guards\n",
      "[2024-04-26 07:32:59,629] [2/1] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['x'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[2, 2], stride=[2, 1])  # x += y  # <ipython-input-3-6f5b09f6080d>:15 in with_int\n",
      "[2024-04-26 07:32:59,630] [2/1] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['y'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[2, 2], stride=[2, 1])  # x += y  # <ipython-input-3-6f5b09f6080d>:15 in with_int\n",
      "[2024-04-26 07:32:59,631] [2/1] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['z'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[2, 2], stride=[2, 1])  # return x * y + z  # <ipython-input-3-6f5b09f6080d>:17 in with_int\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2.],\n",
       "        [2., 2.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Example 2: Specializaton on non-tensors and displaying the captured graph\n",
    "\n",
    "In this example, dynamo will specialize on an int because it is a non-tensor value,\n",
    "so a guard will be generated for it.\n",
    "\n",
    "There will be two graphs generated because the guard failure will trigger a recompile and\n",
    "the logs will be used to display these two graphs along with the recompile reason.\n",
    "\"\"\"\n",
    "import torch\n",
    "\n",
    "\n",
    "@torch.compile()\n",
    "def with_int(x, y, z, n):\n",
    "  if n > 0:\n",
    "    x += y\n",
    "\n",
    "  return x * y + z\n",
    "\n",
    "# View the captured graphs with graph=True, and recompiles to see the guard failure\n",
    "# due to `flag` changing from True -> False\n",
    "torch._logging.set_logs(graph=True, recompiles=True, guards=True)\n",
    "with_int(torch.ones(2, 2), torch.ones(2, 2), torch.zeros(2, 2), 0)\n",
    "with_int(torch.ones(2, 2), torch.ones(2, 2), torch.zeros(2, 2), 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JPruiwHhc1C5",
    "outputId": "02b9a623-d5cf-4026-f789-cf72d5f5f267"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-26 07:36:59,801] [3/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG] Graph break: 'skip function graph_break in file /usr/local/lib/python3.10/dist-packages/torch/_dynamo/decorators.py'', skipped according skipfiles.SKIP_DIRS' from user code at:\n",
      "[2024-04-26 07:36:59,801] [3/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"<ipython-input-4-70e0bc373d08>\", line 15, in graph_break_0\n",
      "[2024-04-26 07:36:59,801] [3/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     torch._dynamo.graph_break()\n",
      "[2024-04-26 07:36:59,801] [3/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG] \n",
      "[2024-04-26 07:37:01,407] [3/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG] ORIGINAL BYTECODE graph_break_0 <ipython-input-4-70e0bc373d08> line 12 \n",
      "[2024-04-26 07:37:01,407] [3/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]  14           0 LOAD_FAST                0 (x)\n",
      "[2024-04-26 07:37:01,407] [3/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]               2 LOAD_FAST                1 (y)\n",
      "[2024-04-26 07:37:01,407] [3/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]               4 BINARY_ADD\n",
      "[2024-04-26 07:37:01,407] [3/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]               6 STORE_FAST               2 (z)\n",
      "[2024-04-26 07:37:01,407] [3/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:37:01,407] [3/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]  15           8 LOAD_GLOBAL              0 (torch)\n",
      "[2024-04-26 07:37:01,407] [3/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              10 LOAD_ATTR                1 (_dynamo)\n",
      "[2024-04-26 07:37:01,407] [3/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              12 LOAD_METHOD              2 (graph_break)\n",
      "[2024-04-26 07:37:01,407] [3/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              14 CALL_METHOD              0\n",
      "[2024-04-26 07:37:01,407] [3/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              16 POP_TOP\n",
      "[2024-04-26 07:37:01,407] [3/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:37:01,407] [3/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]  16          18 LOAD_FAST                2 (z)\n",
      "[2024-04-26 07:37:01,407] [3/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              20 LOAD_FAST                0 (x)\n",
      "[2024-04-26 07:37:01,407] [3/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              22 INPLACE_ADD\n",
      "[2024-04-26 07:37:01,407] [3/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              24 STORE_FAST               2 (z)\n",
      "[2024-04-26 07:37:01,407] [3/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:37:01,407] [3/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]  17          26 LOAD_FAST                2 (z)\n",
      "[2024-04-26 07:37:01,407] [3/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              28 RETURN_VALUE\n",
      "[2024-04-26 07:37:01,407] [3/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:37:01,407] [3/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:37:01,409] [3/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG] MODIFIED BYTECODE graph_break_0 <ipython-input-4-70e0bc373d08> line 12 \n",
      "[2024-04-26 07:37:01,409] [3/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]  12           0 LOAD_GLOBAL              3 (__compiled_fn_6)\n",
      "[2024-04-26 07:37:01,409] [3/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]               2 LOAD_FAST                0 (x)\n",
      "[2024-04-26 07:37:01,409] [3/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]               4 LOAD_FAST                1 (y)\n",
      "[2024-04-26 07:37:01,409] [3/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]               6 CALL_FUNCTION            2\n",
      "[2024-04-26 07:37:01,409] [3/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]               8 STORE_FAST               4 (graph_out_0)\n",
      "[2024-04-26 07:37:01,409] [3/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              10 LOAD_GLOBAL              0 (torch)\n",
      "[2024-04-26 07:37:01,409] [3/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              12 LOAD_ATTR                1 (_dynamo)\n",
      "[2024-04-26 07:37:01,409] [3/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              14 LOAD_ATTR                2 (graph_break)\n",
      "[2024-04-26 07:37:01,409] [3/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              16 LOAD_FAST                4 (graph_out_0)\n",
      "[2024-04-26 07:37:01,409] [3/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              18 LOAD_CONST               1 (0)\n",
      "[2024-04-26 07:37:01,409] [3/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              20 BINARY_SUBSCR\n",
      "[2024-04-26 07:37:01,409] [3/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              22 STORE_FAST               2 (z)\n",
      "[2024-04-26 07:37:01,409] [3/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:37:01,409] [3/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]  15          24 CALL_FUNCTION            0\n",
      "[2024-04-26 07:37:01,409] [3/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              26 LOAD_GLOBAL              4 (__resume_at_16_7)\n",
      "[2024-04-26 07:37:01,409] [3/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              28 ROT_TWO\n",
      "[2024-04-26 07:37:01,409] [3/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              30 LOAD_FAST                0 (x)\n",
      "[2024-04-26 07:37:01,409] [3/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              32 LOAD_FAST                2 (z)\n",
      "[2024-04-26 07:37:01,409] [3/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              34 CALL_FUNCTION            3\n",
      "[2024-04-26 07:37:01,409] [3/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              36 RETURN_VALUE\n",
      "[2024-04-26 07:37:01,409] [3/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:37:01,409] [3/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:37:03,037] [4/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] ORIGINAL BYTECODE resume_in_graph_break_0 <ipython-input-4-70e0bc373d08> line 15 \n",
      "[2024-04-26 07:37:03,037] [4/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]  15           0 LOAD_FAST                0 (___stack0)\n",
      "[2024-04-26 07:37:03,037] [4/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               2 JUMP_ABSOLUTE           10 (to 20)\n",
      "[2024-04-26 07:37:03,037] [4/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               4 LOAD_FAST                1 (x)\n",
      "[2024-04-26 07:37:03,037] [4/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               6 LOAD_FAST                3 (y)\n",
      "[2024-04-26 07:37:03,037] [4/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               8 BINARY_ADD\n",
      "[2024-04-26 07:37:03,037] [4/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              10 STORE_FAST               2 (z)\n",
      "[2024-04-26 07:37:03,037] [4/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              12 LOAD_GLOBAL              0 (torch)\n",
      "[2024-04-26 07:37:03,037] [4/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              14 LOAD_ATTR                1 (_dynamo)\n",
      "[2024-04-26 07:37:03,037] [4/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              16 LOAD_ATTR                2 (graph_break)\n",
      "[2024-04-26 07:37:03,037] [4/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              18 CALL_FUNCTION            0\n",
      "[2024-04-26 07:37:03,037] [4/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]         >>   20 POP_TOP\n",
      "[2024-04-26 07:37:03,037] [4/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:37:03,037] [4/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]  16          22 LOAD_FAST                2 (z)\n",
      "[2024-04-26 07:37:03,037] [4/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              24 LOAD_FAST                1 (x)\n",
      "[2024-04-26 07:37:03,037] [4/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              26 INPLACE_ADD\n",
      "[2024-04-26 07:37:03,037] [4/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              28 STORE_FAST               2 (z)\n",
      "[2024-04-26 07:37:03,037] [4/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:37:03,037] [4/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]  17          30 LOAD_FAST                2 (z)\n",
      "[2024-04-26 07:37:03,037] [4/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              32 RETURN_VALUE\n",
      "[2024-04-26 07:37:03,037] [4/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:37:03,037] [4/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:37:03,038] [4/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] MODIFIED BYTECODE resume_in_graph_break_0 <ipython-input-4-70e0bc373d08> line 15 \n",
      "[2024-04-26 07:37:03,038] [4/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]  15           0 LOAD_GLOBAL              3 (__compiled_fn_8)\n",
      "[2024-04-26 07:37:03,038] [4/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               2 LOAD_FAST                2 (z)\n",
      "[2024-04-26 07:37:03,038] [4/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               4 LOAD_FAST                1 (x)\n",
      "[2024-04-26 07:37:03,038] [4/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               6 CALL_FUNCTION            2\n",
      "[2024-04-26 07:37:03,038] [4/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               8 UNPACK_SEQUENCE          1\n",
      "[2024-04-26 07:37:03,038] [4/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              10 RETURN_VALUE\n",
      "[2024-04-26 07:37:03,038] [4/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:37:03,038] [4/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Example 3: Graph break on unsupported behavior\n",
    "\n",
    "This example demonstrates a graph break - a region of code that dynamo doesn't support.\n",
    "Dynamo compiles the current subgraph and generates a continuation function to call immediately\n",
    "after the unsupported code. As a result the rewritten bytecode will consist of 1) a call to the compiled subgraph\n",
    "2) the unmodified unsupported region and 3) the call to the continuation (these are named \"resume_in_<function name>\"\n",
    "in the generated bytecode)\n",
    "\"\"\"\n",
    "import torch\n",
    "\n",
    "\n",
    "@torch.compile()\n",
    "def graph_break_0(x, y):\n",
    "  z = x + y\n",
    "  torch._dynamo.graph_break()\n",
    "  z += x\n",
    "  return z\n",
    "\n",
    "# Observe the structure of the modified bytecode and the graph break that caused it\n",
    "torch._logging.set_logs(graph_breaks=True, bytecode=True)\n",
    "graph_break_0(torch.ones(4, 4), torch.zeros(4, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hWVQqe0ltUTP",
    "outputId": "2220d2a6-1492-446c-c20e-3a8939472cee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-26 07:40:46,031] [5/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG] Graph break: Tensor.item from user code at:\n",
      "[2024-04-26 07:40:46,031] [5/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"<ipython-input-5-1fcb39c11676>\", line 13, in data_dep\n",
      "[2024-04-26 07:40:46,031] [5/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     if x.item() == 1: # <--- graph break here, extracting data from a tensor.\n",
      "[2024-04-26 07:40:46,031] [5/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG] \n",
      "[2024-04-26 07:40:46,038] [5/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG] ORIGINAL BYTECODE data_dep <ipython-input-5-1fcb39c11676> line 11 \n",
      "[2024-04-26 07:40:46,038] [5/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]  13           0 LOAD_FAST                0 (x)\n",
      "[2024-04-26 07:40:46,038] [5/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]               2 LOAD_METHOD              0 (item)\n",
      "[2024-04-26 07:40:46,038] [5/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]               4 CALL_METHOD              0\n",
      "[2024-04-26 07:40:46,038] [5/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]               6 LOAD_CONST               1 (1)\n",
      "[2024-04-26 07:40:46,038] [5/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]               8 COMPARE_OP               2 (==)\n",
      "[2024-04-26 07:40:46,038] [5/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              10 POP_JUMP_IF_FALSE       16 (to 32)\n",
      "[2024-04-26 07:40:46,038] [5/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:40:46,038] [5/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]  14          12 LOAD_FAST                1 (y)\n",
      "[2024-04-26 07:40:46,038] [5/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              14 LOAD_CONST               2 (2)\n",
      "[2024-04-26 07:40:46,038] [5/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              16 INPLACE_ADD\n",
      "[2024-04-26 07:40:46,038] [5/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              18 STORE_FAST               1 (y)\n",
      "[2024-04-26 07:40:46,038] [5/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:40:46,038] [5/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]  15          20 LOAD_FAST                0 (x)\n",
      "[2024-04-26 07:40:46,038] [5/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              22 LOAD_CONST               3 (3)\n",
      "[2024-04-26 07:40:46,038] [5/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              24 INPLACE_ADD\n",
      "[2024-04-26 07:40:46,038] [5/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              26 STORE_FAST               0 (x)\n",
      "[2024-04-26 07:40:46,038] [5/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:40:46,038] [5/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]  19          28 LOAD_FAST                1 (y)\n",
      "[2024-04-26 07:40:46,038] [5/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              30 RETURN_VALUE\n",
      "[2024-04-26 07:40:46,038] [5/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:40:46,038] [5/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]  17     >>   32 LOAD_FAST                1 (y)\n",
      "[2024-04-26 07:40:46,038] [5/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              34 LOAD_CONST               3 (3)\n",
      "[2024-04-26 07:40:46,038] [5/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              36 INPLACE_ADD\n",
      "[2024-04-26 07:40:46,038] [5/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              38 STORE_FAST               1 (y)\n",
      "[2024-04-26 07:40:46,038] [5/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:40:46,038] [5/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]  19          40 LOAD_FAST                1 (y)\n",
      "[2024-04-26 07:40:46,038] [5/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              42 RETURN_VALUE\n",
      "[2024-04-26 07:40:46,038] [5/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:40:46,038] [5/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:40:46,039] [5/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG] MODIFIED BYTECODE data_dep <ipython-input-5-1fcb39c11676> line 11 \n",
      "[2024-04-26 07:40:46,039] [5/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]  11           0 LOAD_FAST                0 (x)\n",
      "[2024-04-26 07:40:46,039] [5/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]               2 LOAD_ATTR                0 (item)\n",
      "[2024-04-26 07:40:46,039] [5/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:40:46,039] [5/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]  13           4 CALL_FUNCTION            0\n",
      "[2024-04-26 07:40:46,039] [5/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]               6 LOAD_GLOBAL              1 (__resume_at_6_9)\n",
      "[2024-04-26 07:40:46,039] [5/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]               8 ROT_TWO\n",
      "[2024-04-26 07:40:46,039] [5/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              10 LOAD_FAST                0 (x)\n",
      "[2024-04-26 07:40:46,039] [5/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              12 LOAD_FAST                1 (y)\n",
      "[2024-04-26 07:40:46,039] [5/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              14 CALL_FUNCTION            3\n",
      "[2024-04-26 07:40:46,039] [5/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              16 RETURN_VALUE\n",
      "[2024-04-26 07:40:46,039] [5/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:40:46,039] [5/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:40:47,631] [6/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] ORIGINAL BYTECODE resume_in_data_dep <ipython-input-5-1fcb39c11676> line 13 \n",
      "[2024-04-26 07:40:47,631] [6/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]  13           0 LOAD_FAST                0 (___stack0)\n",
      "[2024-04-26 07:40:47,631] [6/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               2 JUMP_ABSOLUTE            5 (to 10)\n",
      "[2024-04-26 07:40:47,631] [6/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               4 LOAD_FAST                1 (x)\n",
      "[2024-04-26 07:40:47,631] [6/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               6 LOAD_ATTR                0 (item)\n",
      "[2024-04-26 07:40:47,631] [6/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               8 CALL_FUNCTION            0\n",
      "[2024-04-26 07:40:47,631] [6/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]         >>   10 LOAD_CONST               1 (1)\n",
      "[2024-04-26 07:40:47,631] [6/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              12 COMPARE_OP               2 (==)\n",
      "[2024-04-26 07:40:47,631] [6/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              14 POP_JUMP_IF_FALSE       18 (to 36)\n",
      "[2024-04-26 07:40:47,631] [6/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:40:47,631] [6/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]  14          16 LOAD_FAST                2 (y)\n",
      "[2024-04-26 07:40:47,631] [6/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              18 LOAD_CONST               2 (2)\n",
      "[2024-04-26 07:40:47,631] [6/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              20 INPLACE_ADD\n",
      "[2024-04-26 07:40:47,631] [6/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              22 STORE_FAST               2 (y)\n",
      "[2024-04-26 07:40:47,631] [6/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:40:47,631] [6/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]  15          24 LOAD_FAST                1 (x)\n",
      "[2024-04-26 07:40:47,631] [6/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              26 LOAD_CONST               3 (3)\n",
      "[2024-04-26 07:40:47,631] [6/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              28 INPLACE_ADD\n",
      "[2024-04-26 07:40:47,631] [6/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              30 STORE_FAST               1 (x)\n",
      "[2024-04-26 07:40:47,631] [6/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:40:47,631] [6/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]  19          32 LOAD_FAST                2 (y)\n",
      "[2024-04-26 07:40:47,631] [6/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              34 RETURN_VALUE\n",
      "[2024-04-26 07:40:47,631] [6/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:40:47,631] [6/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]  17     >>   36 LOAD_FAST                2 (y)\n",
      "[2024-04-26 07:40:47,631] [6/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              38 LOAD_CONST               3 (3)\n",
      "[2024-04-26 07:40:47,631] [6/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              40 INPLACE_ADD\n",
      "[2024-04-26 07:40:47,631] [6/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              42 STORE_FAST               2 (y)\n",
      "[2024-04-26 07:40:47,631] [6/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:40:47,631] [6/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]  19          44 LOAD_FAST                2 (y)\n",
      "[2024-04-26 07:40:47,631] [6/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              46 RETURN_VALUE\n",
      "[2024-04-26 07:40:47,631] [6/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:40:47,631] [6/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:40:47,632] [6/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] MODIFIED BYTECODE resume_in_data_dep <ipython-input-5-1fcb39c11676> line 13 \n",
      "[2024-04-26 07:40:47,632] [6/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]  13           0 LOAD_GLOBAL              1 (__compiled_fn_10)\n",
      "[2024-04-26 07:40:47,632] [6/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               2 LOAD_FAST                2 (y)\n",
      "[2024-04-26 07:40:47,632] [6/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               4 LOAD_FAST                1 (x)\n",
      "[2024-04-26 07:40:47,632] [6/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               6 CALL_FUNCTION            2\n",
      "[2024-04-26 07:40:47,632] [6/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               8 UNPACK_SEQUENCE          1\n",
      "[2024-04-26 07:40:47,632] [6/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              10 RETURN_VALUE\n",
      "[2024-04-26 07:40:47,632] [6/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:40:47,632] [6/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:40:47,642] torch._dynamo.guards.__recompiles: [DEBUG] Recompiling function resume_in_data_dep in <ipython-input-5-1fcb39c11676>:13\n",
      "[2024-04-26 07:40:47,642] torch._dynamo.guards.__recompiles: [DEBUG]     triggered by the following guard failure(s):\n",
      "[2024-04-26 07:40:47,642] torch._dynamo.guards.__recompiles: [DEBUG]     - L['___stack0'] == 1.0                                         # if x.item() == 1: # <--- graph break here, extracting data from a tensor.  # <ipython-input-5-1fcb39c11676>:13 in resume_in_data_dep\n",
      "[2024-04-26 07:40:49,198] [6/1] torch._dynamo.convert_frame.__bytecode: [DEBUG] ORIGINAL BYTECODE resume_in_data_dep <ipython-input-5-1fcb39c11676> line 13 \n",
      "[2024-04-26 07:40:49,198] [6/1] torch._dynamo.convert_frame.__bytecode: [DEBUG]  13           0 LOAD_FAST                0 (___stack0)\n",
      "[2024-04-26 07:40:49,198] [6/1] torch._dynamo.convert_frame.__bytecode: [DEBUG]               2 JUMP_ABSOLUTE            5 (to 10)\n",
      "[2024-04-26 07:40:49,198] [6/1] torch._dynamo.convert_frame.__bytecode: [DEBUG]               4 LOAD_FAST                1 (x)\n",
      "[2024-04-26 07:40:49,198] [6/1] torch._dynamo.convert_frame.__bytecode: [DEBUG]               6 LOAD_ATTR                0 (item)\n",
      "[2024-04-26 07:40:49,198] [6/1] torch._dynamo.convert_frame.__bytecode: [DEBUG]               8 CALL_FUNCTION            0\n",
      "[2024-04-26 07:40:49,198] [6/1] torch._dynamo.convert_frame.__bytecode: [DEBUG]         >>   10 LOAD_CONST               1 (1)\n",
      "[2024-04-26 07:40:49,198] [6/1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              12 COMPARE_OP               2 (==)\n",
      "[2024-04-26 07:40:49,198] [6/1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              14 POP_JUMP_IF_FALSE       18 (to 36)\n",
      "[2024-04-26 07:40:49,198] [6/1] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:40:49,198] [6/1] torch._dynamo.convert_frame.__bytecode: [DEBUG]  14          16 LOAD_FAST                2 (y)\n",
      "[2024-04-26 07:40:49,198] [6/1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              18 LOAD_CONST               2 (2)\n",
      "[2024-04-26 07:40:49,198] [6/1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              20 INPLACE_ADD\n",
      "[2024-04-26 07:40:49,198] [6/1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              22 STORE_FAST               2 (y)\n",
      "[2024-04-26 07:40:49,198] [6/1] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:40:49,198] [6/1] torch._dynamo.convert_frame.__bytecode: [DEBUG]  15          24 LOAD_FAST                1 (x)\n",
      "[2024-04-26 07:40:49,198] [6/1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              26 LOAD_CONST               3 (3)\n",
      "[2024-04-26 07:40:49,198] [6/1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              28 INPLACE_ADD\n",
      "[2024-04-26 07:40:49,198] [6/1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              30 STORE_FAST               1 (x)\n",
      "[2024-04-26 07:40:49,198] [6/1] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:40:49,198] [6/1] torch._dynamo.convert_frame.__bytecode: [DEBUG]  19          32 LOAD_FAST                2 (y)\n",
      "[2024-04-26 07:40:49,198] [6/1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              34 RETURN_VALUE\n",
      "[2024-04-26 07:40:49,198] [6/1] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:40:49,198] [6/1] torch._dynamo.convert_frame.__bytecode: [DEBUG]  17     >>   36 LOAD_FAST                2 (y)\n",
      "[2024-04-26 07:40:49,198] [6/1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              38 LOAD_CONST               3 (3)\n",
      "[2024-04-26 07:40:49,198] [6/1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              40 INPLACE_ADD\n",
      "[2024-04-26 07:40:49,198] [6/1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              42 STORE_FAST               2 (y)\n",
      "[2024-04-26 07:40:49,198] [6/1] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:40:49,198] [6/1] torch._dynamo.convert_frame.__bytecode: [DEBUG]  19          44 LOAD_FAST                2 (y)\n",
      "[2024-04-26 07:40:49,198] [6/1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              46 RETURN_VALUE\n",
      "[2024-04-26 07:40:49,198] [6/1] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:40:49,198] [6/1] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:40:49,200] [6/1] torch._dynamo.convert_frame.__bytecode: [DEBUG] MODIFIED BYTECODE resume_in_data_dep <ipython-input-5-1fcb39c11676> line 13 \n",
      "[2024-04-26 07:40:49,200] [6/1] torch._dynamo.convert_frame.__bytecode: [DEBUG]  13           0 LOAD_GLOBAL              1 (__compiled_fn_11)\n",
      "[2024-04-26 07:40:49,200] [6/1] torch._dynamo.convert_frame.__bytecode: [DEBUG]               2 LOAD_FAST                2 (y)\n",
      "[2024-04-26 07:40:49,200] [6/1] torch._dynamo.convert_frame.__bytecode: [DEBUG]               4 CALL_FUNCTION            1\n",
      "[2024-04-26 07:40:49,200] [6/1] torch._dynamo.convert_frame.__bytecode: [DEBUG]               6 UNPACK_SEQUENCE          1\n",
      "[2024-04-26 07:40:49,200] [6/1] torch._dynamo.convert_frame.__bytecode: [DEBUG]               8 RETURN_VALUE\n",
      "[2024-04-26 07:40:49,200] [6/1] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:40:49,200] [6/1] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[4., 4., 4., 4., 4.],\n",
       "        [4., 4., 4., 4., 4.],\n",
       "        [4., 4., 4., 4., 4.],\n",
       "        [4., 4., 4., 4., 4.],\n",
       "        [4., 4., 4., 4., 4.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Example 4: Graph break on data-dependent control flow\n",
    "\n",
    "In this example, the program conditions on data within a tensor. This is not traceable into\n",
    "our graph (because we need to run the computation to determine the runtime value)\n",
    "so the graph is broken, data extracted from the tensor, and tracing continues afterward.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "import torch\n",
    "\n",
    "@torch.compile()\n",
    "def data_dep(x, y):\n",
    "  if x.item() == 1: # <--- graph break here, extracting data from a tensor.\n",
    "    y += 2\n",
    "    x += 3\n",
    "  else:\n",
    "    y += 3\n",
    "\n",
    "  return y\n",
    "\n",
    "torch._logging.set_logs(graph_breaks=True, recompiles=True, bytecode=True)\n",
    "data_dep(torch.ones(1), torch.ones(5, 5))\n",
    "data_dep(torch.zeros(1), torch.ones(5, 5))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "duMkqxyFd11c",
    "outputId": "f5f140ab-b12c-46a1-90d0-d0b1afa39b5c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-26 07:44:27,454] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-04-26 07:44:27,454] [7/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_12 <eval_with_key>.99 opcode         name    target                   args           kwargs\n",
      "[2024-04-26 07:44:27,454] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  ------  -----------------------  -------------  --------\n",
      "[2024-04-26 07:44:27,454] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_x_    L_x_                     ()             {}\n",
      "[2024-04-26 07:44:27,454] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul     <built-in function mul>  (l_x_, 2)      {}\n",
      "[2024-04-26 07:44:27,454] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add     <built-in function add>  (l_x_, 3)      {}\n",
      "[2024-04-26 07:44:27,454] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output  output                   ((mul, add),)  {}\n",
      "[2024-04-26 07:44:27,454] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-04-26 07:44:29,624] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] ORIGINAL BYTECODE mut_list <ipython-input-6-906bdb434fd9> line 12 \n",
      "[2024-04-26 07:44:29,624] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]  14           0 LOAD_FAST                1 (y)\n",
      "[2024-04-26 07:44:29,624] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               2 LOAD_METHOD              0 (append)\n",
      "[2024-04-26 07:44:29,624] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               4 LOAD_FAST                0 (x)\n",
      "[2024-04-26 07:44:29,624] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               6 LOAD_CONST               1 (2)\n",
      "[2024-04-26 07:44:29,624] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               8 BINARY_MULTIPLY\n",
      "[2024-04-26 07:44:29,624] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              10 CALL_METHOD              1\n",
      "[2024-04-26 07:44:29,624] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              12 POP_TOP\n",
      "[2024-04-26 07:44:29,624] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:44:29,624] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]  15          14 LOAD_FAST                1 (y)\n",
      "[2024-04-26 07:44:29,624] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              16 LOAD_METHOD              0 (append)\n",
      "[2024-04-26 07:44:29,624] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              18 LOAD_FAST                0 (x)\n",
      "[2024-04-26 07:44:29,624] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              20 LOAD_CONST               2 (3)\n",
      "[2024-04-26 07:44:29,624] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              22 BINARY_ADD\n",
      "[2024-04-26 07:44:29,624] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              24 CALL_METHOD              1\n",
      "[2024-04-26 07:44:29,624] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              26 POP_TOP\n",
      "[2024-04-26 07:44:29,624] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:44:29,624] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]  16          28 LOAD_FAST                1 (y)\n",
      "[2024-04-26 07:44:29,624] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              30 RETURN_VALUE\n",
      "[2024-04-26 07:44:29,624] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:44:29,624] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:44:29,627] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] MODIFIED BYTECODE mut_list <ipython-input-6-906bdb434fd9> line 12 \n",
      "[2024-04-26 07:44:29,627] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]  12           0 LOAD_GLOBAL              1 (__compiled_fn_12)\n",
      "[2024-04-26 07:44:29,627] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               2 LOAD_FAST                0 (x)\n",
      "[2024-04-26 07:44:29,627] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               4 CALL_FUNCTION            1\n",
      "[2024-04-26 07:44:29,627] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               6 STORE_FAST               2 (graph_out_0)\n",
      "[2024-04-26 07:44:29,627] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               8 LOAD_FAST                1 (y)\n",
      "[2024-04-26 07:44:29,627] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              10 LOAD_FAST                1 (y)\n",
      "[2024-04-26 07:44:29,627] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              12 LOAD_CONST               3 (0)\n",
      "[2024-04-26 07:44:29,627] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              14 BINARY_SUBSCR\n",
      "[2024-04-26 07:44:29,627] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              16 LOAD_FAST                1 (y)\n",
      "[2024-04-26 07:44:29,627] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              18 LOAD_CONST               4 (1)\n",
      "[2024-04-26 07:44:29,627] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              20 BINARY_SUBSCR\n",
      "[2024-04-26 07:44:29,627] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              22 LOAD_FAST                1 (y)\n",
      "[2024-04-26 07:44:29,627] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              24 LOAD_CONST               1 (2)\n",
      "[2024-04-26 07:44:29,627] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              26 BINARY_SUBSCR\n",
      "[2024-04-26 07:44:29,627] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              28 LOAD_FAST                2 (graph_out_0)\n",
      "[2024-04-26 07:44:29,627] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              30 LOAD_CONST               3 (0)\n",
      "[2024-04-26 07:44:29,627] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              32 BINARY_SUBSCR\n",
      "[2024-04-26 07:44:29,627] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              34 LOAD_FAST                2 (graph_out_0)\n",
      "[2024-04-26 07:44:29,627] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              36 LOAD_CONST               4 (1)\n",
      "[2024-04-26 07:44:29,627] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              38 BINARY_SUBSCR\n",
      "[2024-04-26 07:44:29,627] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              40 BUILD_LIST               5\n",
      "[2024-04-26 07:44:29,627] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              42 LOAD_FAST                1 (y)\n",
      "[2024-04-26 07:44:29,627] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              44 LOAD_CONST               0 (None)\n",
      "[2024-04-26 07:44:29,627] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              46 LOAD_CONST               0 (None)\n",
      "[2024-04-26 07:44:29,627] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              48 BUILD_SLICE              2\n",
      "[2024-04-26 07:44:29,627] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              50 STORE_SUBSCR\n",
      "[2024-04-26 07:44:29,627] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              52 RETURN_VALUE\n",
      "[2024-04-26 07:44:29,627] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:44:29,627] [7/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:44:29,653] [8/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-04-26 07:44:29,653] [8/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_13 <eval_with_key>.106 opcode         name    target                   args       kwargs\n",
      "[2024-04-26 07:44:29,653] [8/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  ------  -----------------------  ---------  --------\n",
      "[2024-04-26 07:44:29,653] [8/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_x_    L_x_                     ()         {}\n",
      "[2024-04-26 07:44:29,653] [8/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add     <built-in function add>  (l_x_, 2)  {}\n",
      "[2024-04-26 07:44:29,653] [8/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output  output                   ((add,),)  {}\n",
      "[2024-04-26 07:44:29,653] [8/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-04-26 07:44:31,540] [8/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] ORIGINAL BYTECODE mut_dict <ipython-input-6-906bdb434fd9> line 22 \n",
      "[2024-04-26 07:44:31,540] [8/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]  24           0 LOAD_FAST                0 (x)\n",
      "[2024-04-26 07:44:31,540] [8/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               2 LOAD_CONST               1 (2)\n",
      "[2024-04-26 07:44:31,540] [8/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               4 BINARY_ADD\n",
      "[2024-04-26 07:44:31,540] [8/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               6 LOAD_FAST                1 (d)\n",
      "[2024-04-26 07:44:31,540] [8/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               8 LOAD_CONST               2 ('z')\n",
      "[2024-04-26 07:44:31,540] [8/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              10 STORE_SUBSCR\n",
      "[2024-04-26 07:44:31,540] [8/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:44:31,540] [8/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]  25          12 LOAD_FAST                0 (x)\n",
      "[2024-04-26 07:44:31,540] [8/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              14 LOAD_FAST                1 (d)\n",
      "[2024-04-26 07:44:31,540] [8/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              16 LOAD_CONST               3 ('a')\n",
      "[2024-04-26 07:44:31,540] [8/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              18 STORE_SUBSCR\n",
      "[2024-04-26 07:44:31,540] [8/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:44:31,540] [8/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]  26          20 LOAD_FAST                1 (d)\n",
      "[2024-04-26 07:44:31,540] [8/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              22 RETURN_VALUE\n",
      "[2024-04-26 07:44:31,540] [8/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:44:31,540] [8/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:44:31,542] [8/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] MODIFIED BYTECODE mut_dict <ipython-input-6-906bdb434fd9> line 22 \n",
      "[2024-04-26 07:44:31,542] [8/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]  22           0 LOAD_GLOBAL              2 (__compiled_fn_13)\n",
      "[2024-04-26 07:44:31,542] [8/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               2 LOAD_FAST                0 (x)\n",
      "[2024-04-26 07:44:31,542] [8/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               4 CALL_FUNCTION            1\n",
      "[2024-04-26 07:44:31,542] [8/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               6 STORE_FAST               2 (graph_out_0)\n",
      "[2024-04-26 07:44:31,542] [8/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               8 LOAD_FAST                1 (d)\n",
      "[2024-04-26 07:44:31,542] [8/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              10 LOAD_FAST                1 (d)\n",
      "[2024-04-26 07:44:31,542] [8/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              12 LOAD_METHOD              1 (update)\n",
      "[2024-04-26 07:44:31,542] [8/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              14 LOAD_CONST               2 ('z')\n",
      "[2024-04-26 07:44:31,542] [8/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              16 LOAD_FAST                2 (graph_out_0)\n",
      "[2024-04-26 07:44:31,542] [8/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              18 LOAD_CONST               4 (0)\n",
      "[2024-04-26 07:44:31,542] [8/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              20 BINARY_SUBSCR\n",
      "[2024-04-26 07:44:31,542] [8/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              22 LOAD_CONST               3 ('a')\n",
      "[2024-04-26 07:44:31,542] [8/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              24 LOAD_FAST                0 (x)\n",
      "[2024-04-26 07:44:31,542] [8/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              26 BUILD_MAP                2\n",
      "[2024-04-26 07:44:31,542] [8/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              28 LOAD_FAST                1 (d)\n",
      "[2024-04-26 07:44:31,542] [8/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              30 LOAD_METHOD              0 (clear)\n",
      "[2024-04-26 07:44:31,542] [8/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              32 CALL_METHOD              0\n",
      "[2024-04-26 07:44:31,542] [8/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              34 POP_TOP\n",
      "[2024-04-26 07:44:31,542] [8/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              36 CALL_METHOD              1\n",
      "[2024-04-26 07:44:31,542] [8/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              38 POP_TOP\n",
      "[2024-04-26 07:44:31,542] [8/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              40 RETURN_VALUE\n",
      "[2024-04-26 07:44:31,542] [8/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:44:31,542] [8/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'z': tensor([[3., 3.],\n",
       "         [3., 3.]]),\n",
       " 'a': tensor([[1., 1.],\n",
       "         [1., 1.]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Example 5: Mutation of python object\n",
    "\n",
    "In this example, the programs take in a python dicts and lists\n",
    "and mutate the contents. Internally, dynamo tracks these mutations and constructs\n",
    "the final state directly after calling the compiled graph.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "import torch\n",
    "import logging\n",
    "\n",
    "@torch.compile()\n",
    "def mut_list(x, y):\n",
    "  y.append(x * 2)\n",
    "  y.append(x + 3)\n",
    "  return y\n",
    "\n",
    "torch._logging.set_logs(graph=True, bytecode=True)\n",
    "mut_list(torch.ones(2, 2), [0, 0, 0])\n",
    "\n",
    "\n",
    "@torch.compile()\n",
    "def mut_dict(x, d):\n",
    "  d[\"z\"] = x + 2\n",
    "  d[\"a\"] = x\n",
    "  return d\n",
    "\n",
    "mut_dict(torch.ones(2, 2), {})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RNRvDrJdd_67",
    "outputId": "0d9ec4ca-99c2-4fc7-da57-92c866e5bd9c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-26 07:50:56,479] [14/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG] Graph break: call torch._dynamo.disable() wrapped function <function inner at 0x7e3ef2fe9990> from user code at:\n",
      "[2024-04-26 07:50:56,479] [14/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"<ipython-input-9-2bde79ae0f3d>\", line 22, in disable_demo\n",
      "[2024-04-26 07:50:56,479] [14/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     z = inner(x)\n",
      "[2024-04-26 07:50:56,479] [14/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG] \n",
      "[2024-04-26 07:50:56,487] [14/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG] ORIGINAL BYTECODE disable_demo <ipython-input-9-2bde79ae0f3d> line 20 \n",
      "[2024-04-26 07:50:56,487] [14/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]  22           0 LOAD_GLOBAL              0 (inner)\n",
      "[2024-04-26 07:50:56,487] [14/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]               2 LOAD_FAST                0 (x)\n",
      "[2024-04-26 07:50:56,487] [14/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]               4 CALL_FUNCTION            1\n",
      "[2024-04-26 07:50:56,487] [14/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]               6 STORE_FAST               1 (z)\n",
      "[2024-04-26 07:50:56,487] [14/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:50:56,487] [14/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]  23           8 LOAD_FAST                1 (z)\n",
      "[2024-04-26 07:50:56,487] [14/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              10 RETURN_VALUE\n",
      "[2024-04-26 07:50:56,487] [14/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:50:56,487] [14/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:50:56,488] [14/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG] MODIFIED BYTECODE disable_demo <ipython-input-9-2bde79ae0f3d> line 20 \n",
      "[2024-04-26 07:50:56,488] [14/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]  20           0 LOAD_GLOBAL              0 (inner)\n",
      "[2024-04-26 07:50:56,488] [14/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]               2 LOAD_FAST                0 (x)\n",
      "[2024-04-26 07:50:56,488] [14/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:50:56,488] [14/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]  22           4 CALL_FUNCTION            1\n",
      "[2024-04-26 07:50:56,488] [14/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]               6 LOAD_GLOBAL              1 (__resume_at_6_17)\n",
      "[2024-04-26 07:50:56,488] [14/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]               8 ROT_TWO\n",
      "[2024-04-26 07:50:56,488] [14/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              10 CALL_FUNCTION            1\n",
      "[2024-04-26 07:50:56,488] [14/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG]              12 RETURN_VALUE\n",
      "[2024-04-26 07:50:56,488] [14/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:50:56,488] [14/0_1] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:50:56,537] [15/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] ORIGINAL BYTECODE inner2 <ipython-input-9-2bde79ae0f3d> line 11 \n",
      "[2024-04-26 07:50:56,537] [15/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]  12           0 LOAD_FAST                0 (x)\n",
      "[2024-04-26 07:50:56,537] [15/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               2 LOAD_CONST               1 (2)\n",
      "[2024-04-26 07:50:56,537] [15/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               4 BINARY_MULTIPLY\n",
      "[2024-04-26 07:50:56,537] [15/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               6 RETURN_VALUE\n",
      "[2024-04-26 07:50:56,537] [15/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:50:56,537] [15/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:50:56,538] [15/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] MODIFIED BYTECODE inner2 <ipython-input-9-2bde79ae0f3d> line 11 \n",
      "[2024-04-26 07:50:56,538] [15/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]  11           0 LOAD_GLOBAL              0 (__compiled_fn_18)\n",
      "[2024-04-26 07:50:56,538] [15/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               2 LOAD_FAST                0 (x)\n",
      "[2024-04-26 07:50:56,538] [15/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               4 CALL_FUNCTION            1\n",
      "[2024-04-26 07:50:56,538] [15/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               6 UNPACK_SEQUENCE          1\n",
      "[2024-04-26 07:50:56,538] [15/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               8 RETURN_VALUE\n",
      "[2024-04-26 07:50:56,538] [15/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2024-04-26 07:50:56,538] [15/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3., 3.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Example 6: Using dynamo disable\n",
    "\n",
    "In this example, the use of dynamo disable is demonstrated. This function can be used to\n",
    "tell dynamo to always run this function in the python interpreter. It can be setup to apply recursively on all inner\n",
    "functions or just on the highest level frame.\n",
    "\n",
    "\"\"\"\n",
    "import torch\n",
    "import logging\n",
    "\n",
    "def inner2(x):\n",
    "  return x * 2\n",
    "\n",
    "# By default, the disable\n",
    "# applies to function and all recursively invoked frames\n",
    "@torch._dynamo.disable(recursive=False)\n",
    "def inner(x):\n",
    "  return inner2(x) + 1\n",
    "\n",
    "@torch.compile()\n",
    "def disable_demo(x):\n",
    "  z = inner(x)\n",
    "  return z\n",
    "\n",
    "\n",
    "torch._logging.set_logs(graph_breaks=True, bytecode=True)\n",
    "disable_demo(torch.ones(5, 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sEf5ppnydbRc",
    "outputId": "8516462c-69c1-4b70-8b53-eef9bd5c488b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-26 07:54:12,368] [17/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-04-26 07:54:12,368] [17/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_19 <eval_with_key>.127 opcode       name      target    args                kwargs\n",
      "[2024-04-26 07:54:12,368] [17/0] torch._dynamo.output_graph.__graph: [DEBUG] -----------  --------  --------  ------------------  --------\n",
      "[2024-04-26 07:54:12,368] [17/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder  l_x_      L_x_      ()                  {}\n",
      "[2024-04-26 07:54:12,368] [17/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder  l_y_      L_y_      ()                  {}\n",
      "[2024-04-26 07:54:12,368] [17/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder  l_z_      L_z_      ()                  {}\n",
      "[2024-04-26 07:54:12,368] [17/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  addcdiv_  addcdiv_  (l_x_, l_y_, l_z_)  {}\n",
      "[2024-04-26 07:54:12,368] [17/0] torch._dynamo.output_graph.__graph: [DEBUG] output       output    output    ((addcdiv_,),)      {}\n",
      "[2024-04-26 07:54:12,368] [17/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-04-26 07:54:12,395] [17/0] torch._functorch._aot_autograd.dispatch_and_compile_graph.__aot_graphs: [INFO] TRACED GRAPH\n",
      "[2024-04-26 07:54:12,395] [17/0] torch._functorch._aot_autograd.dispatch_and_compile_graph.__aot_graphs: [INFO]  ===== Forward graph 17 =====\n",
      "[2024-04-26 07:54:12,395] [17/0] torch._functorch._aot_autograd.dispatch_and_compile_graph.__aot_graphs: [INFO]  <eval_with_key>.131 from /usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py:511 in wrapped class <lambda>(torch.nn.Module):\n",
      "[2024-04-26 07:54:12,395] [17/0] torch._functorch._aot_autograd.dispatch_and_compile_graph.__aot_graphs: [INFO]     def forward(self, arg0_1: \"f32[2, 2]\", arg1_1: \"f32[2, 2]\", arg2_1: \"f32[2, 2]\"):\n",
      "[2024-04-26 07:54:12,395] [17/0] torch._functorch._aot_autograd.dispatch_and_compile_graph.__aot_graphs: [INFO]         # File: <ipython-input-10-9f10f08444dc>:15, code: return x.addcdiv_(y, z)\n",
      "[2024-04-26 07:54:12,395] [17/0] torch._functorch._aot_autograd.dispatch_and_compile_graph.__aot_graphs: [INFO]         mul: \"f32[2, 2]\" = torch.ops.aten.mul.Tensor(arg1_1, 1);  arg1_1 = None\n",
      "[2024-04-26 07:54:12,395] [17/0] torch._functorch._aot_autograd.dispatch_and_compile_graph.__aot_graphs: [INFO]         div: \"f32[2, 2]\" = torch.ops.aten.div.Tensor(mul, arg2_1);  mul = arg2_1 = None\n",
      "[2024-04-26 07:54:12,395] [17/0] torch._functorch._aot_autograd.dispatch_and_compile_graph.__aot_graphs: [INFO]         add: \"f32[2, 2]\" = torch.ops.aten.add.Tensor(arg0_1, div);  div = None\n",
      "[2024-04-26 07:54:12,395] [17/0] torch._functorch._aot_autograd.dispatch_and_compile_graph.__aot_graphs: [INFO]         \n",
      "[2024-04-26 07:54:12,395] [17/0] torch._functorch._aot_autograd.dispatch_and_compile_graph.__aot_graphs: [INFO]         # No stacktrace found for following nodes\n",
      "[2024-04-26 07:54:12,395] [17/0] torch._functorch._aot_autograd.dispatch_and_compile_graph.__aot_graphs: [INFO]         copy_: \"f32[2, 2]\" = torch.ops.aten.copy_.default(arg0_1, add);  arg0_1 = None\n",
      "[2024-04-26 07:54:12,395] [17/0] torch._functorch._aot_autograd.dispatch_and_compile_graph.__aot_graphs: [INFO]         return (add,)\n",
      "[2024-04-26 07:54:12,395] [17/0] torch._functorch._aot_autograd.dispatch_and_compile_graph.__aot_graphs: [INFO]         \n",
      "[2024-04-26 07:54:12,395] [17/0] torch._functorch._aot_autograd.dispatch_and_compile_graph.__aot_graphs: [INFO] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Example 7: Functionalization and Decompositions\n",
    "\n",
    "In this example we'll show how AOTAutograd will remove mutations from the graph\n",
    "and also decompse complex ops into the core Aten opset.\n",
    "\n",
    "\"\"\"\n",
    "import torch\n",
    "\n",
    "\n",
    "# addcdiv is a composed add and divide\n",
    "# see https://pytorch.org/docs/stable/generated/torch.Tensor.addcdiv_.html\n",
    "# for more info\n",
    "@torch.compile()\n",
    "def func_and_decomps(x, y, z):\n",
    "  return x.addcdiv_(y, z)\n",
    "\n",
    "\n",
    "# View the graph after decompositions and functionalization have been applied\n",
    "# in the previous examples we only viewed the graph that dynamo captured\n",
    "# AOTAutograd takes this graph and applies transformations to it.\n",
    "torch._logging.set_logs(graph=True, aot_graphs=True)\n",
    "func_and_decomps(torch.ones(2, 2), torch.zeros(2, 2), torch.ones(2, 2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yPNkk1mdc-nj",
    "outputId": "779e57f9-c464-4a7a-ce74-fef9237e5c62"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "[2024-04-27 06:53:16,056] [0/0] torch._functorch._aot_autograd.jit_compile_runtime_wrappers.__aot_graphs: [INFO] TRACED GRAPH\n",
      "[2024-04-27 06:53:16,056] [0/0] torch._functorch._aot_autograd.jit_compile_runtime_wrappers.__aot_graphs: [INFO]  ===== Forward graph 0 =====\n",
      "[2024-04-27 06:53:16,056] [0/0] torch._functorch._aot_autograd.jit_compile_runtime_wrappers.__aot_graphs: [INFO]  <eval_with_key>.35 class GraphModule(torch.nn.Module):\n",
      "[2024-04-27 06:53:16,056] [0/0] torch._functorch._aot_autograd.jit_compile_runtime_wrappers.__aot_graphs: [INFO]     def forward(self, primals_1: \"f32[2, 2]\", primals_2: \"f32[2, 2]\"):\n",
      "[2024-04-27 06:53:16,056] [0/0] torch._functorch._aot_autograd.jit_compile_runtime_wrappers.__aot_graphs: [INFO]         # File: <ipython-input-1-9069f7cc785b>:14, code: return input * param\n",
      "[2024-04-27 06:53:16,056] [0/0] torch._functorch._aot_autograd.jit_compile_runtime_wrappers.__aot_graphs: [INFO]         mul: \"f32[2, 2]\" = torch.ops.aten.mul.Tensor(primals_2, primals_1);  primals_1 = None\n",
      "[2024-04-27 06:53:16,056] [0/0] torch._functorch._aot_autograd.jit_compile_runtime_wrappers.__aot_graphs: [INFO]         return [mul, primals_2]\n",
      "[2024-04-27 06:53:16,056] [0/0] torch._functorch._aot_autograd.jit_compile_runtime_wrappers.__aot_graphs: [INFO]         \n",
      "[2024-04-27 06:53:16,056] [0/0] torch._functorch._aot_autograd.jit_compile_runtime_wrappers.__aot_graphs: [INFO] \n",
      "[2024-04-27 06:53:16,059] [0/0] torch._functorch._aot_autograd.jit_compile_runtime_wrappers.__aot_graphs: [INFO] TRACED GRAPH\n",
      "[2024-04-27 06:53:16,059] [0/0] torch._functorch._aot_autograd.jit_compile_runtime_wrappers.__aot_graphs: [INFO]  ===== Backward graph 0 =====\n",
      "[2024-04-27 06:53:16,059] [0/0] torch._functorch._aot_autograd.jit_compile_runtime_wrappers.__aot_graphs: [INFO]  <eval_with_key>.36 class GraphModule(torch.nn.Module):\n",
      "[2024-04-27 06:53:16,059] [0/0] torch._functorch._aot_autograd.jit_compile_runtime_wrappers.__aot_graphs: [INFO]     def forward(self, primals_2: \"f32[2, 2]\", tangents_1: \"f32[2, 2]\"):\n",
      "[2024-04-27 06:53:16,059] [0/0] torch._functorch._aot_autograd.jit_compile_runtime_wrappers.__aot_graphs: [INFO]         # File: <ipython-input-1-9069f7cc785b>:14, code: return input * param\n",
      "[2024-04-27 06:53:16,059] [0/0] torch._functorch._aot_autograd.jit_compile_runtime_wrappers.__aot_graphs: [INFO]         mul_1: \"f32[2, 2]\" = torch.ops.aten.mul.Tensor(tangents_1, primals_2);  tangents_1 = primals_2 = None\n",
      "[2024-04-27 06:53:16,059] [0/0] torch._functorch._aot_autograd.jit_compile_runtime_wrappers.__aot_graphs: [INFO]         return [mul_1, None]\n",
      "[2024-04-27 06:53:16,059] [0/0] torch._functorch._aot_autograd.jit_compile_runtime_wrappers.__aot_graphs: [INFO]         \n",
      "[2024-04-27 06:53:16,059] [0/0] torch._functorch._aot_autograd.jit_compile_runtime_wrappers.__aot_graphs: [INFO] \n"
     ]
    }
   ],
   "source": [
    "\"\"\"Example 8: Forward and Backward\n",
    "\n",
    "In this example the program will generate a forward and backward graph using AOTAutograd.\n",
    "Up until this point the previous examples had been generating inference graphs (ie only the forward pass)\n",
    "\n",
    "\"\"\"\n",
    "import torch\n",
    "\n",
    "input = torch.ones(2, 2)\n",
    "param = torch.ones(2, 2, requires_grad=True)\n",
    "\n",
    "@torch.compile()\n",
    "def fwd_bwd(input):\n",
    "  return input * param\n",
    "\n",
    "torch._logging.set_logs(aot_graphs=True)\n",
    "out = fwd_bwd(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NYgSlULYdN75",
    "outputId": "55068d43-a809-473d-d4c6-22a5c8ba7dbc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-26 07:59:44,623] [21/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-04-26 07:59:44,624] [21/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['x'], '_dynamo_dynamic_indices') == False           # return x * y + 10  # <ipython-input-14-b1360c215c49>:13 in fn\n",
      "[2024-04-26 07:59:44,627] [21/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['y'], '_dynamo_dynamic_indices') == False           # return x * y + 10  # <ipython-input-14-b1360c215c49>:13 in fn\n",
      "[2024-04-26 07:59:44,629] [21/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:379 in init_ambient_guards\n",
      "[2024-04-26 07:59:44,631] [21/0] torch._dynamo.guards.__guards: [DEBUG] (___skip_backend_check() or ___current_backend() == ___lookup_backend(138808821124928))  # _dynamo/output_graph.py:385 in init_ambient_guards\n",
      "[2024-04-26 07:59:44,633] [21/0] torch._dynamo.guards.__guards: [DEBUG] ___compile_config_hash() == '88a14d47e62622e2d97d70c8d06ad8bd'  # _dynamo/output_graph.py:387 in init_ambient_guards\n",
      "[2024-04-26 07:59:44,635] [21/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['x'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[2, 2], stride=[2, 1])  # return x * y + 10  # <ipython-input-14-b1360c215c49>:13 in fn\n",
      "[2024-04-26 07:59:44,637] [21/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['y'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[2, 2], stride=[2, 1])  # return x * y + 10  # <ipython-input-14-b1360c215c49>:13 in fn\n",
      "[2024-04-26 07:59:44,647] torch._dynamo.guards.__recompiles: [DEBUG] Recompiling function fn in <ipython-input-14-b1360c215c49>:11\n",
      "[2024-04-26 07:59:44,647] torch._dynamo.guards.__recompiles: [DEBUG]     triggered by the following guard failure(s):\n",
      "[2024-04-26 07:59:44,647] torch._dynamo.guards.__recompiles: [DEBUG]     - tensor 'L['x']' size mismatch at index 0. expected 2, actual 4\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG] Output code: \n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG] from ctypes import c_void_p, c_long\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG] import torch\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG] import math\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG] import random\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG] import os\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG] import tempfile\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG] from math import inf, nan\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.hooks import run_intermediate_hooks\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import maybe_profile\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.codegen.memory_planning import _align as align\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG] from torch import device, empty, empty_strided\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.codecache import AsyncCompile\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.select_algorithm import extern_kernels\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG] aten = torch.ops.aten\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG] inductor_ops = torch.ops.inductor\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG] assert_size_stride = torch._C._dynamo.guards.assert_size_stride\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG] alloc_from_pool = torch.ops.inductor._alloc_from_pool\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG] reinterpret_tensor = torch.ops.inductor._reinterpret_tensor\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG] async_compile = AsyncCompile()\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG] cpp_fused_add_mul_0 = async_compile.cpp('''\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG] #include \"/tmp/torchinductor_root/26/c26eqbkuxvn72gf7p2xujmqjcwf4bo6lxmp6rwborxnf4gldnimh.h\"\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG] extern \"C\" void kernel(const float* in_ptr0,\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG]                        const float* in_ptr1,\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG]                        float* out_ptr0,\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG]                        const long ks0)\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG] {\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG]     {\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG]         for(long x0=static_cast<long>(0L); x0<static_cast<long>(8L*(c10::div_floor_integer(ks0, 4L))); x0+=static_cast<long>(8L))\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG]         {\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG]             auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<long>(x0));\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG]             auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<long>(x0));\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG]             auto tmp2 = tmp0 * tmp1;\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG]             auto tmp3 = static_cast<float>(10.0);\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG]             auto tmp4 = at::vec::Vectorized<float>(tmp3);\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG]             auto tmp5 = tmp2 + tmp4;\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG]             tmp5.store(out_ptr0 + static_cast<long>(x0));\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG]         }\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG]         #pragma omp simd simdlen(4) \n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG]         for(long x0=static_cast<long>(8L*(c10::div_floor_integer(ks0, 4L))); x0<static_cast<long>(2L*ks0); x0+=static_cast<long>(1L))\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG]         {\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG]             auto tmp0 = in_ptr0[static_cast<long>(x0)];\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG]             auto tmp1 = in_ptr1[static_cast<long>(x0)];\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG]             auto tmp2 = decltype(tmp0)(tmp0 * tmp1);\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG]             auto tmp3 = static_cast<float>(10.0);\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG]             auto tmp4 = decltype(tmp2)(tmp2 + tmp3);\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG]             out_ptr0[static_cast<long>(x0)] = tmp4;\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG]         }\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG]     }\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG] }\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG] ''')\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG] async_compile.wait(globals())\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG] del async_compile\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG] def call(args):\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG]     arg0_1, arg1_1, arg2_1 = args\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG]     args.clear()\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG]     s0 = arg0_1\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(arg1_1, (s0, 2), (2, 1))\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(arg2_1, (s0, 2), (2, 1))\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG]     buf0 = empty((s0, 2), device='cpu', dtype=torch.float32)\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG]     cpp_fused_add_mul_0(c_void_p(arg1_1.data_ptr()), c_void_p(arg2_1.data_ptr()), c_void_p(buf0.data_ptr()), c_long(s0))\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG]     del arg1_1\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG]     del arg2_1\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG]     return (buf0, )\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG] def benchmark_compiled_module(times=10, repeat=10):\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG]     from torch._dynamo.testing import rand_strided\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG]     from torch._inductor.utils import print_performance\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG]     arg0_1 = 4\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG]     arg1_1 = rand_strided((4, 2), (2, 1), device='cpu', dtype=torch.float32)\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG]     arg2_1 = rand_strided((4, 2), (2, 1), device='cpu', dtype=torch.float32)\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG]     fn = lambda: call([arg0_1, arg1_1, arg2_1])\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG]     return print_performance(fn, times=times, repeat=repeat)\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG] if __name__ == \"__main__\":\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG]     from torch._inductor.wrapper_benchmark import compiled_module_main\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG]     compiled_module_main('None', benchmark_compiled_module)\n",
      "[2024-04-26 07:59:44,706] [21/1] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2024-04-26 07:59:44,707] [21/1] torch._inductor.graph.__output_code: [INFO] Output code written to: /tmp/torchinductor_root/lv/clvfvhkuloham2li25fy37akxn4g2wx2a3eyduwhmpgetczoxrdv.py\n",
      "[2024-04-26 07:59:44,717] [21/1] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-04-26 07:59:44,718] [21/1] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['x'], '_dynamo_dynamic_indices') == False           # return x * y + 10  # <ipython-input-14-b1360c215c49>:13 in fn\n",
      "[2024-04-26 07:59:44,720] [21/1] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['y'], '_dynamo_dynamic_indices') == False           # return x * y + 10  # <ipython-input-14-b1360c215c49>:13 in fn\n",
      "[2024-04-26 07:59:44,723] [21/1] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:379 in init_ambient_guards\n",
      "[2024-04-26 07:59:44,725] [21/1] torch._dynamo.guards.__guards: [DEBUG] (___skip_backend_check() or ___current_backend() == ___lookup_backend(138808821124928))  # _dynamo/output_graph.py:385 in init_ambient_guards\n",
      "[2024-04-26 07:59:44,727] [21/1] torch._dynamo.guards.__guards: [DEBUG] ___compile_config_hash() == '88a14d47e62622e2d97d70c8d06ad8bd'  # _dynamo/output_graph.py:387 in init_ambient_guards\n",
      "[2024-04-26 07:59:44,729] [21/1] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['x'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[None, 2], stride=[2, 1])  # return x * y + 10  # <ipython-input-14-b1360c215c49>:13 in fn\n",
      "[2024-04-26 07:59:44,732] [21/1] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['y'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[None, 2], stride=[2, 1])  # return x * y + 10  # <ipython-input-14-b1360c215c49>:13 in fn\n",
      "[2024-04-26 07:59:44,733] [21/1] torch._dynamo.guards.__guards: [DEBUG] L['y'].size()[0] == L['x'].size()[0]                          # _dynamo/output_graph.py:371 in init_ambient_guards\n",
      "[2024-04-26 07:59:44,735] [21/1] torch._dynamo.guards.__guards: [DEBUG] 2 <= L['x'].size()[0]                                         # _dynamo/output_graph.py:371 in init_ambient_guards\n",
      "[2024-04-26 07:59:44,736] [21/1] torch._dynamo.guards.__guards: [DEBUG] 2 <= L['x'].size()[0]                                         # _dynamo/output_graph.py:371 in init_ambient_guards\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[11., 11.],\n",
       "        [11., 11.],\n",
       "        [11., 11.],\n",
       "        [11., 11.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Example 9: Dynamic Shapes\n",
    "\n",
    "In this example, we will show how dynamic shapes will automatically get enabled\n",
    "if the shapes of the inputs change during a recompilation. In the output code\n",
    "the shapes values are passed to the kernel to take into account this dynamism.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "\n",
    "@torch.compile()\n",
    "def fn(x, y):\n",
    "  return x * y + 10\n",
    "\n",
    "torch._logging.set_logs(guards=True)\n",
    "fn(torch.ones(2, 2), torch.ones(2, 2))\n",
    "torch._logging.set_logs(guards=True, recompiles=True, output_code=True)\n",
    "fn(torch.ones(4, 2), torch.ones(4, 2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YEmwIqpdzCJv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
